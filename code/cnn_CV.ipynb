{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa1e0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 15:24:28.881855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-26 15:24:29.404102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 15:24:30.507142: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 15:24:30.528982: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 15:24:30.529037: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 15:24:30.531453: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 15:24:30.531500: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 15:24:30.531532: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 15:24:30.718591: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 15:24:30.718665: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 15:24:30.718673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-04-26 15:24:30.718718: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 15:24:30.718739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:05:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Add this at the very top\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Restrict TensorFlow to only allocate memory dynamically\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "# Load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "from Resnet3D_model import Resnet3DBuilder\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, f1_score, matthews_corrcoef, roc_auc_score, roc_curve, accuracy_score, recall_score, confusion_matrix\n",
    "from data_utils_CV import get_paths_and_labels, calculate_min_max, create_dataset, clean_zone_identifier_files, extract_subject_id\n",
    "from plotting_utils import view_image, view_random_image, plot_loss_curves, make_confusion_matrix, view_image_data\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccca6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set for reproducibility (seed=42)\n",
      "PYTHONHASHSEED set to: 42\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(f\"Seeds set for reproducibility (seed={seed})\")\n",
    "print(f\"PYTHONHASHSEED set to: {os.environ.get('PYTHONHASHSEED')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6be449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision policy set to: mixed_float16\n"
     ]
    }
   ],
   "source": [
    "# Set mixed precision policy to 'mixed_float16'\n",
    "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.set_global_policy(policy)\n",
    "print('Mixed precision policy set to:', policy.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0dbea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class map: {'smci': 0, 'pmci': 1}\n",
      "Scanning /home/diogommiranda/tese/datasets/mni_reg_CV/smci_pmci/train...\n",
      "Found 575 files for class 'smci'\n",
      "Found 314 files for class 'pmci'\n",
      "Calculating minmax across 889 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Class map: {'smci': 0, 'pmci': 1}\n",
      "Scanning /home/diogommiranda/tese/datasets/mni_reg_CV/smci_pmci/test...\n",
      "Found 143 files for class 'smci'\n",
      "Found 78 files for class 'pmci'\n",
      "\n",
      "No mask applied.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VOLUME_SHAPE = (91, 109, 91) # Expected volume shape of the PET nifti images\n",
    "NORMALIZATION = \"mni_reg_CV\" # Choose intensity normalization method: \"minmax\"\n",
    "DATASET = \"smci_pmci\" # Choose dataset: \"smci_pmci\" or \"nc_ad\"\n",
    "BATCH_SIZE = 4 # Choose batch size\n",
    "\n",
    "DATA_DIR = Path(\"/home/diogommiranda/tese/datasets/\") / NORMALIZATION / DATASET\n",
    "#ROI_MASK_PATH = str(Path(\"/home/diogommiranda/tese/masks/ROI_MASK.nii\"))\n",
    "ROI_MASK_PATH = None \n",
    "\n",
    "# Get train paths and labels to calculate minmax values\n",
    "train_paths, train_labels_list, class_map = get_paths_and_labels(DATA_DIR, 'train')\n",
    "train_paths = np.array(train_paths)\n",
    "train_labels = np.array(train_labels_list)\n",
    "\n",
    "# Calculate minmax values for train set\n",
    "minmax_min, minmax_max = calculate_min_max(train_paths)\n",
    "\n",
    "# Create test set with the minmax values from train\n",
    "test_paths, test_labels, _ = get_paths_and_labels(DATA_DIR, 'test', class_map=class_map)\n",
    "test_data = create_dataset(\n",
    "    paths=test_paths,\n",
    "    labels=test_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    volume_shape=VOLUME_SHAPE,\n",
    "    is_training=False,\n",
    "    seed=None,\n",
    "    min_val=minmax_min, \n",
    "    max_val=minmax_max,\n",
    "    mask_path=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84def554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZwAAAHqCAYAAACA44tnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAyp9JREFUeJzs3XmcJlV59/9rWGaGWXqmZ2OGAWYGiEE0CYiIAZG4DKiIohEEHxfwpxjNg2hckKBsLqhxgUejRo2AiKJGUIhBRMHHjai4EA2JIqvszNKzs079/vCZydzf+naf6667uqe75/N+vfqPqq7l1KntrqpzrmtCVVVVAAAAAAAAAADQo+22dgEAAAAAAAAAAOMDL5wBAAAAAAAAAK3ghTMAAAAAAAAAoBW8cAYAAAAAAAAAtIIXzgAAAAAAAACAVvDCGQAAAAAAAADQCl44AwAAAAAAAABawQtnAAAAAAAAAEAreOEMAAAAAAAAAGgFL5wBAACALpx55pkxYcKE1pZ32223xYQJE+KCCy4YtnV04ytf+UrMmjUr1q5du1XW34ZHHnkkdtttt/jEJz6xtYsCADDcvS/rggsuiAkTJsRtt93WWnkmTJgQZ5555rCuI+unP/1pTJw4MW6//fYRX3fb3vGOd8SBBx64tYuBrYAXzgAAAGjNzTffHK973etijz32iMmTJ0dfX18cfPDBcd5558WGDRu2dvFG3BVXXBGHHnpozJs3L6ZMmRJ77LFHHHPMMfGtb31raxfNeuyxx+KMM86Ik046KaZNmxbXXXddbLfddnHqqafa6T/wgQ/EhAkT4pvf/GZP6/2rv/qrmDBhQu3vOc95zpDzvfe9740JEybEE5/4xI7xO+64Y/zd3/1dvPe9740HH3ywp7IBAP7HJz7xiZgwYcKYeYn4wx/+MJ773OfGwoULY/LkybH77rvHkUceGV/84he3dtEGddppp8Vxxx0XixYtioj/efld+mv75fhrX/vamDBhQjz/+c+v/W/x4sW2DH/zN3/TMd2b3vSmuOGGG+Lyyy9vtWwY/XbY2gUAAADA+PDNb34zjj766Jg0aVK88pWvjCc+8Ynx8MMPxw9/+MN429veFv/5n/8Zn/70p7d2MUfMhz70oXjb294Whx56aJx66qkxZcqU+P3vfx/f+c534pJLLhnyZeo73/nOeMc73jGCpf2jK664In7729/GiSeeGBERf/mXfxmve93r4sMf/nC8/OUvjyc84Qmbp7399tvj7LPPjqOPPjqOOOKInte96667xjnnnNMxbpdddhl0+jvvvDPe9773xdSpU+3/TzjhhHjHO94RX/ziF+PVr351z+UDAERcfPHFsXjx4vjpT38av//972OvvfZqtJxFixbFhg0bYscdd2y5hP/jq1/9arz0pS+NfffdN04++eTo7++PW2+9Nb7//e/HZz7zmXjZy1426LyveMUr4thjj41JkyYNW/mcX/3qV/Gd73wnfvzjH28e9/SnPz0uuugiO/1dd90Vp556aixevDjmzZvXWjmuv/76uOCCC2Ly5MmDTrPvvvvGW97ylo5xj3vc4zqG58+fHy984QvjQx/6ULzgBS9orXwY/XjhDAAAgJ7deuutceyxx8aiRYvimmuuiQULFmz+39/+7d/G73//+55bwUZEVFUVDz74YOy00049L2s4Pfroo/Hud787li5dGt/+9rdr/7///vuHnH+HHXaIHXYY+Z/q559/fhx88MGxcOHCzePe//73xze+8Y143eteFz/4wQ82h/o46aSTYscdd4zzzjuvlXXPmDEjXv7yl6enf+tb3xpPfepT47HHHotly5bV/j9z5sw47LDD4oILLuCFMwC04NZbb40f//jHcemll8brXve6uPjii+OMM85otKwJEyYM+TKzDWeeeWbss88+8e///u8xceLEjv+V7sPbb799bL/99sNZPOv888+P3XffPZ761KduHrfHHnvEHnvsUZv2sccei2c+85mxww47xJe+9KWYMmVKK2Woqire+MY3xitf+cr47ne/O+h0CxcuTN23jznmmDj66KPjlltusduB8YmQGgAAAOjZBz/4wVi7dm388z//c8fL5k322muvOPnkkzcPb3ohu+eee8akSZNi8eLF8fd///fx0EMPdcy3ePHieP7znx9XXXVVPPnJT46ddtop/umf/ikiIm655ZY4+uijY9asWTFlypR46lOfWnup/b3vfS8mTJgQX/nKV+K9731v7LrrrjF58uR41rOeFb///e87pv3BD34QRx99dOy+++4xadKk2G233eLNb35zo1Agy5Yti9WrV8fBBx9s/19qhTRYDOcvfOEL8ZSnPCWmTJkS/f398fSnP732QvvKK6+MQw45JKZOnRrTp0+PI444Iv7zP/+zWOYHH3wwvvWtb8Wzn/3sjvEzZsyI8847L370ox/FZz/72YiIuOyyy+KKK66I97///XZ/N/Xoo4+mYkd///vfj3/5l3+Jc889d8jpli5dGj/84Q9jxYoVLZUQALZdF198cfT398cRRxwRL3nJS+Liiy+uTXPGGWfEdtttV3tReeKJJ8bEiRPjhhtuiAgfw/k//uM/4vjjj98clmv+/Pnx6le/OpYvX96ovDfffHMccMABtZfNEeX78GAxnK+88so49NBDY/r06dHX1xcHHHBALTzHT37yk3jOc54TM2bMiClTpsShhx4aP/rRj1Jl/vrXvx7PfOYzU3kczjrrrPj+978f73nPe1oNcXLRRRfFb37zm3jve99bnPbhhx+OdevWDTnNpt8V3/jGN1opH8YGXjgDAACgZ1dccUXssccecdBBB6Wmf81rXhOnn356POlJT4qPfvSjceihh8Y555wTxx57bG3a3/72t3HcccfF0qVL47zzzot999037rvvvjjooIPiqquuije84Q2bY/W+4AUviMsuu6y2jPe///1x2WWXxVvf+tY49dRT49///d/jf/2v/9UxzVe/+tVYv359vP71r4+Pfexjcfjhh8fHPvaxeOUrX9l1fcybNy922mmnuOKKK1p72XnWWWfFK17xithxxx3j7LPPjrPOOit22223uOaaazZPc9FFF8URRxwR06ZNiw984APxrne9K2688cZ42tOeVozt+POf/zwefvjheNKTnlT736awGaecckrccsstcfLJJ8dBBx0Ur3vd6zqmW7t2bSxbtqz4t2rVqto6fve7321+ST5//vx417veFY888khtusceeyxOOumkeM1rXhN/9md/NuQ27b///lFVVUfXZABAMxdffHG8+MUvjokTJ8Zxxx0XN910U/zsZz/rmOad73xn7LvvvvH//X//X6xZsyYiIq666qr4zGc+E6effnr8xV/8xaDLv/rqq+OWW26JE044IT72sY/FscceG5dcckk873nPi6qqui7vokWL4rvf/W7ceeedXc/rXHDBBXHEEUfEihUr4tRTT433v//9se+++3bkZbjmmmvi6U9/eqxevTrOOOOMeN/73hcDAwPxzGc+M376058Oufy77ror7rjjDnsfVtdcc028973vjcMPPzze9ra3dfzvkUceSd2Lly1bFhs3buyYd82aNXHKKafE3//938f8+fOLZZgyZUpMmzYtFi9ePGiPpxkzZsSee+6ZfumOcaICAAAAerBq1aoqIqoXvvCFqel/9atfVRFRveY1r+kY/9a3vrWKiOqaa67ZPG7RokVVRFTf+ta3OqZ905veVEVE9YMf/GDzuDVr1lRLliypFi9eXD322GNVVVXVtddeW0VE9fjHP7566KGHNk973nnnVRFR/frXv948bv369bWynnPOOdWECROq22+/ffO4M844o8r8jD799NOriKimTp1aPfe5z63e+973Vj//+c9r0916661VRFTnn3/+oOu46aabqu2226560YtetHnbNtm4cePm7Z85c2b12te+tuP/9957bzVjxozaePXZz362Vidbuu2226qpU6dWs2bNqnbccUc73ate9aoqIop/hx56aMd8r371q6szzzyz+trXvlZ9/vOfr17wghdUEVEdc8wxtXV8/OMfr2bMmFHdf//9VVVV1aGHHlo94QlPsGW+++67q4ioPvCBDwy57QCAoV1//fVVRFRXX311VVV/vPfsuuuu1cknn1yb9te//nU1ceLE6jWveU21cuXKauHChdWTn/zk6pFHHtk8jbv3ufvwl770pSoiqu9///ubx51//vlVRFS33nrrkGX+53/+5yoiqokTJ1bPeMYzqne9613VD37wg9p9tKqqKiKqM844Y9B1DAwMVNOnT68OPPDAasOGDR3zbroPb9y4sfqTP/mT6vDDD988btN2LVmypFq6dOmQ5f3Od75TRUR1xRVXDDndfffdVy1YsKCaP39+dd9999X+v+m3T+ZP6/Ctb31rtWTJkurBBx+squqPv8OOOOKI2jqOPPLI6gMf+ED19a9/vfrnf/7n6pBDDqkionr7299uy3zYYYdVj3/844fcLowvxHAGAABAT1avXh0REdOnT09N/2//9m8REfF3f/d3HePf8pa3xIc+9KH45je/Gc94xjM2j1+yZEkcfvjhtWU85SlPiac97Wmbx02bNi1OPPHEOPXUU+PGG2+MJz7xiZv/d8IJJ3R0qT3kkEMi4o9hOTZNt2Vc6HXr1sWGDRvioIMOiqqq4pe//GXsvvvuqe3b5Kyzzoq99947PvGJT8RVV10VV155ZZx22mmx3377xcUXXxyPf/zj08v6+te/Hhs3bozTTz89ttuus5Pipm63V199dQwMDMRxxx3XEdN4++23jwMPPDCuvfbaIdexqctyf3+//f+iRYvijDPOiLe//e1xyimndNTvJm9/+9tT8Rx1Hf/8z//cMfyKV7wiTjzxxPjMZz4Tb37zmzfHsly+fHmcfvrp8a53vSvmzp2bXo+L8QwAyLv44otj55133nx/njBhQrz0pS+NL3zhC/HhD3+4I97xE5/4xDjrrLPi1FNPjf/4j/+IZcuWxbe//e1iboIt78MPPvhgrF27dvP1/xe/+MXme3fWq1/96li4cGF85CMfiWuvvTauvfbaePe73x177LFHXHTRReleWRF/vMeuWbMm3vGOd9RiT2+6D//qV7+Km266Kd75znfWwoA861nPiosuuig2btxYu49vUroPR/wxvvIrX/nKuO++++Kqq66yoUH+4i/+Iq6++urUdm3Zivl3v/tdnHfeefGlL32pmCzx8ssv7xg+4YQT4rnPfW585CMfiZNOOil23XXXjv/39/fHL3/5y1SZMD7wwhkAAAA96evri4jY3HW25Pbbb4/tttuultl+/vz5MXPmzLj99ts7xi9ZssQuw8Ur3PQS9/bbb+94Iaovizc9zK1cuXLzuDvuuCNOP/30uPzyyzvGR4QNAZFx3HHHxXHHHRerV6+On/zkJ3HBBRfEF7/4xTjyyCPjN7/5TTph0s033xzbbbdd7LPPPoNOc9NNN0VExDOf+Uz7/037qaQaotvyAQccEBERT37yk+3/99lnnyHL2I23vOUt8ZnPfCa+853vbH7h8M53vjNmzZoVJ510UmoZm7YlEwsTAOA99thjcckll8QznvGMuPXWWzePP/DAA+PDH/5wfPe7343DDjusY563ve1tcckll8RPf/rTeN/73pe6N6xYsSLOOuusuOSSS2pJ/Zrehw8//PA4/PDDY/369fHzn/88vvzlL8enPvWpeP7znx///d//XYzlvMnNN98cEWE/tm6y6T78qle9atBpVq1aNeQL5Yih78Mf+MAH4qqrropTTz21lnNhk/7+/kH/N5RN4bL++q//uut5J0yYEG9+85vjqquuiu9973u1j89VVXEv3sbwwhkAAAA96evri1122SV+85vfdDVf9sFjyxZPTQ2WaX7TQ91jjz0WS5cujRUrVsQpp5wSe++9d0ydOjXuuuuuOP7442sxDrvV19cXS5cujaVLl8aOO+4YF154YfzkJz+JQw89tKflbmlTGS+66CIbd7HUsmz27NkR8ceX8NoyKWvVqlWpJIsTJ06MWbNmDTnNbrvtFhGxOQb2TTfdFJ/+9Kfj3HPPjbvvvnvzdA8++GA88sgjcdttt0VfX1/Hcjd9OJgzZ07X2wIA+KNrrrkm7rnnnrjkkkvikksuqf3/4osvrr1wvuWWWza/gP31r3+dWs8xxxwTP/7xj+Ntb3tb7LvvvjFt2rTYuHFjPOc5z+n5PjxlypQ45JBD4pBDDok5c+bEWWedFVdeeeWQL4e7tamM//AP/xD77ruvnWbatGmDzr/lfdi57rrr4l3velccdNBBcfbZZw+6nIcffjidP2Lu3Lmx/fbbxzXXXBPf+ta34tJLL+3I+fDoo4/Ghg0b4rbbbotZs2YN+fFa79tbWrlyJffibQwvnAEAANCz5z//+fHpT386rrvuuvjLv/zLIaddtGhRbNy4MW666aaOsBL33XdfDAwMxKJFi4rrW7RoUfz2t7+tjf/v//7vzf/vxq9//ev43e9+FxdeeGFHksBsl9RuPPnJT44LL7ww7rnnnvQ8e+65Z2zcuDFuvPHGQR9i99xzz4j4Y8LCJi2b9t5774iIuPXWW4vJ+AZz8sknx4UXXlic7tBDD43vfe97Q05zyy23RERsDp1x1113xcaNG+ONb3xjvPGNb6xNv2TJkjj55JPj3HPP3TxuU0u8bsKXAAA6XXzxxTFv3rz4x3/8x9r/Lr300rjsssviU5/61OYPxBs3bozjjz8++vr64k1velO8733vi5e85CXx4he/eNB1rFy5Mr773e/GWWedFaeffvrm8ZteWrdpUy+dbu/DERG/+c1vaj20dJq+vr6e78Nq5cqVceyxx8a0adPii1/84pAfkX/84x93hCYbyq233hqLFy+OO+64IyLC7qO77rorlixZEh/96EfjTW9606DL0vu2rmeohJEYf3jhDAAAgJ69/e1vj4svvjhe85rXxDXXXBM777xzx/9vvvnm+Nd//dc4+eST43nPe178/d//fZx77rnxT//0T5un+chHPhIREUcccURxfc973vPi3HPP7XjBvW7duvj0pz8dixcv7jqsw6YW0Ft2Y62qatCM6yXr16+PG264wb58v/LKKyMi4k//9E/TyzvqqKPilFNOibPPPjv+5V/+pSP+46Zuqocffnj09fXF+973vnjGM54RO+64Y8cyHnjggSHjHu+///4xceLEuP766+MFL3hBumxbahLDefXq1TFp0qSOeJFVVcV73vOeiIjN8buf+MQnxmWXXVZb1jvf+c5Ys2ZNnHfeeZsf9jf5+c9/HhMmTCh+BAEAeBs2bIhLL700jj766HjJS15S+/8uu+wSX/rSl+Lyyy+Pl770pRHxx/v5j3/847j88svjiCOOiO9973vx+te/Pp7+9KcP2srV3YcjouMjYre++93vxrOe9aza+E25JLq5Dx922GExffr0OOecc+I5z3lOR0isTffh/fffP/bcc8/40Ic+FC972ctqrZlL9+GFCxfGbrvtFtdff33tf69+9avjjjvuiK997WvFj+pNYjg/85nPtPfYE088MRYtWhSnnXba5o/RK1asiBkzZnT0HnvkkUfi/e9/f0ycOLH2snvVqlVx8803x+tf//pUmTA+8MIZAAAAPdtzzz3ji1/8Yrz0pS+Nxz/+8fHKV74ynvjEJ8bDDz8cP/7xj+OrX/1qHH/88RHxxwehV73qVfHpT386BgYG4tBDD42f/vSnceGFF8ZRRx2VapXzjne8I770pS/Fc5/73HjjG98Ys2bNigsvvDBuvfXW+NrXvjZoQp7B7L333rHnnnvGW9/61rjrrruir68vvva1rw3arbVk/fr1cdBBB8VTn/rUeM5znhO77bZbDAwMxNe//vX4wQ9+EEcddVTst99+6eXttddecdppp8W73/3uOOSQQ+LFL35xTJo0KX72s5/FLrvsEuecc0709fXFJz/5yXjFK14RT3rSk+LYY4+NuXPnxh133BHf/OY34+CDD46Pf/zjg65j8uTJcdhhh8V3vvOdIbvqDqVJDOdf/OIXm2Nd77XXXrFhw4a47LLL4kc/+lGceOKJ8aQnPSki/hgW46ijjqrNv+llhPvf1VdfHQcffPDmbsoAgO5cfvnlsWbNmkE/RD71qU+NuXPnxsUXXxwvfelL47/+67/iXe96Vxx//PFx5JFHRkTEBRdcEPvuu2+84Q1viK985St2OX19ffH0pz89PvjBD8YjjzwSCxcujG9/+9u2tW/WC1/4wliyZEkceeSRseeee8a6deviO9/5TlxxxRVxwAEHbC5fRl9fX3z0ox+N17zmNXHAAQfEy172sujv748bbrgh1q9fHxdeeGFst9128dnPfjae+9znxhOe8IQ44YQTYuHChXHXXXfFtddeG319fXHFFVcUy3zZZZd1xDz+1Kc+FV//+tfjz//8z2P9+vXxhS98wc67dOnS2HnnnRvFcN59991tcuQ3velNsfPOO3fcYy+//PJ4z3veEy95yUtiyZIlsWLFivjiF78Yv/nNb+J973tfLazXd77znaiqKl74whd2VSaMcRUAAADQkt/97nfVa1/72mrx4sXVxIkTq+nTp1cHH3xw9bGPfax68MEHN0/3yCOPVGeddVa1ZMmSascdd6x222236tRTT+2YpqqqatGiRdURRxxh13XzzTdXL3nJS6qZM2dWkydPrp7ylKdU//qv/9oxzbXXXltFRPXVr361Y/ytt95aRUR1/vnnbx534403Vs9+9rOradOmVXPmzKle+9rXVjfccENtujPOOKMq/Yx+5JFHqs985jPVUUcdVS1atKiaNGlSNWXKlGq//far/uEf/qF66KGHhizLYOv43Oc+V+23337VpEmTqv7+/urQQw+trr766to2H3744dWMGTOqyZMnV3vuuWd1/PHHV9dff/2QZa6qqrr00kurCRMmVHfccYf9/2D12YtbbrmlOvroo6vFixdXkydPrqZMmVLtv//+1ac+9alq48aNxfkPPfTQ6glPeEJt/MDAQDVx4sTqs5/9bGtlBYBtzZFHHllNnjy5Wrdu3aDTHH/88dWOO+5YLVu2rDrggAOqXXfdtRoYGOiY5rzzzqsiovryl79cVZW/9915553Vi170omrmzJnVjBkzqqOPPrq6++67q4iozjjjjM3TnX/++VVEVLfeeuuQZf/Sl75UHXvssdWee+5Z7bTTTtXkyZOrffbZpzrttNOq1atXd0ybXcfll19eHXTQQdVOO+1U9fX1VU95ylOqL33pSx3T/PKXv6xe/OIXV7Nnz64mTZpULVq0qDrmmGOq7373u0OWt6qq6he/+EUVEdUPfvCDzeNe9apXVRFR/Lv22muLy++W+x12/fXXV0ceeWS1cOHCauLEidW0adOqpz3tadVXvvIVu4yXvvSl1dOe9rTWy4bRbUJVDZH+EgAAAMA247HHHot99tknjjnmmHj3u9+9tYvTk3PPPTc++MEPxs0339xK4kkAAEbCs571rNhll13ioosu2tpF6dm9994bS5YsiUsuuYQWztsYXjgDAAAA2OzLX/5yvP71r4877rijFn9yrHjkkUdizz33jHe84x3xhje8YWsXBwCAtJ/85CdxyCGHxE033dR1EuTR5h3veEdcc8018dOf/nRrFwUjjBfOAAAAAAAAAIBWdJdNBQAAAAAAAACAQfDCGQAAAAAAAADQCl44AwAAAAAAAABawQtnAAAAAAAAAEAreOEMAAAAAAAAAGjFDlu7AAAAYHSaMGHC1i4CAAAjrqqqrV2EcYXfE2jTSBxPXAOAoWXOEVo4A1v43ve+FxMmTIjvfe97I7K+M888s9Ub5m233RYTJkyICy64YNjW0Y2vfOUrMWvWrFi7du1WWX+bjj322DjmmGO2djEAAAAAAABGNV44Y1T69a9/HS95yUti0aJFMXny5Fi4cGEsXbo0Pvaxj414Wb74xS/GueeeWxt/9913x5lnnhm/+tWvRqQcV1xxRRx66KExb968mDJlSuyxxx5xzDHHxLe+9a0RWX+3HnvssTjjjDPipJNOimnTpkVExI033hgTJ06ME044oTb9wMBALFiwIA488MDYuHFjq2VZunRpTJgwIf73//7ftf9NmDDB/r3//e/vmO6UU06Jr33ta3HDDTe0WjYAAAAAAIDxhBfOGHV+/OMfx5Of/OS44YYb4rWvfW18/OMfj9e85jWx3XbbxXnnnTes6376058eGzZsiKc//embxw31wvmss84akRfOH/rQh+IFL3hBTJgwIU499dT46Ec/Gn/9138dN910U1xyySVDzvvOd74zNmzYMOxlVFdccUX89re/jRNPPHHzuH322Sfe9ra3xQUXXBD/9//+347p3/GOd8QDDzwQ//RP/xTbbdfepenSSy+N6667bshpli5dGhdddFHH35FHHtkxzX777RdPfvKT48Mf/nBrZQMAAAAAABhviOGMUee9731vzJgxI372s5/FzJkzO/53//33D+u6t9tuu5g8efKwrqNbjz76aLz73e+OpUuXxre//e3a/0t1ssMOO8QOO4z8qX7++efHwQcfHAsXLuwY/653vSu+/OUvx+te97r4j//4j5g4cWJcd9118elPfzre/OY3x7777ttaGR588MF4y1veEqecckqcfvrpg073uMc9Ll7+8pcXl3fMMcfEGWecEZ/4xCc2t9oGAAAAALRjNMT8HukyEDMa4xEtnDHq3HzzzfGEJzyh9rI5ImLevHkdw+eff34885nPjHnz5sWkSZNin332iU9+8pO1+TZu3Bhnnnlm7LLLLjFlypR4xjOeETfeeGMsXrw4jj/++M3TaQznv/qrv4pvfvObcfvtt28OtbB48eL43ve+FwcccEBERJxwwgmb/7cpdvIPfvCDOProo2P33XePSZMmxW677RZvfvObG7U0XrZsWaxevToOPvhg+3+tEzVYDOcvfOEL8ZSnPCWmTJkS/f398fSnP732QvvKK6+MQw45JKZOnRrTp0+PI444Iv7zP/+zWOYHH3wwvvWtb8Wzn/3s2v8mT54cn/zkJ+O3v/1tnHPOOfHII4/EiSeeGLvttlucffbZxWV344Mf/GBs3Lgx3vrWtxan3bBhQzz44INDTrN06dJYt25dXH311W0VEQAAAAAAYFyhhTNGnUWLFsV1110Xv/nNb+KJT3zikNN+8pOfjCc84Qnxghe8IHbYYYe44oor4g1veENs3Lgx/vZv/3bzdKeeemp88IMfjCOPPDIOP/zwuOGGG+Lwww8vvmA87bTTYtWqVXHnnXfGRz/60YiImDZtWjz+8Y+Ps88+O04//fQ48cQT45BDDomIiIMOOigiIr761a/G+vXr4/Wvf33Mnj07fvrTn8bHPvaxuPPOO+OrX/1qV/Uxb9682GmnneKKK66Ik046KWbNmtXV/M5ZZ50VZ555Zhx00EFx9tlnx8SJE+MnP/lJXHPNNXHYYYdFRMRFF10Ur3rVq+Lwww+PD3zgA7F+/fr45Cc/GU972tPil7/8ZSxevHjQ5f/85z+Phx9+OJ70pCfZ/y9dujSOO+64OOecc+Luu++O3/zmN/GNb3wjpk6d2jHdQw89FGvWrElt05w5czqG77jjjnj/+98fn/vc52KnnXYact4LLrggPvGJT0RVVfH4xz8+3vnOd8bLXvay2nT77LNP7LTTTvGjH/0oXvSiF6XKBQAAAAAAsE2pgFHm29/+drX99ttX22+/ffWXf/mX1dvf/vbqqquuqh5++OHatOvXr6+NO/zww6s99thj8/C9995b7bDDDtVRRx3VMd2ZZ55ZRUT1qle9avO4a6+9toqI6tprr9087ogjjqgWLVpUW8/PfvazKiKq888/P1Wuc845p5owYUJ1++23bx53xhlnVJnT8PTTT68iopo6dWr13Oc+t3rve99b/fznP69Nd+utt9bKpOu46aabqu2226560YteVD322GMd82/cuLGqqqpas2ZNNXPmzOq1r31tx//vvffeasaMGbXx6rOf/WwVEdWvf/3rQae59957q/7+/ioiavtmk/PPP7+KiNSfeslLXlIddNBBm4cjovrbv/3b2nQHHXRQde6551bf+MY3qk9+8pPVE5/4xCoiqk984hO2TI973OOq5z73uUNuPzBeZM8//vjjjz/++BtPf2jX1t6f/I2tvwkTJmxzf1u7zvnjr9u/DFo4Y9RZunRpXHfddXHOOefEVVddFdddd1188IMfjLlz58ZnP/vZeMELXrB52i1brq5atSoeeeSROPTQQ+Oqq66KVatWxYwZM+K73/1uPProo/GGN7yhYz0nnXRSnHnmmcOyDVuWa926dbFhw4Y46KCDoqqq+OUvfxm77757V8s766yzYu+9945PfOITcdVVV8WVV14Zp512Wuy3335x8cUXx+Mf//j0sr7+9a/Hxo0b4/TTT68l59sUeuPqq6+OgYGBOO6442LZsmWb/7/99tvHgQceGNdee+2Q61i+fHlERPT39w86zZQpU2LKlCmxcuXKza2q1eGHH94ofMW1114bX/va1+InP/lJcdof/ehHHcOvfvWrY//994+///u/j+OPP77WOrq/v7+jTgAAAAAAOd3GRx4NMZ2HW2Ybqx7jPPc6P9AtXjhjVDrggAPi0ksvjYcffjhuuOGGuOyyy+KjH/1ovOQlL4lf/epXsc8++0TEH18WnnHGGXHdddfF+vXrO5ax6YXz7bffHhERe+21V8f/Z82aNeQL0V7ccccdcfrpp8fll18eK1eurJWrieOOOy6OO+64WL16dfzkJz+JCy64IL74xS/GkUceGb/5zW/SyQ5vvvnm2G677TbXoXPTTTdFRMQzn/lM+/++vr7Uuoa6qZ122mlx7733xuMf//g444wz4thjj63tjwULFsSCBQtS69rk0UcfjTe+8Y3xile8YnOc7W5MnDgx/vf//t/xN3/zN/Hzn/88nva0p3X8v6qqbeJHDwAAAAAAQBO8cMaoNnHixDjggAPigAMOiMc97nFxwgknxFe/+tU444wz4uabb45nPetZsffee8dHPvKR2G233WLixInxb//2b/HRj340Nm7cuFXK/Nhjj8XSpUtjxYoVccopp8Tee+8dU6dOjbvuuiuOP/74nsvV19cXS5cujaVLl8aOO+4YF154YfzkJz+JQw89tKUtiM1lvOiii2L+/Pm1/++ww9CXjtmzZ0dExMqVK2PXXXet/f/666+Pf/zHf4w3vvGNccIJJ8T+++8fp5xySnz605/umG7Dhg3pF/Sbyvn5z38+fvvb38Y//dM/xW233dYxzZo1a+K2226LefPmxZQpUwZd1m677RYREStWrKj9b+XKlfEnf/InqTIBAAAAAABsa3jhjDHjyU9+ckRE3HPPPRERccUVV8RDDz0Ul19+eUeICg33sGjRooiI+P3vfx9LlizZPH758uW11sfOYK1ZBxv/61//On73u9/FhRdeGK985Ss3j28SGqLkyU9+clx44YWb6yRjzz33jI0bN8aNN94Y++6776DTRPwxYeGzn/3srsu19957R0TErbfeGn/2Z3/W8b/HHnssTjzxxNhll13i7LPPjunTp8fJJ58cH/nIR+KEE06Iv/zLv9w87Ze//OU44YQTUuvc1Jr6jjvuiEceeSQOPvjg2jSf//zn4/Of/3xcdtllcdRRRw26rFtuuSUiIubOndsx/tFHH40//OEPHWFdAAAAAAAA8D944YxR59prr42/+qu/qr3Q/bd/+7eIiPjTP/3TiPhjPOGIzrANq1ativPPP79jvmc961mxww47xCc/+clYunTp5vEf//jHU+WZOnWqbWU7derUiIgYGBjoGO/KVVVVnHfeean1qfXr18cNN9zQ8SJ2kyuvvDIi/qdOMo466qg45ZRT4uyzz45/+Zd/6YjjvClcxOGHHx59fX3xvve9L57xjGfEjjvu2LGMBx54oPYydkv7779/TJw4Ma6//vray9n/83/+T/zyl7+MSy+9NKZPnx4Rf4xR/ZWvfGVzGItNLaibxHA+9thj7Yv0F73oRfG85z0vXvva18aBBx446HasWbMmzj333JgzZ07sv//+Hf+78cYb48EHH4yDDjqoqzIBAAAAwHjXJPRgaZ6xEPO57XVm4i2XptH/axm7nR/oFi+cMeqcdNJJsX79+njRi14Ue++9dzz88MPx4x//OL785S/H4sWLN7d4Peyww2LixIlx5JFHxute97pYu3ZtfOYzn4l58+Z1tPjdeeed4+STT44Pf/jD8YIXvCCe85znxA033BBXXnllzJkzp3hz2H///ePLX/5y/N3f/V0ccMABMW3atDjyyCNjzz33jJkzZ8anPvWpmD59ekydOjUOPPDA2HvvvWPPPfeMt771rXHXXXdFX19ffO1rX0u1pnbWr18fBx10UDz1qU+N5zznObHbbrvFwMBAfP3rX48f/OAHcdRRR8V+++2XXt5ee+0Vp512Wrz73e+OQw45JF784hfHpEmT4mc/+1nssssucc4550RfX1988pOfjFe84hXxpCc9KY499tiYO3du3HHHHfHNb34zDj744CFf2E+ePDkOO+yw+M53vhNnn3325vF/+MMf4vTTT48jjzwyXvSiF20eP3Xq1DjvvPPixS9+cZx33nnxlre8JSKaxXDee++9N7ewVkuWLOlo2fyP//iP8fWvfz2OPPLI2H333eOee+6Jz33uc3HHHXfERRddFBMnTuyY/+qrr44pU6Z0fLgAAAAAAADAFipglLnyyiurV7/61dXee+9dTZs2rZo4cWK11157VSeddFJ13333dUx7+eWXV3/+539eTZ48uVq8eHH1gQ98oPrc5z5XRUR16623bp7u0Ucfrd71rndV8+fPr3baaafqmc98ZvVf//Vf1ezZs6u/+Zu/2TzdtddeW0VEde21124et3bt2uplL3tZNXPmzCoiqkWLFm3+3ze+8Y1qn332qXbYYYcqIqrzzz+/qqqquvHGG6tnP/vZ1bRp06o5c+ZUr33ta6sbbrihY5qqqqozzjijKp2GjzzySPWZz3ymOuqoo6pFixZVkyZNqqZMmVLtt99+1T/8wz9UDz300OZpb7311vQ6Pve5z1X77bdfNWnSpKq/v7869NBDq6uvvrpjmmuvvbY6/PDDqxkzZlSTJ0+u9txzz+r444+vrr/++iHLXFVVdemll1YTJkyo7rjjjs3jXvjCF1ZTp06tbr/9djvP85///GratGkd87QlIqq//du/7Rj37W9/u1q6dGk1f/78ascdd6xmzpxZHXbYYdV3v/tdu4wDDzywevnLX9562YDRKiL4448//vjjb5v7Q7u29v7kb+T+JkyY0PXfdtttN+Tf9ttv39XfDjvsMOJ/O+64Y6t/mXWW6qFUr6X9srWPJf5G91/GhP93AwC2OQMDA9Hf3x/vec974rTTTtvaxRl3Hnvssdhnn33imGOOiXe/+91buzg9+9WvfhVPetKT4he/+MWgsa+B8WZrdEkEAGBr4xG5Xfye2HYQUqMdmWtQaZrh/j+2bZnjgxfO2CZs2LAhdtppp45xZ555Zpx11lnxwx/+0CaYQ+++/OUvx+tf//q44447Ytq0aVu7OD059thjY+PGjfGVr3xlaxcFGDE8IAIAtkU8IreL3xPjRxsvh3WaXpc5Go6vkShjty+Iex3OrJ9r5baLF87A/3PBBRfEBRdcEM973vNi2rRp8cMf/jC+9KUvxWGHHRZXXXXV1i4eAIxKo+EHPAAAI41H5Hbxe2L84IVzszLwwhnjTWbfkzQQ24Q///M/jx122CE++MEPxurVqzcnEnzPe96ztYsGAAAAAAAAjBu0cAYAANZoaDECAMBI4xG5XfyeGD9o4dysDLRwxniT2ffbjUA5AAAAAAAAAADbAEJqAAAAAAAAoEOpNXKTlr3Dscy29dpyt9dtbKLXFssbN27senm9tprG+EYLZwAAAAAAAABAK3jhDAAAAAAAAABoRTqkxmgIxA4AwLaGrmgAAAAAgLGEGM4AAAAAAADbuG5jDzeJVdzGMnrRpDHHSDcAyWxzaZpuYzhvt11nAIRSTOfMNPr/bsuIsY2QGgAAAAAAAACAVvDCGQAAAAAAAADQCl44AwAAAAAAAABaQQxnAAAAAACAcW64YzQ3ib880jGc3fI0lrBOo/8vDZeWnylTk2m6mb60jfp/F4+5NE1mGUOVAWMbL5wBAACAUWLatGkdw+7h67HHHkstSxMADTbOcevNjnMPuW69a9euTZUFAAAAYwshNQAAAAAAAAAAreCFMwAAAAAAAACgFYTUAAAAAAAAGGdGQ4zmtstUWl63/3e6jdncbezhkYhb3XaZMuvoNaZz2/WMrYsXzgAAANgq+vv7a+P0YcIlmMmOy8YXdrLxih23Djdu++23L07ntsvN10u85mzdZevd2WGH+mNHX19fbZzbNuViWLtxjz76aGq6XrYLAAAAdYTUAAAAAAAAAAC0ghfOAAAAAAAAAIBWEFIDAAAAAABgDMmEiNJpNNTScMQO7rZM3Zax1/873cYOLsUeLmkSw1nH9VrGUplL8ZkzZer2/1rmUngrYjqPbrRwBgAAAAAAAAC0ghbOAAAA41Q2eZ1LLueSt7lxLhlcNqmdK0umtYpr8ZLdrmw5mpatm3Vkk/oNdzkcl3Dv4YcfTk2XTcKXSeqXPTaz+/qRRx5JlcMZa4kEezmGe0muCQAAQAtnAAAAAAAAAEAraOEMAAAAAAAwirUR93e4YzaX4im7cdprpdth7WlViuHsemboOO1to8Pdxhou1UtpG90ySmXW3jul4TbiJZeOp26PxyYxnul5M3rQwhkAAAAAAAAA0ApeOAMAAAAAAAAAWkFIDQAAgDFmuLvARvjunDvuuGNtXC/JADNdIbWL6GBcOVxCw2yiPldet11uHdl6cusodeON6C1RX/bYyc7bdoJIXW92P2TX6crbS/fbTNfsXvSSvK/t7QIAAMjihTMAAAAAAMAo0m182+yHt+EsUyYWsX6U1eGJEycOOTxp0qQh53cfgrfkPto+8sgjHcMPPfTQkPPo9PpxuFQvug2TJ0/uGHYfrnW79MOglunBBx8ccnjDhg0dww8//HDHsG5T5kOkTjPcMZ2dzIdrjAxCagAAAAAAAAAAWsELZwAAAAAAAABAK3jhDAAAAAAAAABoBTGcAQAARrFs/MVsIrVscj0XP9DFYnR6iZdXinvY6/KdrVVPLiGgblsvif9GImlc9rhzMkkjM4kVB5suK1tet63ZZI291GfT+YhbCYwtvcZsdteB0jWldJ0orVPvd3pP1FjFEfV4xVOnTu0YnjZtWsfwlClThhzWGM9aJr1naKziiIj169d3DK9bt27IYY2HrDGetd60zNOnT+8YnjFjxpD/j6hvp9IyaZlXrVo15PCaNWs6hjXGs8aIjijHS+72+Cr9BmxyjySm89bDC2dgnNAbc0Tu4qo/Gtr44RJRv4EBAAAAAABg/COkBgAAAAAAAACgFbxwBgAAAAAAAAC0gpAaAAAAAAAAI6jXmM3Z+PO9lEFj6GouA40rXIrPHBHR19fXMdzf398xPGvWrI7hmTNnDrlMl0thSxp7WGMbR0QMDAwMOazbrfWkMZy1XnSbZ8+e3TE8d+7cIf8fUQ+hqfv/oYce6hjWbVi+fHnH8P33398x/MADDww5v8a5duvUeNkup8GWNORnt+dAE8R0Hjm8cAYAABhFSj+2I/wPbpeorpdxvSR+c0ndnMx2ZJMGZvIUROQT/7lERy5hj5vX7TN9GI2oJ/iJKD+cRbSfDDCbr2EkkhVmlpWpo8G4bcieE9myuOM/m+iQB18AADAe8MIZKZmHX32A0wewzA939zA2mr5AZdbd7ZfqiPYS9ZWWm3mw0S/ATetbH9QzXydLWY8dLZ97oNNjKJNRPjMPD4UAAAAAAACdiOEMAAAAAAAAAGgFL5wBAAAAAAAAAK0gpAYAAAAAAMBW1G2SwEzIxVJStlJIw1JSwJ122qljWBP6TZ8+vVYmTZC38847dwzPmzevY1iTCuo6dRs0xKLmS1izZk2tTLpdpUSE6uGHH+4Y1vCSmgRw/vz5Qw7PmTOntg5NPKghTTU0pm6nlkGXN2XKlI5h3QZNOhhRT8Coda1l6jZcKkkEx7ZR98LZXTTZ4cOrSYzhTHIVXU4mqUomTm4mO6/Ok1luph6ayFwU9WbhEhrpfJkLo45rOk1pnsw0mfVkjoc2YllnjvEm9Zs5znpJdARg/MnE7G87QaBbXi/J4LIx7rP5CTL3ecctyz0w6kNlRP0hK6KeDX6w6dw9Wx+wIuoPZRG+7ty8KpMHoRvZ/e/Km8m/Mdi4TFlGIlFhL8dYLzLJNXvZLp6rAADA1kJIDQAAAAAAAABAK3jhDAAAAAAAAABoxagLqQEAAAAAADCedBujuUnMZlVapsZo1ri9GpNZw01pjGYdnjlzZq1M3cZw1ljDGi5LQzZpaKoNGzZ0DLtwY0rDRT300END/l/Da2kILq2HWbNmdQxrnGrd5oj6vtB16vGh+0qXqf/XkGN6bLgQYhrXWetWYzprrGsNLVUKw5kJO6fTNAn12c3/MThaOAMAAAAAAAAAWjHqWjjz9WDk6Rcg9+VKvyJmkqs0SUaX0SRRm6Nf30rDg43rlltG5uuhbpN+DXSJZ7Ru2kpq1+TLopZPv25G1L9Gt3XMZBJQaXkz+zpTd6WEQJlkhADGh2zSvMw1NptIMJsgMJvQLXvNyiQDjPBl1ntgdrvcdC7Jn2s1pC2LIuqtjyJ8IkHHJQhctmxZbZxLEFhq/RPhfye47c/uhyxXFnc/d+OyyQWb6uV+2maSy16RSBAAAIwHtHAGAAAAAAAAALRi1LVwBgAAAAAAGMu0R0G3w72uL6Le+6UUo1l7AZViD+v/Z8yYMeRwRL1XkS5Ty6CxhVWpZ5D21nbL0x5RWi/6//Xr13cMa2+XbmNf6/K1zBHl3rXa+6m0DTvttFPHsPa6zvTC1mlWrFjRMbxmzZqOYe0BVoqN3aQHju4LV+6h1qH1Si+g5mjhDAAAAAAAAABoBS2cx5kmX00z8W2bxPltEsM5E2uyjWy9meVmY0b2up6IcmZdt5wmZcvEN8zUZ2YflLbbfWnUaZrEnM5so1tury0KBluGHkdtbKObBgAAAAAAYDTghTMAAMBWkvkQnE1im/1wlv2I1UsywEwC4uy47PJdgkDXlXfu3Lm1cfPmzauNmz17dm2cdk+N8EneVq5cWRvnaFfSiPpH5+z+d12EXT1lk8a548Ql/nvwwQdr4zZs2FAb57Y1kyDPyZY3k1B5sOX18mE3m6wzw20DH50BAMBoxwtnAAAAAACAHvQas7nbD1M6feZjpMYS1o+r+gF2/vz5HcP60VbjL2tsYvehthRLWD8860c2jdlcGtb53cdYjW2t9ab/12HdF7pNWg+l+MnuWNAPkPoBtdRgQdepx4L+v1QHbhod1g/wAwMDHcMa41k/WOtH+MwH1257snf7ETfT2x9/RAxnAAAAAAAAAEAraOE8hjWJm5vpCptZrlOK2Zzpmuu6IJa+SLXVbbFJWZxSTORMeTP7oMnXvSbLbRLTOTNfpjt4Jt515v9N4oln6q5JXbW13CaxqwEAAAAAAIYbLZwBAAAAAAAAAK2ghTMAAEAPsr1qsj1nMj152kxKFpFPEJiJexjhE9hlx+k63DrdfBo3MiJizpw5tXEuQeDOO+9cGzdz5szaOLetGl8woh6LcbDp1q1bV5zOJerTOIsR9ViMEb68jktM58ZpXMyIiPXr19fGue1yiQTd8jLc8erq1y3fjXN1nE0umO0Z2FYPwsEQUxIYWZlzuknv426Wp78X3DVf7w16X1y4cGHH8O677z7k//Ueqsl5NT6zux/qfV23S6/Jev/QZLV6H9LrodZT5reMDut2uKTHQ81finVcilsd4e9VW9Lt1HotbaPGmdZ96X57leJC33fffUNOr8vUGM/6e0Lv4Zl7XybW+VBKvY/pVTw4WjgDAAAAAAAAAFrBC2cAAAAAAAAAQCsIqTFKtZWoTadpmrAu002g1J2hSZLDiHLXWtclQpfTJKFaJsFik+4TbXeDHkpm3zYpSxtJGTP7zdHjTOcpdTVyy3Ay+7bJ/m/rfNP5miRLpPsPAAAAAABoGy+cAQAAAAAABpFpNNJtzOZuh7XBjsYV1hi8EfV8BPPnz+8Y1pjNS5Ys6RjWGM6zZs3qGNY4vxqL2DUo0kYvmjOgNKxxfB966KHaOoYqQyZHRamRW6lhXyludCmOtcuj4HIVbEnr3i1jS3r8lOJvu3jcGoNZj8G+vr6OYY35rTGeNa708uXLO4ZXr17dMezyMpRiLpcaz3XbSEsbftGo63/wwhkAAMDI9ubIJgPLJAh045r2COmGW4dLqpNNVucS7ulDx2DL0weabNJAt/zZs2fXxs2dO7c2rr+/vzZOH7wi/H51D4Cu14lLrrd27drauAy3ra7OXT25srltcA/w2aSBbrtc0kC33tKDYoR/iNYkUoOVI1u2bCJBJ3tNcA+lei5me+k17TEFAAAwHIjhDAAAAAAAAABoBS2cR4k2uui4cZnuI5kWXG3Efs209sq09Cp1RxlsOarU9WEk4x03iV2cbWVTKkspFnC2FU1JZhszy9XytRFPOqJ8TDeJA960LJlzPXO8lvZlJu4zAAAAAABAN3jhDAAAAAAAkJRpNNLtsNJGJxqjV0NaaXzliIgFCxZ0DO+6664dw7vttlvHsMZsnjdvXsewxujNNPQq0UYwGtJIQzxpGCQNqaRlysSVLjXcU00aPXXDNQzSsFalhlgaD1nrScOaaT1paLFM+DUN5aUxmzWEmf5f1+kaF25JYzpH+PBfWyo17iqts4RGXf+DkBoAAAAAAAAAgFbQwhkAAIwLw93aZLB1ZFrKDDYuE0rKzdc0RNZg02UTBLrEdC4J384771wb51peaUupiHrSQFdHLlO6W5ZLrjd9+vTaOLetmVBFEb7ViiuLqzuXcE/3hbY4ivB16ZavrZsifDI81xrIJQ1041yyPpeEz03nkgZmWpm5/eCSAWp2+4iIBx54oDZu5cqVtXFu3/SSSNBpGm4u21Iqe7yScBAAALSNFs4AAAAAAAAAgFbQwnmUci0NMi2eMkkCSzLJ0TKtIzItVEoJAd04nScTSyjTOqSXFirdrLtJYryIequaTHm1zt082rpI1/PYY48V15NpoZOJWdYkeWKThJuuHkpJGTOthJq0BsqcS02TU2a2u1Se4UqWCAAAAIxWTeIv9/osXoolq71ntLeLxl+OiNh99907hhctWjTkPHPmzOkY1jjR+myrzxf67OieG3Qa7T2jPUy0B4sOaw8a7RmkvaLcM1HpXUYpVrVup26jDpeSu7t60+d2HdZ1lI6nUqxijafseoOV4mXrMas9z7TXmeuZtSXdxkzPI51G67bbfV/aVzw//w9aOAMAAAAAAAAAWsELZwAAAAAAAABAKwipAQAAxpy2EwRml9dmMsDsvNkEgdmyuSR0kydPro1zSegWLFhQG7frrrumxmk33Yh6d82IetfX7La67XLjSt1iN3HdNDNhpiJ8UkOXwNAl69M6cftm9uzZqeW7bXXb5RL6uencOJf4z41z2+q6NWuZXV26rqmrV6+ujbvrrrtq49wxkT3HtkYiwez1hUSCAABgNOGF81bSJEZQ06z1W2rrh2KTrNouRlCTaTLz6MOJm6ZUV5mHysy69cEm8wM+86BWij0UUa8rt026XI2h5cqiDyuZlxyZFyil+EgR9Qe7JvHUXD2U4o9ljoem8c+bLLdJXOdMXLlM7OpM+QAAAICxqkl+otLv89L/dZn6wXHGjBkdw/Pnz+8YXrx4cW2ZS5Ys6RjWmM1z587tGNaPl/psW4qhq8+W7hlK59mwYUPH8KpVqzqGBwYGhhzW59XSh1sXi7jb/d1tvO7SM2HmfZBOU3qO7zVutJbBNRLQmMul7dJ3I6U40rqNeqxkPpjrx+LS863uy9I7iszzsy5zW3l+JqQGAAAAAAAAAKAVvHAGAAAAAAAAALSCF84AAAAAAAAAgFYQw3kEZBKRNInZ4+JGNYkX22Qet26Nv5OJz1OKz+zWpcOZOMou4U4pXlCmHtwyNI6RDmcS+LhYRBqbqhRjyY1ziW00DlImHlUmfnQplrUrry4nE3Nah92xWYr7PNi6SjKxmEoxnTJxn53MPsjEt1au/lQp7tW2EpMKY0MvyQWzSfiySb2y02WShmXuwxH+/udiF06fPr02TmNDRkQsWrSoNm6PPfaojdMYkRH12JMR9XtkRC7mf+Z6G5G7j0TU4x5G+BwGbr1uH7p9MXXq1FT5pk2bNuRwRMSsWbNq49x+deV125UtW1Z2X7jptO7cMeyO/zVr1tTGueM6k79gsHGuPvV3VIT/vZW9N2bO/+xxmEUiQQAA0DZeOAMAAAAAgG1WqaFGpiFHt4nBSgnV9ENif39/x/CCBQs6hnfbbbfaOnbdddeOYU0SqB/mtAy6DfrxUD9i6gdc95FXx61du7ZjeOXKlR3Dy5cv7xh2Hxi3VGp05T6AdpvQsdRwToe7TTKYoduhjdZ0uJTQUcuUaTBWasSn82hDAz3+9IP6vHnzOob12NAEkxH146mUXLGU6LDXhJJuHd3+f6wipAYAAAAAAAAAoBW8cAYAAAAAAAAAtIKQGgAAYJuS7cbopuslXrMbl1mHW752c4yImDJlSm1cX19fbZx2yY2ImDNnTm3cLrvsUhu3ePHi2jgX13n27Nm1cRrbPyK3/dmuiS428fr162vjXLxmlzvBxeHN7v9M3oqIXExcF8PZxcN2x4TbBlcOV5/ZOOGZ2P8R+TjJWj4Xw9ltgzuu3THnulJn40tnYx1njycnk6Ohl3jNmXUONg4AACCLF84jIPNDMZM8r0mcnyYJAZ0mifoySQMzyy09eLqEQ/pw4h7WMjGJlO4DN4+WR+vFzaMPOpnkRZm60/K65ep8TY6RTKIqrRf3YKzcA5uO03pw87Qhk2Qok8RK93XmgbatB8HhSiKoZck+kAMAAACjQZOYzarb37ul+Lb60Vg/5u68884dwxqfOSJi5syZHcMaF1q3S5859dlF4+Fq4lQdzjzPrV69umNYYzYPDAwMOb97HzCUUgL0zDS67/SZX5+F9dlXn7H0o2Qm+a7Oo3Vfeseg69Bn+szzutZ95rlwS1qP2nhCj1+N8ew+NpeOl9IxrmUuXQsyDSUyz/fjESE1AAAAAAAAAACt4IUzAAAAAAAAAKAVvHAGAAAAAAAAALSCGM7DIBPDpRSzORM3NRP7NROfqBSDJiIXz0fHZWI467hMkh0tn0smozGbXQxnjV/l1q3aqCu3Ho3h45LX6DSZuN86j0uepHTdmXrJxNGeOnVqx7A7hnTdGocqImLt2rUdw5lzReM2NYmJnEla5Zah26THkNvXOk0mJnImDlRmmiZxnUtxrpqWBdiklyR/Wdkkf+5a23bSwFJcwIj6NTWiHtcuoh7fMSJi/vz5jcctWLCgNs7FjHT3Zpc0TWNBRjTL7xCRi3c42DiXcNBNl8mXEOHvcdnjSa+Pbl/rb5jBluW47XLccefGZZMGZsuSydXh9kM2hmd2X2eTBvaSXDDzG8DN10siwexvIBIJYrzr5TdDU6X7m8av1RjOpfi106dPr61Tr9t6Hutzkl6/9JqpcYD1eU2f1dzz57p16zqGNYbzypUrh1ym7ju955ZyKrl9X4rjW3oWL9273P1zqPW730c6Tved7otSvG1dZ+l+7u6f+p5Ft1OPcV2HTq+/b3T5esxrjGc3jW63bkfmXcFQMu//dFxpHePlfksLZwAAAAAAAABAK3jhDAAAAAAAAABoBS+cAQAAAAAAAACtIIYzAAAAAADYZmlc3zZiPOsyNO6vxqvVmM1z5swZcljj12bi+2tsYs2vUIrZrPFuNb7yqlWrhhyOiFizZs2Qwxr3WcusuQ10WGNZa14JF/O+lPsqk19iS6VYxqW8Pi5essZkLsV0LuVv0nWUjg0XV1rjiusxqTGYS/WgZdD5dX0u34jGbNZjWLe7FD9b4ymXrg3u/6UcSOMlZrPihXOP3MFUurG4cTrslps5KEsXyszB7y6epYSAmWnccvVCnFmuzuOSxOhNJ5M0MLMPMkqJEDOJhDIJiEoX64j6xdMlKygdM3rjiqjXlUsOpfWrSTDc8aA3tUxyokzdZZTO20wCIDdNG+Vrej1ocuNqkliwaZLTJusGhpJNrpUd10siwV7Wodd7lzRu3rx5tXELFy6sjVu8eHFt3C677JJaniZdiag/DEf4B1x3zrv7iUsOq/Xk7jGZe0hEPhlcL0nTMgmEI/KJBJXbfnd/dMeXe2DNXI8Hm86Ny97Xsr9bM0nzsnXukgk5bhvcet0xpg+yg02XPe6aJPwebJzTy7Ge3QYAAABCagAAAAAAAAAAWsELZwAAAAAAAABAKwipAQAAAAAAthnDEbNZafgfDQWpYarmzp3bMbxgwYKOYY1Xq/FsXQguF85pSxp6qhQyUOPbapzg1atXdwyvWLGits6BgYEhl6FhiTS0lG6T/l9DfbkwVEr3lYZLK4UP1eMnE/6yW7pvSnGfNZSZ7kudXuvdhSVTup0aRlO3W/dFKazpjBkzOoZLZY6ob2fpGO61HjLhJnXf6TSl8FRjNXwVL5y7lDmYSvGZ3XyZeHU6rq1Yq3qRcBfkTAznUuxit1wdpxeoiPqNuTQcUb/puGlK5c3G81OlOnfHQyYudZMbp15M3Ta5i3Tp/7oNriylfeDqQS/27ngt1W9mHrduF4NxS5lYlq6udFwm7nOTcz1zzWgrOUEbiRIysSHH6o0VAAAAAIBtGS+cAQDAqJZNBuj0krwv88G4m+VlEsJG1D++alb6CJ8M8E/+5E9S07kEgS65rvv46crrtst9xFu3bl1qXCZpqyubm859COwlGVr2uMseO266zDTZ/eASNbqWOi7zvBvnEvNlEh92Qz9iu+VnkgpH+ISL7nxy87pjZ+3atbVxq1atqo1zyTBdfbpjTD++Z5M8Zq9Dbh9mZc8JPhgDAABiOAMAAAAAAAAAWkELZwAAAAAAMG51G0O3SYxnnUZ7o2gPJo3BvHDhwo7h3XffvWN4l112GXJ+11tJe4RoD4RSTxvtnaG9ZLQnzZo1azqGXS8QHafLKNVjKVxiG/GSSzGcS+Etdf62ewM5pXCPui9L+1bL7HoNTZ8+fchllo630r4t9fLJ9CjT7dKY4TqsvfT0+NRtylwrSmFBS/G5xypaOAMAAAAAAAAAWkEL54ImCeCaJA3MJAnLxEMrJVBzcdv061wmuV8mhl9mufqV1yUN1GR5TRICZmIkNtkHmbh6pYy1Ebmvh5p1OJM0UL8YuvLq1zMtX+brWia+pA43jWVZOqZd/epy3TR6nGWOh9JX44jyF9FMMsJMzMQmMRQz626iaasC3bckEQQAAAAAYOzhhTMAANimZJNrZcdluY9q7gPjzJkzO4Z33XXX2jR77bVXbdyf/umf1sYtWLCgNs51uc1+tMom5nNJ07TL4mDj9KOgK1s2yZ9LXug+DrqPq70kIXTLc8dO0w+K2aSEbpwmpYuod4GO8NvqZBpfRPiPvS75oda7a1iQbZjhyuGWp+dchE+u6ca5JIQDAwO1cS6BY+ZDavaYy37szV7DmjZ+icifnwAAYPzihTMAAAAAANhmlD7ulT7iZD5e60c1/eA7d+7cjmGN4azDOr3Gz9Uem64MWm7tNavboB9u9eORfkzTD8nr1q2rlUmn0Q/B+oFSP5SWhrXMpV7gEeVevZme7lsqHT+lXqWZD+E6rPNkeuMORffd2rVra9PovtTjQfeNlrnUG9w1zNiS2w96jGojiJUrV3YMr1ixomNYt7MU61plrg2lXs+l42esfMQlhjMAAAAAAAAAoBW0cN5Ck2ySmW6Ema5rmXixpbK5dekXItd1UbsWuq6GOs4tpxS72sUc1i9W7qusfrnVeTLdMZvEyc10kc3EN9b1uONBt8kdV1p/uk8yx4yLka10ua7rrX4tzXQdznxZznzRLGW2dcdDZrmlfZnpqu26kLsvwaXl6jjXnbZJnOe2rkWlYy1zLW0r5vRY+boLAAAAAMC2ghbOAAAAAAAAAIBW0MIZAACMC9lkgNmEZm66TAv+wdbrehBpL56IiJ133rljeNGiRbVplixZUhvnkgu6ZGhtJ9fLJg1063C9aDJx7Nx8rmxundlyZJMmZuvOccvTY8dN00siQVdPLmlgNpFgNjGf68U2derU2jg9F7PHXDZpoDvX3TjXK8ydT27cjBkzauPccZLZjy7ZYDahYy+yPZx6SS5ILyUMp25jNLcRw1nPX70Wagzn/v7+juHZs2d3DOu1RJdXigvrxpV6Ies9x/VS3pJej/Ral7nnluL8luJEa49SradMj+NSGUsxl1Wpx2q3sbHdOP2tUeqFXOohq8vT9bl43PpbQYd1Hr3vl/aFllmPX9dzWc8bjX2uCYDvv//+jmGN6ay/aUv1mEni2+31Z6zeL2nhDAAAAAAAAABoBS2cC9qI4ew0iR+cicda+mLpWpzoNK5Fh7ZKcXFydVwpnnRE/YtUZt067Oq7lKk2ov4FMBMTt5T51dF53H7T7c7s/8xXL60b17qoFN/YfV0tZaONKGfNbZLZ2ZVXj1/3FV6Pe9fyTOtPy+JaWJW+rkfUt0HL744HrRtXv3qMN/nqmdkHTeImNzl+M+XLzDNWv/4CAAAAADBe0MIZAAAAAAAAANAKWjgDAAAAAIBxq9RbWIebxHjWnoza01Hj12oeB+31qmXS3rUaW9blI9AylHol6zJ0nTpcmt71Ei31hNVh7bWrvUpXrVo15PRaRteLttS7tbSdpVjZpX2l63O5MHS7S72OS2VWekzr/K7XrZZp9erVQw5rj+tSL+NS7Gx3Huo6Zs2a1TG8YMGCjuEHHnhgyGGNQ13ad016+47XmM68cAYAAOOCC1GTTRqYCW8z2Dg3r3uYcWGN9EdwRMQuu+zSMeySAeo0ET5RmQtnlU2kl01Wlk3W5x6E3fJKyYQi8okEswn9son53La6UE4uiY077tx6Sw+5g82XPf7dNrhEQMuXL6+Nc/XpjjFNjBXhy+zOk9KLiAh/bGYTKbrwctnrhAv9pkm/IuoJiiL8w2EmdJgrm3sR0SQE1lDc8rLjsgk3nbHyEA0AAIZGSA0AAAAAAAAAQCu26RbOmW4xpSSBrtWBcl/qdZx+9c+0qnItL7SlRCahmrbWcK03tLuPa6Wl684k+NJ5XIsgbYmiw24fZOqzlAAw0/3HtcwqtczJJDl06860eCpxLWm0PNqyxrVI0e47mfLqMZ9piZRtcbQl13JJj1e3TaV1u/rWLkTu+NVzrtSNLSJ37qjMsZjR5JqWSXpaWoaTSZSaSfYJAAAAAABGDi2cAQAAAAAAAACt2KZbOAMAAAAAgPGl2yRcpaSByvW8056i2vtRh7UXpvaE1J57Ln59qUzai7PbXp0DAwMdw9rDs5Sorkl8ef2/LlN722rSQN13mn/A9ejWutdy6zI0H0Spx6frETzU/zNJAzX/QrdJA0vnhJbJ5cDQdeq+0TLqsK7T5YXYkh6vbnod19fX1zGseRbmz5/fMXzvvfd2DOs5oPumjR63megLQ/1/tPby5YUzAAAY1bLJ+7IJ/TKhY7rhQv240FMzZ86sjdMfuRH1hIBuGv3xHOF/dLsHPRciKJtwz03nHqLcQ0kmQaCbN5NYL7uswebNJnRzx1g2pFEmxJorX3Z/uf2frSf3YLtmzZraOH2QjPDh2hw3XSYJpTsOSw/um7h9mE3y6c7rqVOn1sa5BIGujl3Ir8xLD8cdN66essdhNoRZL4kE3bkzWh+QAQBA73jhvIXMg2q3Xz4j8j/ESsstxdqNqP+Y1x+3Lsas/th1D7Ga+d5lH9d16Y9I91Ch2+l+jOs2ZbJ36zzugVM1ieGc2be6nMzDX+brYekLZUT9ocUdM3pcZX78Zx4GS8txDzKZ86v0lT5zTrp1a93oNG6flI7NiPI+aPriq/TlPqJ8TGdefmQeEDPnRROZL7eZr8E80AIAAAAAMHKI4QwAAAAAAAAAaAUtnAEAAAAAwJjVbYzmXnsyZ2I4a29I7VmsvY+1Z6SWoUnvxdJ2lOJEa3zk1atXdwxrSCYtYxs9H3WZ2vNU4wLrvtF6cj2vdV+VYluXwn91O73+34W60nG63drjVcug9eB6/W6p1KvVLbNU11omHdZ1ls5Ld8zrdmkveu29P3v27I7hWbNmdQxr734NOZY55ku9iLsdHis9eGnhDAAAAAAAAABoBS2cAQDAqJZNBuhaarhx2YSDjluvyz/gch3MmzevNs4lBFywYEHHcH9/f20al5Mhm9DO5RLIjssmsMsmDXTTaWI6F6PezZdNaOi4GPxuX2dyC3SzvEwuiGy9ueVn686Nc/Nqy7cIvw0uQWB2n+l0bp3Za0Ivcf3dPpw+fXptnDuH3fa7eV0SQt0Ot/+z57Wr32wLyGzSQLdety+atLwcbD4AADD6bdMvnEvdbNy4Jj+MMj+UMmXRH34ui7X+wNVh94CqP3Zd0kB92NVuCG7Zpa4vEfUfqZmka1oPmWzj7oe/PkhluilkugSVumc5Wg/u4UqXo3XljgfdJlcPOk3mQbfUPWc4lc6VzAsnVw86LpM0MKOUjNDR+sxke3fnjh7jui/dvs0kAMwkFizN06R7XWY9PLwCAAAAALB1bdMvnAEAAAAAwPjSbUznbmOoZnq3aIOWnXbaacjhUgOYUqMU15ik1OhDGxJpnGCNV6u9kLRRTqYhUqkuS41b9P+lbdDpXT1p47lS3WvDHv1/6fjRMujyMr2MdJom+2JL3cY5jyjvGz3eSjGeS42HMo2jSue29kzUXonaI0kbaJYaRGZ69Gi5e43prEZLAytiOAMAAAAAAAAAWsELZwAAAAAAAABAK7aZkBqZBEGZuMmZeLyZGM6ldWdiGbuYvaXYxVOmTKnNo10EXFITjeE8a9as2jTaDUW7dGj3m4h695dMEphMXG2tBxe7Wtetw026Z7hp9BjKJGFxdaXdTTL7VruLZLrV6DSZBFGurkrb7Y7xJudbE5nrgQ67802Pq0xc4kyXribHoqtPHafnZGbfumMm05VJlbqZRTTr+pO5jpfKN1q6HOF/ZLqN9ZI0MBNLfbB1uBjwLvHXnDlzauNccrGFCxfWxs2dO7dj2OVWyMTt72Zc9nrrrgnZJHTZ5ILaZdTdE12uA7d8x+1Dl/jR/XZwySDd/nfzuut05r7srlHu3uG632YTKWbHuetpLwkH3Tjd32773Tns9quTPSfcOebORbded5y4cW4dmbwe2ePf7UNXn9mEftnrbvbYycgmdOVeDgDA6LLNvHAGAAAAAADjT+njRNsxnTMftPVjpn6M1BjOOr37KLWlTEMR/UBZalykH7R0uNQwRj/+uA9V+gG2231Xajig26zb4D6A6TxaRp2n23jJpbjTmRjOOk8mIfyWSsd4qaGfq3edRrdT60XrTetZpy/th0yC+0yDr6HWqeeh/j8Tw7n0UbQU+zr78XW0IaQGAAAAAAAAAKAVvHAGAAAAAAAAALRi3IbUyMR/zMTWLcU0zDSXz8RAK8VeduMyMZy1246L86sxm2fOnFmbRmM463BEvQuQdgNxdanTuK4opX3QtHtBqQuK27fatcEdM6UuFm4eXZeLzVfqDuWOhybx8prE53X7qBRjOBNzOBMrMLP/M91ompzrpfM4on4O6n5z52TmvMjEmC6dk+44a9KdK3PNy1yTS92fMvs6G5tzqPUAAAAAAIDmxu0LZwAAMPo1/UCRTV7lPm5lE+S5eTXeYoT/UKuJ/yIidtlll9q4BQsW1MbNnj27uM5s4kMnW09unNsX7qNYNkFgZlw2aZorR+bjfIRP6Kb7IcLvV5dI2SUSzCbca/IhdTBuWW6/uiSHLpFitt4zySAjfEJIbWDh6s2VLXu8Zse58ySToDkinzTS7Uetp7Vr19amcfWWTdTZNHlfRK6BQTfjMo07ejnW+aA8vvUas7nXmM6Ze2mpwVi3sWFL528mGbleK3RYG5uUGj2VYs1mfq+VEseXGiWV4t9mYl3rNKW4vJlldlOmUqxst45S45xSTObS8Vb6v1unlkmPJ72n6XaWGmKW4qJH1Otaj2Etgw6X4nOXjtfM/a7bBlGl86y0/K11PySkBgAAAAAAAACgFbxwBgAAAAAAAAC0ghfOAAAAAAAAAIBWjNsYzpnYQZlYK20km8rELWqSNNBNozFtNO6jiynY19fXMexiUeo4N42WR+MQubrSenCxj0p1nNkHbj9q3Whsn0ycShcHUutB97+LvaWxi1z8LZ1PYyo1PRZL54qL1ZRJhNhtTKiIen22lTRQufot7dumsQFL9enOYz02M8k0MwkL9Zx0cSfXrVvXMZzZ7kw8yExM3qYJQLtdd+b/xH0EAAAYO3qN2dxtTGf3nFJKkq7Dbf/2db9f9TmzlCBcnxdK8WxV5jd/6VlSn1H0eUmnL8VD1m10Me8z+3dL+jypz0OlePSl/eKeV1Xp+brb469JfpDSdm3YsGHI+fX/pRjNmedO3U49HgYGBoYc1pjOpWO+SQzn0nBpmb3GdHbTDIdx+8IZAAD0Zrg+AnS73mzSwLbHuQ9C2eRyLkHgwoULa+PmzZtXG6cfgt3HIVcn7ke4+zGZTSTnPmS56Zxs0sDMdG6azINYhN+HM2bMqI1z+2H+/Pm1cS5p4PTp02vjXD25h65MAp7s8e/2l0s46crr6mT16tW1cfpAHOG3y+0zN51+5IzIfVDPNCQYbF53nrhxvSQmddNlk0aWkhlF+Hpz9esSNbpzJ3s+9VInbl9kxzWZJoIPygAAbE2E1AAAAAAAAAAAtIIXzgAAAAAAAACAVoybkBrdxlxy4zLdrkrDTpP4TplurG4aHacxb1xXYO1GmYnhrN19I8oxpl1d6Ta5LpileLGZLsSurkr733XD1XVlYm3rcl131PXr13cMl+IERTSLXZ2JoaXld125dVwmxnCTczLTTbUUXyuivt9c11E99nQ4E/860zW0SexlR+vGHYvaVVePvWz3bqX1qfu/SUzniHJsqqbdYJvEcFZ0wQUAABg7Ms9BvSwv84xf+l2tzyT6W12XV/qNnQ3BtKVun7W7/U2cKZM+D5XyUGm9aL1pmUtxqSPKMW9L9VSqF31e0n2vw5n8V/rMqPVWyo+UeWbbknvmL8WidqGdtuSeYbdUOlbcOaZ1qc+8GpZK/6/bVIqX3EYM59L0Wve6jiZ5zzLvMnpFC2cAAAAAAAAAQCvGTQtnAAAwumVbFzXpETHYOLfOTG+PCN/Dw/UUmjNnTm2cSzi3884718b19/fXxk2ZMqVjuJcEXFlu+10PDNcSxdW760nievi4VkY6r2tR47bVlVfrMsLXuUsG6PbXrFmzauOyyercuEzSvGxSNne8unnd9rtyuHGupVI2qaOb1yXEy/RAdPs603spwh9zmZaKg02Xvca4MmurvYh6ElLXG6mXcW77s4kUnWyCxExvuIhyK8LB0BMJAIDRhRbOAAAAAAAAAIBW0MIZAAAAAACMWaWYzW3HdG4Sw7kUW1jz+mRiw27J9UIqxYItxWzW3iOlfDqZei7l7dGeQ5o/Snv0lGLwam+abC+sNnW7H9y+LtWL5ubS40HXqdusPWBKZY4ox6Iu5abS7dTjqxQHPdNDx/V2Gmodenxpvev/9TzO5OMqnSda96VrSak30NbqBTQmXzhnuq4NV9LATLeuzI2hlADQdeMrJRqMqB/8GkjedS2dPn16x7BLCKjT6HBEOdmcqwedx10M9IQtBdyPyAVl17rRYXfTySQjdOO25Lo3Zo4ZPfYyAfObJA3MJKPL7Lc2LnpNyuvoMePKq+NKgfndOFfe0s3A7Tc9FjPXkEzSQB3OJNN0+1HPuVJihYh2rqWZ5WYSImT+T9dcAAAAAACaGZMvnAEAwPjQ5CNyRG+xVN287uOP+5DjPrjOnDmzNs7FdXaxc93y9IOt2wbXeiLbWquX7XcfqjIf2yL8h1wX11c/jmU+LEf4D5AuRq77sK6tggabVz8IRvjYyW77XX265em2ueW7/eC23+1XF4fcHcOrV69OjXNxmN2HXbf/XfkyH5Zdvbnlu3HZWNfZ60n2+HfnndsO3RfuXHdxmF2DBheH202XjX/tZK+xTa/ZvbRCzX6E5iMzAADtI4YzAAAAAAAAAKAVtHAGAAAAAABjRtsxmZW2fM+E7NSeLDpcisNaCoenPT5KsZAjyuHnSvVYioervSa6jcEbUS+39v7QnjnaA0l7rmgsbC1DpldHt/VUUgqzqPvS9YrS7Z41a1bHsPak095QejytWbOmY1i3ORM2sRSLWum+LsVLLp1Dmf1QOr6055seP9pbSOtN/+96IaluYzbrcCn8p+6HTO+eUpmaGLcvnDM3hMzB2e0F2o1zF/5SzGbXVbIUIzmiHLPZdQ/Vca6rpU7jYkGX4ke7bdJp3MmpFzodznS1zXR31G6XrithJoaz7iedx3Vl1LrLdE/Vi467KZWSOrhxma6sut2uHjKJD1QmHq/K3Pwz8YL1op25UTS54ek2uXrR+hyuGM6Z+NfuPNAu8Lpc1/03sw9K07TVDTazn5rsSwAAAAAAQEgNAAAAAAAAAEBLxm0LZwAA0JtswqXhlk1A1UsiwWxismwSOpcM0PUg0q6DEfVeDq71f3bftJ1IMZuYzvV0cAncXK8fnc71ZMpug+uB43qIue3KJj50ZXF1kunpFZHrIu221dWT2wY3Lps00o3LdOGO8D1mtNtqRH3bsvXmxmV6lUXkj+vs+ZQ9PzMJDLP72tWlS/KoXYEj/HGd6Tod0dt1p2nSwGwPIxIEAgCw9dDCGQAAAAAAAADQinHTwrkUsznzBd198S59Bc+0asm0rtFWGZmWG65VVClmcyaGs4vPrOvKtizZkmsVo/O4FhYaL1anybS2cK1DSgkQXEsc5Vq/6DZpWdw2ap27fVCKKexa52idZ1pJlWI6u+W6fVAKZJ+J6ZxpXZPZ15lkBqVEDpkWMU1ixWfmcfugSXzuzHVRW03p+RdRv2bosZmJq545vzLJDppcxzOtp4jhDAAAMHa1nVRQ58/0gtIeUNr7SZ+xS/lVSvlu3G/TUq8ZfVehv+O7TVRYGnb03YgOa71qPepzkc6vZXb1pNutz4/d5u7pNjdRpneT1sPMmTM7hmfPnj3kMjRPlD6PZd6zKN2u0jO1Kp2n3dazm0f3XSkppSZf1KSAK1eu7BgeGBgYcv0R5efa0jHa7XN9m72FekELZwAAAAAAAABAK3jhDAAAAAAAAABoxbgJqQEAANq1NRIEuvX2kjQwO66XpIFunAuNlE1Wlun6ORLjnOy8rhumCw3lwvbodG5ZmfBJET58j1undjMdjJvXhThzx4QLseaOEz0msvWbCUsWkU8u5+Z1IZPcOFfvmfBbEbluxS5Mmzu/3Dns9pebzpXNhbjKnjvZxIzKHeuufl0ywBUrVqTGuePfrSN7/redSLDJNIOVDQAAjAxeOAMAAAAAgFGpyYeI0jzd5lnRj1/uQ5XG1J0zZ86Qwzq9foTUMmgcWP3gl8lTo/PosH5s0o/ApRi9mVw0Ok0prnQpxnO3cacd/cioH6wy8YyHmr+UUyaT70i3W2NZ6/FUasCgsYkz+X6U1kvpeNqwYUNXZdTl6bGRabhRys2k9VrKi1aKvZ6Jl9xtjqHS8VHaZieTC6lXY/KFs9uBTZJjtbFudwHVkyCTLC+TuE/HuRYaGvBcl6v/z667SdJA3QeZ1iiuNY2r4y25k0nX7VoV6XyZFlW6/91ytR60/K6FVyYhZKl87gJRunm78uly3UXctSJSTZLulZYRUb9plZIIuuVkfjC0cdEebNxQ63HratoCqLRct016nmZah+l5m0ka6Lj5Sko36+y6VeYGPBI3aQAAAAAAxhpiOAMAAAAAAAAAWsELZwAAAAAAAABAK8ZkSA0AADC6ZcO+NAmTNdi4bPiZTDisCJ/4TePlRfhwVU0TBEaU49dF+IRe2XHZ5G3ZJHS9jHNhpkrxIgfjkuENDAzUxrmwVW4dbv+7eWfMmJEqX19fX22cO+6U2/8aAzHCJ/5btWpVbZxLEOcSzq1cuTK1PFcWt1/dsVgKmzbYNO5cyoYAy4Sti/AhpbIJ8rKJSTNJA9063XVo1qxZtXEaL3aw6dy+dvu1SeirTdpMENh2CKutlSAXvek2RnO3w6XwkO7eX4rhrOef3j9KoQ712qr3VXed1ftbKUaz3kt1uBRKLxPurtt4tN2GT+02nrdTCsFYigud/e2yif4ecPc+vafp7xS9N+h2677TdZTuyZkkxvrbUeNEq1KMZz3vdNjdW3U7uj0edF/o7wEdzsRwVqX7WK/Xr8w2j0Q4yDHxwjlTWU1iOJcCdzuZzNl6IXA/WPWHrT6EuBuYjnMPPaXlZn5kuwesTPxo3W6tq0y2b7cP9Caode5+/GpZ3H4qxf51ZdHyZuJS6zyZlxBuuXoxLv1YcFw9KC1v5hh3N9xSAgF3E9Z5MtM0OY8zPwCavPByLw7a+DHSNH50qSyubKUbrBun1wN3TmZieje56TXZ/5kfwqPlJg0AAAAAwFhDSA0AAAAAAAAAQCt44QwAAAAAAAAAaMWYCKkBAAAAAADgdBvTufT/JjGcNSZzKSRmKY5/KWazxtXPxF7XkHAaplFj8Oo6dVjL2CTWu5ZJQ/FpSMVuQzeWlp8pkyrFeC6F8GtyvGqoSw1z6UJ3DjV/JgztllydaN3r8VCKC63HXynOdCakpY7Tc1fDQ5biQmu96vIzMZxLx1OvMZ2HQybkbAkvnAEAgNX2j5ls0qitkTTQxSt3D5PZpIEuFr8ri3tg0QchF6PfJeBzSf6yiQSzCQJdEj43ziWmyyYN1IcXV0fuR697gMw8HEX4pHluX7vEf6587njK5L+IqB/bmfwWET6h3/33318b5xLEuYSDbpzb19lEgm7/ZJIGlnIhDDWdq1+Xq8SNyyT0i8gnA82Oy0zjyuauQy5BYH9/f22c2363r911YriRLwEAgLFpTLxwLn1tdOPaShqo8+kPY/dFRX/cukR9+hCjP/7cj0H9Iel+bOo4fbhxP7wzSQ51Oe6hqfSFNvOgnXmBUNonbpx7GGiSybP0tcxNo9vkypvZptLXZzdPKTFiRP0BMFOWzFc8LW/my7JO4x7iS1+4myQEbDpN5qty6cWBe/GTqQfdziZf6jMv4tx53SRpYJMHRn2hkkk0mDmumrxEzb7IHGq9AAAAAABsC4jhDAAAAAAAAABoxZho4QwAAAAAABDRe8zmEu2lqD0ZXY9fDU+jvQK1TKXYwxqKSsNVaUijdevW1cqkvSl1u0rxkrXHYWm41HvWKfXuLPX0LQ03iSutmsSB3lK38ZIz9VaKBNBtGVVmeb3G39bhbnuIZsLkleJA67ld6vFbiuGc6bVfirYwEjGaRwItnAEAAAAAAAAArRh1LZwzcTIzCYYy82S+IpTi2boYvvpFxSXxmDlzZsfw3Llzhxx2y3Ffc3SbMvFY9YuMm0a30223LicThzYTn7tUPvelrfQVKqJeN1o+V7+6nEx8426/Zg42jY4rZeeNKGfoddNkvjLqNpWy9LrluOWWvnhG1Lczk1yqSdxvncfFAdfjwcVw1vkyX5pdXGeVqc/Svm0a77iUuTcTl9qtu3S8ZmI4u2tIZjklmXOSmM3NNE0amI2r3UvSQJcgzuVYcMnl3PXAHfcu+Zueq+vXr69N41oxuURtbvku8Zdbh0v85xLELV++vDbOJZxzSQPd9SJzL3Dj3HZlt9UlDZwxY0Zqee43kZvX5fTIJETsZRvcvnGJBLOJH7PHXbY1mft95o5Z5c6lbNJA1yoxmyDQJddz63Dc74jM/T67rW673HGozyAR+cSnWZn7dTfj2pR5JgQAAL2jhTMAAAAAAAAAoBWjroUzAAAAAABAVtsxT7UngfbIcD2jdFypV6j2YNH/aw8S7d2iw64XivaS0F5eOlzqlVga1m3I9FIr9cLU3iDaY0rrqUkM51Kv5G5jDev8uk2uXoaaPqK+HdojyPUkG2r+Us/bTG/00jylnsalXsal4y3TQ157mGkPRj1vtR5Lvf21p5Pr0dTtdo1EDOfSOtqIK00LZwAAAAAAAABAK8ZEC+fMl5VMzOZu1+PWlYl3rF9IXAzIOXPmdAzPnz+/Y3jnnXeuzaNx47KxIIcqW0T9C437IlP68hRR/uLllqtf2TJxk902qMw2Nfkaq8tpUg+Z2NuZmI6lL5xunDtmSll/XXxBXXdmmkys5Uxc6tK6MzGcnTZibWdiepdaGbhx2bi0qvTlNBM71X29L8W3zsSuzcTnzsyT+cqdOb+aKN13iAkJAAAAANgWjYkXzgAAYORlPjh0o2miv+w6sy/53YcJ9zHTJdJyH5GzCbdc+Vz3R/3w55LBuaR8riutSzjn1ukSxGXX68a55bmyuA9fTT5QDTYuW+eZ/TAYl6zNJQjMJDmOqJfZ1ZGrc5cgcMWKFbVxy5Ytq41buXJlbZxLTOjqJPsRz31gdXWiy8sk1hts+e48dHXurjFuvW773b52x4RbnitfqdvtYOPcdrkkhy7JqZvOLS/zUbebccONBIEAAGw9vHAGAAAAAACj0kjEM1Wlns6uR59Oo8votseqxibWj6OZ3qyq1Hu81IOz1KNPPxpmPkpquUs9WrXMWg+lmM2ZXqmluNKlXqGlei71inb1VmqQoB9AdR16/HS7DU7p+NH/a92XepBrGXV+93FU60EbhuiwW8aWtFGKLl+HXSMWPZdLx1fp2jES2ui9SwxnAAAAAAAAAEAreOEMAAAAAAAAAGjFqAup0TSWY6m5f6b5t1tGqcm+60qjcdBmzJhRm2bu3LkdwwsWLOgYnjdvXm0ebZrvuopoNwltmu9itGkXgFKXgohcfZa6IUXU67dJoj6333SeTNxA7daQOc5cPehyS91CIurdY1zcRI3XuGrVqo5hFy8z071IuyjpPE0SAjpaV5m6yyQW1PK5smSOmVJ3oKbl1WMv01Up01WoSTebTFLGzP4vddfLJP90cSv1eqrlyyT/zMS61LrLdD9sgtiRAAAAAIBt0ah74QwAAEavXl6at/nCvZekVJmPIhE+GZj7cOtitWUTpLkkZBqTb2BgoDaNS/LmPjxmE+S5D50uCaFbh5tOY9VF1D9oRfg6aXqcuGW5D2uuzl3Zssnw3Mdy97HOJetzH9JK8TAj/P5yCQLvv//+1HQuCaE7Tlx9um3INDKIyH2Yy+4Ht1/dsek+eDrumHD17q4J2USSmaSGri5LsT+HWr4rm7uGZZMrOr1c65vG6s1+5N0asYAxPHrdl93G3C3FnnXTdBvvuNQQqHQ9zFwvSteY0vmrZSwl2HX3Zl2GlqnUuEm3Sf9f2reZ+5YusxRzt6QUw9mVSWld628yvZZrvXYbw7nJtbwUA7xUD6VhLVPmPqrDpXNZl6n3b00grg1M3e8s3Vd6DpQaUY1Eo6U2YjYrQmoAAAAAAAAAAFrBC2cAAAAAAAAAQCu2ekiNTFeYTPzVNtadiR+sw64LWqnJfUTErFmzOoZnz57dMdzf31+bR9flumtqNwltBu+6802bNq1j2HVLyDSvLzW5d/XbpNl+Zr/pNJkuu5kuJDrOdS0tdQHKdNF03ae1a4Z2p24aw7lU3sw8TqkbWma/OaV94LqalbrmZNbt/p/Zt6Vj2pVX15WJ4eyO8VL8cHcNaRLDOxOXOtNtrNTFz3XH1nFNzvXhuqcQrxkAAAAAsC3a6i+cAQAAAAAAIpo1Bui1AUEp9mwb8dW18UepMUgpqb0m3HYNx7RMOk0pwbnOr3GES/O7xjU6TSlebSlRu/6/1HjHNebR7crGyh9snd3GbNZht37dTi2zNmLT7Sw1RmsSN7gUH7vUgKjUuLRJozDdDt1uHS6tQ8+z6dOndwxrDGf9f0TEqlWrOoZ135Xqvo342qrbxlJNrrG8cAYAANbWSPyULUcv41zZ3ENadlymF0KE7x3ikutlkgbqD9cInyDNJfNx41xvhkwPh4jcw2RE9w9vm7jeDdllZRMJumRwbjpXJ64+XVJH1ysuc55kEi5F+G1wyQDdcZLd/mwywGwSuqay15de6i6bDNL1MHM9Cl2yPjdOH2x1OMJfh9y+cfXk9oMbl03y2IsmPV0j8vemXuYFAAC9IYYzAAAAAAAAAKAVvHAGAAAAAAAAALRi1IXUcF2fMnFc2ojzlEkaqF0EXVc4TcLnYrjouMw82qXOdXXULnbaldB1cdRtcN30SrGZIsoxplyXW92GTBKzUlwpt1xXXq2b0rArn+sKrd0yS8MR9e7TmiAwImLZsmUdw9rF2i23FAcsovsYWW4ed/6V4p65rpqZaUrHottvpVhRg41rg+6DJokRM/Wb6V6udZPpLu6mcXVcKoteS925rttUigEWUY7h5sZp+drqXtskwS1dewEAAIbW5B1Bt7Ff24jhXEpcr//PPKsNtc5MYnSdp7Qdpd/N+vzrnte2lEmQXvp/6Xmv9GyiZcw8Y6pSXZf2dbcxnDNhjUoJ7LVMpee8bmNruzKVzpvS837pmTZTJt1OfU+i69R6KB0L+l5O3+W5sFr6jq20nU32Rbe6jdncZJ20cAYAAAAAAAAAtGLUtXAGAADjU9PeBZleKtllRfhWBW5cNlmdK1824Vymp8yDDz6YWpYrh9sG1zurlyRkvSRrbNJaJsLvf7cNbp1u32iroIhcr6sI38No+fLltXGlFjPdyB5z2W3NtkBzx4S27BlsnEtMlylzpudShE+u51oZZcdljzuXNDKbrNDtCz0/3XzZc7jUWnKT7DWxaeLPbgxXj7PRtk4AAMY7WjgDAAAAAAAAAFox6lo4N43hrDIxUDMtaLQ1hrYecDGRtZWEazWhrTBKsW0GW5fSlifaSsQtNxPTKFPnui4ddq0stNWWa8Wlrb9K8ZEi6vs/0/pKy+tarKxbt65jePXq1bVpNLayTrN27draPDqNLiMiYuXKlR3Dq1at6hh2rWRcyyFV2rdNYuJGlOOFZVrTuWl0ObruTIuszPGgx2smZlGTlnqZFkRN4jO78mRiOGdiImfi36tS3LKI8rUoE28tc7xmYmCVYsFFNIsdSMxmAAAAAMB4N+peOAMAAAAAAAym16SB3S4/0yCk24Y8pUYQ2rBCG6BlGtBpAx4d1nlKjU+6TX7mdNsAo9QwqBQ+KNNAqaTbpOndrkPnz4Th0u12IZi2VNqG0vGYaVyljYq0oaWGhHKNkHopo5tGG+ZpI0KtR23gpsvTfaPnhAvxVWo0p7rdF6O1URMhNQAAAAAAAAAAraCFMwAAGHOyoVCyyeuyXCuabGK2bGK6UkuKCB9my4UhyoSiifB14kJLuVBSLlyXa7nhwma5+tR53fJdixi3H7KJ37LJ4Nw2uHFNw5O1LdvyzE3nWujMmDGjNm7WrFm1cX19fal1ZJJmumPEHesuUeHs2bNT41wSPldeV5ZswsWmCUfdNSK7X905kQkZ1Y1sq6rhPv5Ha+suAAC2VVv9hXOm68tw/UDJdFvQhxx9wHM/UHWc+8GuD0qZLjqZ7gZuXVvK1GXmgT0T+zXTxUMfKrR7g5umjbjEEfVt0oce91CtcZRXrFhRm0bHaTxmF8NZt9Gte82aNUOWN/PSoq2M45k42no+lWI6u3HumC/FP8+cx5njV6fJvKDIvHRpEpfY1a+u2+3/Ulz1zMNZk+MjU97Mw3hb8a5L02TiVGe0dT/joRkAAAAAMJZt9RfOAAAAAAAATuYjfreNBXqNI+waLJTiH5caleiwNmYpxZV2jXVK8WW1TNobS3vxlBr7NGm0UYrRrI1mdB2les/EfC4to7T/mzTS6Va326XHQ2nftNHgphTDecqUKR3DpZjgpW3O9NrRZeoy9BjX/5f2bamhnZumVNel420kGii1sQ5iOAMAAAAAAAAAWsELZwAAAAAAAABAKwipAQAAWpeNYd1m7gbX9cuNc10p3XQuNrob55LLue53mRwEEfXuh64+pk6dWhvnpnPJ1dw4V163rZqXIMLHr3fcvG4duh0uQaLLoeG43BaZHAIRPudCNmlgJq9CRPOkli7+v+vCmc0J4up4+vTptXEuQaBLwueOz+x5p+eJm8+Vd+bMmbVxc+fOrY2bN29ebZx28R2M24eZvBCDyeQzyHbTznTvH2y6to2WRIIAAGDrGfEXzqU4RU3jMzWJR1OKNxNRfyjTH7juB2qTpIFalsxDiXvYaPIjVX8oa9wmVx5XPp0vs1xNfKeJ8SLqiQTdclQmIaT+CNcHywceeKA2z/33398xvHz58to0+kCtCQA1QWBEvR7cNPpAq/WQeYDInAeZhGpN6DGfiW3kptF60GncixR9keBeDml96rmeeaB0Lyy0PFpe91CWOd8y55eO03VlHnTdut35tKXMSwW3b5skU20j1lhG5qUQD84AAABjUymOsH5IzPz21mWUEmLrs0Tpt3vmmVd/X5cSmJee2bpdniuTbkep7kvP//p/HdZ9l0m2XoqPnInpPdT/S8OZD4aZZ8YtlWJ+t/Fcpftb34XpuzJ95tYylo6N7MfWbpTmzzxTq9Jzoy6z9OG22+m3FkJqAAAAAAAAAABawQtnAAAAAAAAAEAreOEMAAAAAAAAAGjFVk8aWIpD5MY1iePp/p+JF6vxV0sxaCLqcZ1dYpNSgp1sUhJViieTSZ7kkt9kylKKa+ViL2msYhfDWWMra/xdt02ZuL4636pVqzqGXXzmZcuWdQyvWLGiNo0uR8uvMakjcnWl9avHiKsHPVcyMXsz52QmrrOWR48Zdwzpfssk7CrFooqo7393PJRie7lYTjrOnettxFdy687EkdM6LsXYcpoktHL/z8SgL12TM/eHNhPQ9YqYzjnDXU/ZRILumuTOKxcD3l2r3HXGcb8HMjH1MtfzCH+u9ZI00JXXTae5CSJyvwMclwvDJaVzv8nc9XPGjBmpcS7Jod7jI+q5GiL8vd4dO07meun2Qzbx37Rp01LjXJ24xHxuHa7MmRwWEfVtc/d1t//7+vpq41ySwzlz5tTGuZws2d8/7tqRTVaaiT2ZzaXhrglu3uw4J5v4MqvN3D2jNX4lRo9uj5EmcYUzzw9bKv0WL5U5c77oeavXrNL/tQyluNGlGM+unKV8VqXY2Hov0fcZev9tEsO525jNpXrrdr+4MpXKrMsoxRAfjhjO+puz2xjOTeJWdztPt9eGbs+ZiPLxVDIS97jhWActnAEAAAAAAAAAreCFMwAAAAAAAACgFbxwBgAAAAAAAAC0YqvHcAYAANuGrRHXOrtOF2cxk69gsOncejMx5iPq8e9cvN5sDNNsPLZsnFQXJ9nF/3UxcV2MYVefysVwdnGD+/v7U+t0+8vFYda8DRERDzzwQG3c/fffXxvn8kC4PBUuBqhyx4ir39mzZ9fGzZ07tzbOxTB2defq2K3XHScuH4jb1+6c0OPdxVJ2MZyzsandvG67MnkOBpONk5zJVeGmyV6vsrGks/GlnbZjPmZi0gJNlI6l0rHcJHZsKYZzKXdOG+dXKd6slqEUF7gUs1ev6+46XzrPSzmm9LqoeRNKMZ0zv+VKcXlL+6YU87nbWNoR5Rw+up2ZvFZDaXL8lWI46+8y/V1Zip3eJM9Bt+e2rkPrXfdN5r7dRl6noYzWe+WIv3AuXVwySXDcD8+STCKdzINg6QRx07iHnVIyLHcAZm5g3d7UnEySJPcgodPoieiWqzeHtpIGloLTR9TrQsviEv7ouEwCnNINL6J8EYsoX0ybJGGLaHY+ZX5wZYLnl+ZxSj963DY2SbBX+rHlxmUe2DI3m9KProjcMaNc3ajhuIm75WReMmR+sLaR7AIAAAAAALSHkBoAAAAAAAAAgFbwwhkAAAAAAAAA0ApiOAMAAAAAgG1Wt2HZMiEwu42fXApTVwpHmgnVV4ot3G1s2VK9NQnfqOEPSzGdNYSlhsHU6TPhFUu63XeletYyuXor7f9SKNrS8djt8RdRD3nYbYhEDQFaOocy4Xa7rSddh+6LbmNnawjYiPoxXAqz2XaMZ2ck1rHVXziXdr6bJpvYprTcTBD1JjGcNfGIi+GsCXBKJ2ZE9xc1N0/TGM6ZWMulC7k78TQ+s1uurluXm0lq5GLg6sVNLySZhCzuxqTl02E3T+kC5Ogx7ZJK6XHkEi/pNJljJFMPpRjDpXjjgynN52IOa11lYi2XEjm4cZlpMjeTJomKMj/mdBp3nWkSlzoT91nX3STmeCaGc+Ye0u3/s9Ng63P7yR1r7nrpxjV5SBpqvZlrcET9t4crm+Pu3y5vgJsumyDMySZDzI7Tene/tVxCu3nz5tXGuWR4rrz6sBrhE//dc889tXEuCZ3b/+74dLkgdF+45bsEgQsXLqyNW7RoUWo6tzyXSM9xOS9cwkX9zRfhj2393ezqMpsMMJNHJSKXQ2awsmT3tbufuvOz6f0mm/gv8zu0m+WNRLLSpjIv3wAAwPAgpAYAAAAAAAAAoBW8cAYAAAAAAAAAtGKrh9QAAAAAAACIGJnQJ6XQkzrcJNSbhnXRkIOleMql0HGZkHWq2zjQpfBiTULtlcIS6jI0NGcphnMptKfuh4hyKKDSvtXhUujY0r534c96jb+tIZUyYSe3lInhrMdg6VzuNm60ljkTTk+HS9tdCneqx0/m+CqF6yzVw0jEWx4OtHAGAAAAAAAAALRi1LVwziTtaJJgIpPkI5O4pDQcUU+y4pKuaAIcHXbL1fK5rxylLyeunjKJz/Qrokv8ouP0S49LjLN69eqOYZc0UL9Y6ja6r8ulr3cR9Tpu8tWoyRfbpslVSgnfXOKlTJJLnU/PC1e20lc9N66UTNGtq0liwUySm0zSm0wCrSbLVe7Y1MRimetXJrlZprVI5ut6KYuzqwfdL5lrfSmJoBvXJPFs5p7S1lfl4Vru1jbcLZGyiZ/c/s/c2yN8wjE3zl1H3fIy1+QIn0iwlFg4In+9cQndXII8d167+swmF3Tnq9tWt149991+6Ovrq41zCQJ33nnn2jj3u8zdO1wSwpkzZ9bGuX2duQ5G5Op4xowZtWl22WWX2rg999yzNm6vvfaqjdt9991r41zdue1ySe7uv//+2jj3m8/tf3dO6P5307j9744Tdxy68ySbXC/TuivC79dskuCm11O3/GwywNJ9vY2y9JJcsM1ljZf7LgAAox0tnAEAAAAAAAAArRh1LZwBAAAAAADaUoqxW4rZrL00Mr2WSj1HtXdBqUdgqYe26zVR6iWrSr0+taerDus2ud6S3cZs7nZYy6DDmZ4OpXpSpeNL6f8zsa9Lx0upZ3Wpp3ipXlyddBsvOdNDeEulGM6ZnsDdxpXORFjYUqandLe9a0ZDb5w2ykALZwAAAAAAAABAK4a1hXMmLmaTWJpNYji7WGr6hcbFSNSvlBq70cUB1BhyLqbctGnThhx28+iXmUxsOf3imIkp6LJq6pdJF/9R4y9r3EgX93nVqlUdwxrT2a1bt8HFBFQuDmHpa1tGWzGcVSbbqh6vbcUTz3zN1X3iYjV2+1U3wh97qhTXORPXL7MPmkyTiTObiR1fyvbrxmXi2Wa+CGfin2sMz0zs7Uzs4m6zO0fkYll3+5UaAAAAAAA0R0gNAADQuq3xYt99RHEf41wSttmzZ9fGzZo1KzWv+5jnPoa6hIOZcW673Ac6l8DVfdxx07kur70kNHMfel09ZT6WZRM1unFuXv3IH+E//rnEdNnEhy4JcuajuuOOQ5c0cPHixbVxS5YsSc07ffr0Yjki/Ha5BgVu/7u6cw0slDtusuehO4bdR1F3PmW6Dkf4xge9XP+aNFToVSbx8Ehp0kgAAACMPrxwBgAAAAAA24xSTzr96KQf0pr0Li19QOm2x22pJ2VEOc6zfoTTYe3ZqD2d9f+l+MoR5TjQukwdLsVoLvU4zvSILPUm7fVDXamMpV69mWWU4m+XYo5nYjxnohF0o9uICJme4aVY6qUy6Px6LdB6dB/du40jPV6Mns/ZAAAAAAAAAIAxbcRbOJe+DLUVfzOz3NIXnIj6F0H9epGJ4ey6bmrXRZ3GfTHVbXBfC123zi1luhFmYjjrV8aIesxmjc+swxH17qW6DLfuUkbXiPq+dPWp+z/zVTEzTZMsuJljuvSV3X1JaxJz3C1H6f535S91CXX1ksnOW4q93aQsbXHrbrLf3PGqMrGLS/Gi3Tw6jdumTMxmlclIXNpPTb5gRwxfDGe6+QIAAAAAUEcLZwAAAAAAAABAK4jhDAAARoRrXd60xblroe96KrmkcTNnzqyNmzNnTm2cSyTY399fG+cSrrneTa6XiRuX6eXguDrJ9CaJ8L2bXK8pV8duH7ptcHXilqe9HVxCP7fOTK8jt/wI3zvCHTtu/8+dO7c2ziX6c9vvEgkqlyDPrXPnnXeujXPHtTteXW+bUq+5oWR6/ETkEm665I0u2aDbX+6ccMdJ9trk5nXj3HozCTIjmvVgivDniUvUmE246ebNnv+Z3lEjgZ5IAABsPbxwBgAAAAAAo1IbH6y7TT5WCr+Z+aDjPoRtqRQGVD+QlsqUCS2n9OPi+vXrO4bXrl075LBOX0r4F1EPmanDpcSDpQ+ipbB8mUYLpeFulUJzthF+srQOrWc9XkvJ79zxVUrg2G2Z3TqGmj4zje7vUl3r8aL1oB/L9SO4O+91GaWQjzo8Eh9Qh2MdhNQAAAAAAAAAALRiWFs4Z75EZr42leYZTrquTDI6/aLhuv3pV5HS16WIZsnRSl+1IupfHTds2FCcRr9kRtQT/mk3UddtdM2aNcV161ey0lfaiHKytIjy1zVXFv266rogl74MZRKfuWl0G3TYdYdt8iU+05Vb94H7ylyqKzdPJvmczpdJItnkmtEkyV1mm3SazHId3Qfua3CpFUSmK7sri15HSl+N3XKy3dy3lOmO7Oqhyf7PtDIAAAAAAAB1tHAGAAAAAAAAALSCGM4AAKAnvcRWbNIbarBxroW767XhkpC5BIEu4Vo2gVk2QaAbpy33XW8aN871Ysr2JnHL62Ufuh41rqeA67Wk2+GW77bLbb/rkZWNw+i2wR1jvSRmc72TtE7cMeISELrjMNPDK8LH2NSeShH13mwRvkeYO54cV3d6jrkEjG5bs0n+Mj13IvI9W9wxnE3058bp8enKm12+236XhDJ7XXPHayamZ9vodQSn1HO62xjO3cZ5jSj3Lu22DN2eS5kehDqs1/WBgYEhh1etWjXk/G3EcNbhTA/RLem+z/Ty1Ht0aZ5Sr+tS704d1uMr0/NX16H1Vur9XiqjTu+2WX8D6LD+DtN6LtVj6bxsEtO59H8tk57HbcRwzvRwH+r/Y+U+SAtnAAAAAAAAAEArWm3hnGkJ0+2XRzfOTVN6w5/J8pn5SpCJDZyJiatfSXQ5mfjM7gumtijJxGfWcZp5NqIea9lNozGadRrXKkbL51rTNMkyq/vJxY92X1u35FpF6TjXgkePq1IccDeN2yY9RjJZiXVck4y87ljU7c7EXi+Vza3b0XWV6jsi1zqgdC3KbGMpq+5g5eu2bG5ck/j3mZjImeVm4h1nvj6XDFc9AAAAAACA9tDCGQAAAAAAAADQCmI4AwAAAACAMaPbnnzd9ngrxb/NxNjNxA4eap3aa1B7mZZi7rpxGudXeyVrzOaVK1d2DGvPZ+0trT2WXYz8bmM0l3qil2I2a+9ylz9A4+5qzN1Sj/RSbGHdd65nd7dKcaB1naV43qV6dz1JtZ40xrfWdak3tcZD1ukzMZy1Xko9l7WXcqmXuEYw0Dpw53m3saq7jek8WvHCGQAAjIimSegy4V8i/A88l+TKJcNySbNcYjYXJsuF13JlySar0x/KLiSVCxWlD4ERPjyUe8jJJnlz+8JtvxvnZBIYZpMcum11+99xoZdc0hfHlS+b6DITKsiFa3LzuQfy7AOt234Xhs0dd26c2xeuntxxovU+ffr02jQukaJbvguflgmHNth02SSMTvZYzISKyswX4etp5syZtXH9/f21ce46mU2kmT3+myY9anNZAABgeBBSAwAAAAAAAADQimFt4TxczbzdF+zSV23X+iCThK/UaiGTsC7T8kmX47ZHy+dabWhrFG0V5VqcaDca7TYTEbFixYqOYe1q45aj63LdaTLJ3Lrt7uTW5VquaJ3rclyrIN0mt9xSl4zMeZFpuafHVaYFTCaZmw5nEli6fVA6J91yM4kQtc5L3d3ccjMyLYy0tZJr+VNKEOquD7rdrvyZhJBax5kEi7rfXH02aUWUabFX6saVOY8zrQUBAAAAAMDwIaQGAAAAAAAYs3qN4awNHbRhlDZoatKYqhS/ttSQphTDuUmDNA3HpTF49f86v65TG2258ESl2NPdNvorxWzWUE0u3JCGEdIQaqVQYaXjR7dR6023QRvzRZQbfZViOmfiHw/FNRgqNZQqNbQsxVfWfafTu3OuFLtay1Ta17rOUoPCTCO/kswyh5p+ODRqdDYM5QAAAAAAAAAAbINo4QwAAEa1bAIq1/LCtUjJhL+J8Em+XIiWbMKxbGsobR3kkrK58Fcu3FU2oZsrRyZs2GDjMqGABluHci0qXF26ll0u4aJbnttfbpw77lxyPTdv06Rm7vhy258Jmxbhy+vCiGWTBrrjzpXFlTmTcC57fDm9HDuZsGkRvqWca8nkEo5mrieuHG75mVBlEb68LjGjG9dL0sCtgeSCAABsPWPihXPmh0Gpu4D7waE/4NzDlo4rdY2IKMchdTLdG/ThxT3M6MOBPmi4BwXtNrNs2bLaNDrOPejquvQHvauHTHzjUjcL92Nd6y/zINnkeHDbpC839IWF+/Hf5Id5qbuKk3lozZQl01XKrWtL2ZcWJZlY7JnrQaksmRdZ7mFSuwFlunTpctxLr0wM71LXnUxdZeLfl7q1RdTLm3lYLnUzjKhvQyaW9Wh5EAYAAAAAYDwaEy+cAQAAAAAAnFIDg1KPmlIMXm1w43pyaG+JUsMIbdCiDXa6jcHrenDoMkvbocO6TaU40pmE7plptqT7shSzWRvvaHxm14NjxowZQ85TajxT2nc6vdZzKUa0U1pHqSFkqeGWHq/u+NJ9oT3LSonuSzGgS/veNXzTY1z3jR4vpbovNVYqxVqPqNddt41Ue21AtbV69xDDGQAAAAAAAADQCl44AwAAAAAAAABaMawhNdqIvdx0OcrF/szE7NXm8No83yVZ0W4nbhpdrnYNyMRwziR4WbNmTcewi728fPnyjuEHHnigNs2KFSs6hjMJh7S7hOuq0CSGcybOr9ZVJqGP7rdS/NsIv02lmL2ZpDGuW1Gpq5HrJpZJxlSKS+3qIXMeNClvqQtNRPddz5zMckvdeyLqsZXdvtVxOuxiOOs4t1wX11mVYtA7mXjXuu7MMZNZbuka4vatO/ZK6256jHS7nm0pVvRwd9PKJg3MJhLMXH8GW57rJpeJdT7YvK7u9J6Vyb8w2Dj9HeCWH+HLm62TTOz0wdaRuV64a1c2QaCTTRDoxrltdfXpypz5XRGRi1+fTRro9r/j6jO7PHfcZRNTuvNTt81d513yuky32sHKlk1y6PZ/9prglpfpQp09brLXusxv18HGud8eTfJvDIdsgkASCQIAMDKI4QwAAAAAAEaFNj4CdBvztNSAQj/MZT5euQ9SW9IPu/qhRz8adRuXOqL+sU/L2Gu9qMxHstL+1e3SYf34pR8hS0na+/v7a+ucM2dOx/DMmTM7hkuxg7URlNarbvPatWs7hpt8gCzFkdZ9322c6dKwW4eeJ6V9WYrprGXUfd+koZ7+v9t4yjp/5kN5aV9sDaXtbOM6TEgNAAAAAAAAAEAreOEMAAAAAAAAAGgFL5wBAAAAAAAAAK1oNYZzJmFSkzghw7XcTNJAjceiw5nYTS6JzdSpUzuGSzF+IuqxYDIJczSRiyYIjKgnCVy2bFltGk0S42LOaFwjjUPUNIFWKZmbo3XVJFlaJoGSS+Y2ffr0jmGN/+SSxGnsosyxmEmWl4mh1W0sqIh6zKpMfJ9MQkCdxiWsKiWazCSIcceQHq+6bpcop5QQMKIeU0yX45abmUbL67a7FCPL7dvSPBH1+svEj8vEnNPjXudx50UmsWCTpIGqjSSCbjnbUmLBwWSS/2UT1WXHZZPhZRN/OdmEc+440fu7S9TmxrnfG+53iost58qRTXyX+Y012LyZxMquzrOx7zLxBgebzq0jk+Quwh9PLtGdu28od9y4srm6dMdEJlFlRD2+ZET+WMwmpnT1mfkd7bhzziXczJY3ew5nk/q5feaOCb0+9XKty17/ssem+z3SNGl127L3dhIEjk3D8fuu9FtDz+1SrFo3rhTDufSbuvQMo+eku6ZqufV6p9f60jWo9Nu1yXNBaZ2lZ3CN2azvWmbMmNExPGvWrFqZFixY0DE8e/bsjmGt29L7Bnet3ZLen3T5mWfwUixid4wONX1JJvlz6TwpHdNab7p8fZfijvnSOrrdblV6j+jOe52m27jRJaP13kYLZwAAAAAAAABAK3jhDAAAAAAAAABoBS+cAQAAAAAAAACtaDWG80hpEp8kE/cpEydHY9BkYt65WHEuju9QZYuox7BzsfU0FtDKlSs7hl0MZ43ZPDAwUJtG4xNmYutqbCUXX6dJjKdMDGctn4ujozECdRoXn0q3adq0abVpNGazxojKxHB25dV9oHGA3PGr49xyM9OoTHzVUvylTFxBd5yVpsnEEnTHUCnWsotlqPHBXAzEUmw1VxYdp/GaI+rb7a4Zuhw9hprGr9JjJnNOKnfMlGKDu/ikGU1i/LURW7lpbGIAAAD8j0yumtJwKRZx6TeZPnu5+P2l5zXdjm7LpM8V+uzhtkF/P+uzfrcxmktK8Zcjys8OWgbdTn0u02cyzamkMZw1PnNExLx584rTbEnfzejzkZZZt1njTuuxksnLoftWn6VKeaxK50gmt09pmVqGUoxnfcel9abzu2d09+w8VBlV6RzQ87i0jW6dpefRTJ6qobSRw6gNY/KFMwAAGD3afnGeeQjMjnM/jrPzZpOxZhPOuXW46UoJiyNyHya7Gee2wdWdW68b537sZxIkunHZbXU/8DMfY7vhPiw6mY+UEfWH4oh6+dyy3AN8Nsml237XgMIlnHSNHdxDcSlR0SbuGNN1uGMpm+QvW95sPWU/sGY+mEf4bdM6yXx0Hmyc4+opk0y5m7Jkr7vDbbQmUQIAYFtASA0AAAAAAAAAQCt44QwAAAAAAAAAaAUhNQAAAAAAwKiUycfUa0zn0vI1bJMLT6MxdTVcTymkk4a30ZA1GppGy5TJd1Kqt25jy5ZCDWVC7JS2W8NZaYgqzavU19fXMaw5lfr7+2tl0jxMukytW90urTcNQaQxm3WbNRSV5uaKqOcGK8V0LsVw1jLrfmmSK6kUw1uHtZ5K9Vo6ft00qpRTqRSiqlQGd543zZ2ULUMbMZuHIwzVuHnh3O2F0c3jTkg9afWkziTucxcLvWiWEgq4da1YsaI2jY7TYU0iGFG/cGXi7rmLTSnJWiZOndtu3XeZBHB6kXCx+XRf6oXBXRT0RuFiL+rNSm94Wk8R9W1yx6LOlwlOrz+EXF3p/h6ui1NbF9nSTcwdZ5mbiB6vmtzRJXvMJA0s3USdzDGu4zLnjsrsE1dePVd0PZkbfybWrq6nSdIRt26Vjfvb63rcNCQNBAAAAACMN+PmhTMAABg9son5hnv5vSQSzHzsGWxep2nLgUyLksGW7z5GZhOkZT9kZevJyXzsL7XQ2SSbSNBxH7TcB+LsOG0ZFVH/IB2RK7Nbln4Aj8jXeSZRZYRvgJBNLujmzZ53ui/ccej2l9vXrrzZ48StN7sN7gO0Sxrp9pnOm/mYPVg5sslLs9eYbLJCt12ZD9gAAGD8IIYzAAAAAAAAAKAVvHAGAAAAAAAAALRiTIbUaCvGbCawtsbA1a55Gv84ImJgYKBj2HWhU+vWrSuWRWM4L1++vDbNAw880DG8atWqjmHX7VG7s2W61WW6lGa6BDbpXp2Jb6vLdfF3tYtqJti7dmF1XVp1XRob2HU9zAS/L223O2YyXRVLgf4zMZEz69ZzyW1jprylIP7u+M3EcNbjU/etO491nO5rt+7MMa/bkOn+2iR+cKa+M+XV+nTXhzZiOPcSymCoeTLLyEyTuac0WTcAAMC2JPO7sfTs1u2zU7e5T1x4nlLSQA3fU8pVpP9vI5GhDpeeB3qtR/f7vfTeQJ+pSnmU9JlMcyhpSKvZs2fXyqTL0HJrPWk96vGhZS69G9FjRd8puXH6fkjDWenxoftSy1x6TnHPePquoJQsUfed7iv9v75b0XrLlEmn0TKVco9pPWq9ZXJrdZucs6SNJIEjgRbOAAAAAAAAAIBWjMkWzgAAYHTL9CwazNZoCZ5Nhud6fTiuF0em94ori5svm5TNtVzSVjkRvlVUL60lssnVXPm0LNmEhq73ipvXlS2b5M3N61rXuB5QLvmf63mmLWNcOVyPGlcOV+fZ5JLuGHPldeNcyz/HHduZZblzM5sMMdPyaDDuGHPHhNs/TRNYZlpvRfj96rYre23uJWlg9vwfLb18RmvLMAAAxjJaOAMAAAAAAAAAWtFqC+c2vlK39aW725hMEblWQBonx8XW0VYtrhWGthrRlhDuS7vGedb4zK48uh5XD9pyIhMntUmsHDePawFRWrcrX2ke16pE920mBpZuY7ZVx5YyscLdunVcJlaQtuzJLDfTyqdJvGBdriuLcmXROs/EQ9LjIdNCp3Q8u3FuubqczDGvmraALNV5puVTtsXUlkpxtiP8eazbqedopqVek1ZKwxXDGQAAAL3LtMzX36el4dLySrlPXG8hffbW396l34qlderytAyuZ4rOo79p9VlF30toGbSMpbwy7hlKe+7MmDGjY1jj+nYb51e3QYd1/oh6PXQbp7d0vOnzUSmGs8adjqjXg+YTKz076Tp035by52R6/um7MN23/f39Q/6/lCMp846p1xjOup2l9zCl8z6ifB6p0vWo1+GRQgtnAAAAAAAAAEAriOEMAAB6MtZad2fL63oXZGOnZsdl4jq7aVw5sjGSXVxbN65pzO3Bxjlu27Qs2fi6rqeP235XNhdz18VcdmXJbr8b544xbVmTjYfrjES8ZjdvNu6y2zYd58qbjU3tWhm55WV6R0XkevBE+JjgGzZsqI3LxJjuJTZz9pxwMsfmYON6OWYBAMD4QAtnAAAAAAAAAEAraOEMAAAAAADGjOGOaVqK4et6KGiPj25j5qpSjqFMThztcaHxi5vE7d2S6+WyJY2XGxExZ86cjuF58+Z1DM+dO7djeNasWR3D2gOplDMnk4+q1LusdLzoOnR52kNGy6A9rTSWcUQ93rHm+FL6f+1pozGfSzHHMz1/NJ62lnn27NkdwxqrWo9XrSfd167HX7dxn3Wdup16jugxr8Muvnsp5nfp+lSKEd6kt+lI9FBNv3BuqxvUcCUWzHa33FJpJ0bUbxLalXDlypW1efSi7G4kq1ev7hjWg97t/ExSAC2vLsd1GdV1u/LqctyJXUqglun+m+luWrqBuHFuu/UirhcB1/VR963bT6UfEu4404t7Zt+WgtdH1I8Zd/FrcmPRaTLds3XYlVfrJtOdU4+7bDdTVUos6LrRZn6QlY7fjKZdU0vnV6b7beYY1zp3ZcskTyz9aHbXpsz5NVw30zaWmw27AAAAAADAWEFIDQAAAAAAAABAKwipAQAARkS29Xabrbx7SbjVdtK8XpIVZpbltivTM2CweZ2mid8i8mXOzNfLfnVlW7t2bW2cSxroej852YR7bnm6HdkEdNmEdq4Lrtt+N85tg+vl1EuiR+3tkk226Nbplp/pYTWY7HSunlx9ui7T2ivPnXOuO7iT3dZs0kSSAQIAgCxeOAMAAAAAgDGr25inpWGVCYGoHwP145POUwonVwp1qCHr3EcspR8n9aOmxlwufcwsfXTSmNER9ZjM8+fP7xjeddddO4Y15rOWsRRzNxPrWj+o6Qe7UtxfXWcpbnAphrP76N3f3z/kOrVe9PjTD58a5lU/SGs4TvdxshTuUrdDYzrrsM6v+0XX5z7Kl+q2FAq2FDtdz3MddteGUgznbod7jVE/Ukb8hXMbFdNkmkxLGNfiRw8uPWkzcYldyw+9GOiJk2kZ5aYpnfCuRUTpAh1RP0HcjacU4N3Nk2kVUbrIZOL8OqUbUSmJQ0Quvq3WndtmXXcmCUUpyL+bJhPDOdN6R6dx6y7FmM7ECnfHTJNY1plWX6XY4NkWjKr04zfTqqjpupvEcC4lSIkox/1uek7qunVfu5t35od7tzdoJ9PCMvPgktn/o+UHAgAAAAAATRDDGQAAAAAAAADQCl44AwAAAAAAAABaQQxnAADQul4SBGbCnmSTxmWThmUT6fUS8iSb1E/DybgwS26c2y4nG+LKjXPzunHZpG4u3I6uN7u/suNceB6X0G1gYKA2zpVXw6RF+KRxK1eurI3T+IkRuWPM1XkmVNVg63Tb6urEHXfZxIzZYycTOi2TWLObeZuGrorw9e5CmGWTNWqsSVcOnSbCb1cmTF5E/lrXyzVxtISLGi3lQHfaCKnZbSi00jrdvWTVqlUdw3ptXbNmTcfwzJkzO4Y1XKcOa8jKTGhMvV7osIbF1OHSOkphSl1caY3bqzGa582b1zE8e/bsjmHdBt1Xpd9Rrp663c5STF7d7lL4Ud2mvr6+Whk1dKAuU2Nj631Hf4eUEtBqvbr7h957uo1VXYqvXFqfC3Gr9VJah+77Urx2/R2l93J3bSiFAS1df9oIEbk10MIZAAAAAAAAANCKMZE0sMk03X6hjMglDdSvFa6li67LtXLQryq6HLdc/XrjWtRMmTJlyHlcFk9dV6YFlmttUfqa5VqxZPZLKWlgJhmZK69+Vcok4dN6yLTMUk0TWGp5S+WPqB+vTb62ZVrCZFqflc5Rx9WDHkeZZI/D9QUws9+ayLTcarJNmWSEupxMMkqtB3delLL/RtS/wmsrENc6TI/pTKvPJvcHZ6TuZwAAAAAAjCW0cAYAAAAAAAAAtIIYzgAAAAAAYNzoNmazDmtPQF3ehg0bauvU2K4PPPBAx/Dy5cs7hjU28bRp0zqGNfasi1c7VBkjyj2rtWelDmtPQc1RoL0NS3GGI+o9tTXesQ5rL24Xx35L2rNSh9uI4VzqzavbUNqXWk/Tp0+vlVH3jU6jvVA1tnC3sa91G12Pat2Obnunl4Z1v5SWH1He/zpc6uGr9aix2fW8z/Qq7zaGfLe9m0dLj1leOAMAgBHRNPlfNtmeC9Xiwqy4H4LuR3Q24WA2QZ7bVhe2RsvnEtC5bXDrdMlXXAIfV7ZeEglmQo5F+P2jZc4mTXR1mU2u6JK3Zfere5h2+6dp0kC3Tlc2dwy7eTVcUUQ90VWEP+4yoa4ickl8Bpuu9GA4mGzSTHdsZpML9pLANBOiKiKXNNTJHq+unrLnTibc3GDrHe6HX0JUAQAwuqRfOLd1w+72S2NELkt0r18AstO4H4ZKf3i5H2ylH9Puq51+CXTT6I/oUqZbt+7MDza3T0rrcj/wM7FUS19d3YNI5pgpZeR19as/0t2DvJZHy9sk1q6TeSDNxFrW41OP8cwDrHvYKMUzzmSJd3Wl5dGHerdP9FjMvETKxLLWbczEXm5LJga21l/pXHLcftRjRh9A3XL1/HfXRX0JUhqOqLcuccsttVAYbTGcAQAAAAAYy4jhDAAAAAAAAABoBSE1AAAAAADAmFXqRdZrDGeV6a23bNmyjuH77ruvY3jOnDkdwzNmzOgY1pjOpXi5rmei1oNOo8Paq1PjJ+uw9hLWenM9rEtxekt0eh3WHse6bzM9bbWMup3a+1zp9KVe0Pp/refMNKX42fp/Daely9PQWq5npuvFPtQ8pdjX3cZszoR102Xq8aA9pjXcmZ7HGotd69HFd9fzqteYzWMlpjMtnAEAAAAAAAAArRjWFs6Z+JWZWLClL1huuW3F0mwj3qaLtdok3rF+RXP10G3WTzcu84UxkyBGh91yMzG8lX7lyiQ1ctOUvpa5WMClGNlumkwM58w2labJxM3NxNHWL5+ZhEuleM1O5jjLXA/0WMwkA3LT6P4uZXR2Mud6Zr+VWh4MJ11XJsmRHiOZZEEuodaKFSs6hjUDsEvqVcqMHVH+opzRRi6BrG0trnPm3uvOAXfuuOuVa2Wwbt262jh3fLmkaS7xmbsn9pJIUI/ZbOI7d51yLWTcOKdJfP5NsnXi6lPP42xCM7evXf266082CaNbr8v54MqciUMf0fwa4JbltsEd/26cO8bcfnWtvFxiykzei4hm98nBZJMBun3oyuvqM5usMZuEs8n9JiJ/vrpjPXuddPNmr0+ZXCMRzZ7PAADA6EMLZwAAAAAAAABAK4jhDAAAAAAAxoxuY5a2HcPZ9WTRngEPPPBAx/Bdd93VMdzf398xPH369I5h7UGiPS+a9PzVeUrD2hNFy+B6Kg21vIhyD1vtTaHDpR6v2ssi03OiVE+lelClXq6lmNGZ3tZa96VeqKUevVpm/X+md12p93zpvNT/l/aD692n69TePqWYzffee2/H8D333NMxrOe19pJ0PX+0DKUet8Md03mk0MIZAAAAAAAAANAKXjgDAAAAAAAAAFox4iE12kju1zTBhio138+Wr8TNU+qy45J8lLoXRJQT1jWZx03jkuVp9wY3jcokjSzt/0ziFNflyY3bkqsHlenCoZoe46XuJC7xjtZvZr+VlhExfEkDM/u2iSbncamrV0S9u4xLnKRdnZokOXSaXBd1P7lER7pNbhodp8mGMnXlkrGtWrWqY1i7N7mkRrrcTKKizP7PHItt3Q+2Jdl6zJyz7rrjjj13rGlCyoiI5cuX18bNmzevNi6bDM1dbzO/ByJyyXzdtdslA5w2bVpx+YOVwyUIyyaXc9cxVyeuK27m+uvGue1yx4nr6uiudZkkpBG+nty+dutwy8uUw60zW97MtT8in1zPHWPaLTzC7+vM7/dMHUX4Yzi7DX19fbVx7lx3+9UlHHV17M5Zd+0odXmO8Me6qyd3/LuyuW1w49z5n+k6HNHu9R8AAIx+xHAGAAAAAADjRrcNvDINtYZafkT9Y6B+4NZYsPrBToe1MYt+uNLpXZm7jWWtdJn68VDLkGnMph+q9GOWfvAqxYkuNXTLNI4qxcMuxTfWenYfBrvh5tdxuu/0w2Ppo263caRdPZbqSYf1GO41pngmRrh+aNVGTffdd1/H8O23394xrLHXV6xY0TGsx69rANBtA6ixEqO5hJAaAAAAAAAAAIBW8MIZAAAAAAAAANCKURdSo0lsTUeb1pe6imTLU+q2kKXb0CSetNumJk3tS10pIspdISLqXV2adCNx3TR0nNZ5Jl6si3Wo8WB1mkxMykys3W67LUXk4vHqPnAx/pTbpky3FNUk9rrKnMeZYzzz/8wxU4pL7GIZanxHFz9Vu8KVYjpH5PaB1l+TGM7uvNB4ty5eo9aFLsfFWs4sd82aNR3D2t3JlVfPdXcNKZ1zru4yMbLHS1cnAAAAAADaNOpeOAMAgG1b5gOr+wjgPia5j0UuQeC9995bGzdnzpzauBkzZtTGuaRpLt6g+5iUiW3oknxlkstG+LiG2YRjmsjTlW2wed0Hl2zStEwiZVcOJ5sgza0jm4TNjct+dC8l7o3w+9qVzY3LfGAdjNs3vSQNdMei2zatT7ev3TUhmzTQJfh1SQNnzpxZG+e4OnEfVd22ug/VurxsssVeEqnqB97Bxrl5s0kDs40I+FgLAMD4wAtnAAAAAAAwZnXbC1I/gpQSy+mHnkyvSv1Is2zZso5h7S2pH7/0//pBSj/klZLrNaHr0DIpLYP7KKUfPvVDsPZ6LCVPzPRM3JL7GFnqTVza/6UklKrb4y1ThtI69PjUMurxpfs60zNXPzjrh9XSR9VScsbSfomof2zVBhSavPMPf/hDx/Btt93WMXz33Xd3DGsyUO2F6/Zt20kCx0rPWmI4AwAAAAAAAABawQtnAAAAAAAAAEArxkRIjUxysVICrcwyMjJxJbUJfSaOWZOkgW6azHJKMjEmXWzCUp1nluu6aWjXD91Gl6BMu+W4WHraxUnX446ZJt2UMkkDM/tJ61zncXWn63L7QJfbJGlg00SI3a4nor6fmpyTmZiWesy4mI86zk1T6kaUiWmZOXcy+03rzsXxbJIAUOdxMR61Pl0M1dJyXXl1m5p0YWpyzLtxTZJpjtbuTwAAAAAANDUmXjgDAICxJfsyvemL+VLsu03cRxOXNFDjs0VEzJ49OzVu1qxZtXHuI6D7wORozDz3Ic0lG2ualC+i/oEnwiehcx+L3Mcg92HalS+TXNHta/ehKFsOJ/OBczBuu1wdu+maJg3MJs1025BNrufqzh1Pbh+6cW5eR/e329ZetsGdO9nEh9nEnG6cO8ZcLNRSPMuIfFI+d/1zyUA1HmWETxrolueOu0xDhJHgjh0+9G679LjU4yPTUGdLmd8vel/S8+q+++7rGNbrjiYq1hjPej1z14tSAy8d1mVogxr9v14/9XeCu77ob45SwxS9VpbuJ7rNuq8z9aTTlOJGa6zqbhtbNWlcqNdfPd60TDq/3iP1eNJ6dr8pdDt1X+kxrf/Xe542zirFbHb3Q23EtGLFio5h/c2vMZz1//rcoMen1nP2GWUo46WREiE1AAAAAAAAAACt4IUzAAAAAAAAAKAVoy6kRpN4zY52iWirCXqTrg6uW1kbXc3aiik6XDJxaDPxg3Wcdh1xdanddNasWVObRrtaaNcH11WnFEfZjWsS19Upxch23UabxPnNxAFvEiu8SVz1TF1luqxoeV13IO2CpN133PGg41wMZ+0WpN2GMvHQM+dFpj4zsay1S5AOR9TrKhPDWbvhum65ulwtX6ZreJN44k2vi01i8QMAAAAAMN6NuhfOAAAAAAAATZU+/JcaBXUb0zmzDG2kofGN77333o7hmTNndgz39/d3DGuMZ9f4RRu7dBuzWRvPlPIsaJxq1xhEG5FoIxONkVuKVa3rKMWpdvkTtBFQaR2lxj+ZxPZb0np0DW1KCeA1FrY28NH5tR70eCvFrXbjdB6N8a3HVylGeClms8vfobkKNFa6nmc6vGzZso5hbbyo69QyNWmM122jxbHSsIkXzgAAYERke3g0aak+GJcMzyWw0R+bET4Z4Ny5c2vj5syZUxvnEo5lHnAi6g932cRXTZPSDVYO1xNByxbhe0JkE8658mV6qWWPG1e2zEPcYOvIctufTRqZ4crmXob0UneuB1F2XLZ8rp4yvcnc/uolUWX23HTHsCtf9px151PmOHF1nk0Q6JKm6sP1YPO6dWTPneF+OM7WOYkEAQAYGcRwBgAAAAAAAAC0otUWzm3EX27S/DyznKbxYtvQZLmuvE1i4GbKkunu0cY2uPI26d5S6griZGLVZrpNZeqq1DKvjfjdWZnyaisZnca1osnEzc10O1NNYutm6jOzTXo8aPkzLQdd7GJtqaTzNDmPI+rnRWY5mVjWOs5No3VV6t7lxmVaHZaOzYiR617UJF7/1mjhBQAAAADA1kZIDQAAAAAAsM0oNcwpNZ7KNBDTdWjjCm2souFt7rrrro5hjeGsw1OnTq2VSRupaKMaDTOkjWVKw9pARBvXuFA8Gu5Mp9H/a1xorWdtyKLhijROsAutVNq/peNF66Hbhpa6DZkGPFpPGmtYY2Hr8af1oMePDrtt0nJrPZQaX5WOT6XboNscUQ8ddf/99w85vGLFiiGXWYqF3aRB4XiJ0VxCSA0AAAAAAAAAQCto4QwAAHqS/QqfDTPS9Ct/JhN6hG9to60bIiLuvvvu2rjZs2fXxmkLowifKd6VL5MgzCUqcy1AsuNcWCEXNsitVzPFR/g6dlwSNrdvNQyWa+XjQhhpC6iIesb2wca50FvZ4y6bDC+TINHJ1FE3sgkCXdlc3bljIpuYz7WWahq2y41rWueDrTdbT9kEkZlzwu1rd/y7ZKgPPPBAbZxLkKqtvSJ6SxqYDc/XZuipXu5DAACgfbRwBgAAAAAAAAC0onEL56aJrprItHRqI6Gem6dJ8sHRLNNaw7XUyCTDKu0Dt1ydxrX00HFaXteKLBOnSWMeNUlQ1yRp4HAlEnPr1VYxrpWMjislbnPrysQtaitxZ+l64MrbRJNjU4+piFxSyyb0fMrUbyYJn06T2f86TSYZYWa5o6kVUpNWuKOp/AAAANuyXmM2N/ntrXSd2oNHY8dqL4U777yzY3jmzJkdw9OmTautU3tc6DSlGM0aD1mfq0vPge75SJ8/dbv1uUF7V+i+1HrUnjf63JHpwaX1UEqsrsPdxoDWbXA9WXSc9jrSetTptQy6zdqLr6+vb8j5XRlK+6rb80brqRTfO6Ics1ljPGuPnuGI2VxSem4cq8+VtHAGAAAAAAAAALSCF84AAAAAAAAAgFaQNBAAAIwqbYavyiZc026IET6R1h/+8IfauBkzZtTGuaRhLvmdS7hW6t4a4cP8ONnQTw8//HBqOrdeVz4XWsd1q3XhdbQsLlGZ218u8ePKlStr41ziO7dvsiGR3PHaS1JH1UvXzWziO3dOZNfbNBlghD929JzNHpvZRH1uW90xlj3WHVe+TOi+iFyYKpfQz12v7rnnntS4ZcuW1ca5bsruPHHlc9vVNJFgL6HoxmoXZAAAxoP0C+e2YiKrJj8qMvGDm/zAaBI/NjNN5kdXJg5tk+Xqj0D34zkTj0ofJrI/GkvzNMlErmVxMZynTp3aMeziWWnd6I/oTF258upymzxMNjl+Mw+Q7mFft1sf7JrG2i0dr5mHscxy2yiLo2XJZKZ3+9o9KJc0KV/meps53zJxnpvs2ybblDnfmiw3o80HXgAAAIxupZjO+v9MfiJVeubXj1/6IfXuu+/uGJ4+fXrHsHvmLeU20mXo9Pph3OVG2lLm2Vc/3unHYf3gpbGItZ70eVaHtd7dNmis6tK+7DYGuJah9C7CxXDWj+2lmM26Dt2X2mBi1qxZHcN6bLgPjErrRd9HdPtcpueIvs9wH2A1RrN+VB0YGOgY1norvQ9p4xlwW8kFREgNAAAAAAAAAEAreOEMAAAAAAAAAGgFL5wBAAAAAAAAAK0gaSAAABgRTZMBuvmy4xwXD9zFuHdJ6O66667aOJf4z1m7dm1tXF9fX3F5GlcwwucZyCQgi8gnknMJwlzCPRdn0I1zMe3ddLov3DQuyZuL4+cSn7nluTpxMR57SeCXlYmLn92HmVwTEX7fZI8nx63D1btLOKhlzuRQiPDniTs3XdmySS4nTpyYKktW5prlyuGSYd555521ce56dd9999XGuWud21/Z5JLZvAdN8+eQVwFt6Db/UCYXit6bu43prNci/d2g56/GW9Y8Rm4avVbq/7XMep3W+XWbNT6zu86XyqDzaJn0t4jWm1439TeD+w2hv3n0eq/bWUreXIrJq/c2vQ+7a7AeD6V60HrWmM39/f0dw/qbVPeL+62g9wXdLv1/KT9Xafm6ze5+qDGcdRqNfa37XutxJGI2l6Yfq4b1hXMmuZ9qmliu24u5G9fWj5cmDwp6ULsfvnqyZU54nSaT3MBdPJskGytdXCJy+0DLo+t25dWLq7v5ah1nstHrNK68utwmyTMzx0zpJhVRv3i6hxYdp+VvmqitjUD4Ta4HTZLcOZkEhqVkESNpuI6zJtfApi8CM+XrdhluXJOyNF03AAAAAADbGkJqAAAAAAAAAABawQtnAAAAAAAAAEAriOEMAAAAAAC2WaUQfE3CfGpIyW7Di2rIRM1LcM8993QMu1j2mo+g29jEOr+uQ0NO6vJdaMtSeFHdbp1e16nTl+JQZ8KM6jS97stS2EoNR+ryaOg4PUY15rLGaN555507hufMmdMxrPtKt9mFDyzFAHehYodSyuOhOQfuv//+2jI0hrOeN7oOrfvhCJPYRrjRsSj9wrlJzNMmy8nESW0aj7nJPKVp3DZn4pDqiacHuUvKkYnHqwHwM4lMdBs00H9EPV6wS+BSChjv6kov/u6CVEq+4Mqi07jEP6WLY4Zbd6auVJN4xpnjQS/QLkGC3qC1vE0vfsMVV70Uy7ppLPZSzOYmseMz2kqi1tY1r7Se4ZymdH3NLKOtuM+ZacbrD4O2DHdM82ys8GxCL3etdglbHnjggdo4l0jMLW9gYKA2ziUN1B/8LvGZu1dn8gpE5M8Ttw3uXpNNJOimy8yb+U0U4e9x2eSFLh+EO55cfWaT9WVzIpQeQiP8NmST4fWyPDevG+f2hfst5s7PzPHpzjn3UiOTQGuwsrl1uHwf2WMnex/Rend16ZL86YuniIi77767Nm7ZsmW1ce48dMeEO9az90KS/wEAsG0hpAYAAAAAAAAAoBW8cAYAAAAAAAAAtIIYzgAAAAAAAP+PhnfJhIsshYPrNlycrlPDWq1cubJj2IXb0lBAus5SrGGth1JcXw0z5MLk6DK03C4c0pamT5/eMVwqs4ZI0vkj6uGWdDu0zN2GpSyFCyrFkI6ob4eGg9IwbaWYzdOmTesY1m3WbXIhpDSmt06j+0aH9ZjWEE8ayu6uu+7qGHbhpDR01Nq1azuGSzHCS0qhLZuEDh2v4aRafeHcRiVlYtm5AyIbo3EkZGK/6smbCRKvcQib3FAcrbtMfDpX303ir+oFx627FOQ/c9y58rr6Ky1X91smPrfuy0wMR1dXOp/G9NMLaUT9gt0khnOTmLhOZhtL87hxwxWXuElZ2lrX1pQ5b3v98RyRq8+26q6UByAbaxPd2RqxObNxnbPHlotNq4lHIvw9xsU/dXFX3UOPxmx2MWddYiAnG184O6+L6+vuLdm4zm6c3jezsYndOLcf3HGY+U012PKyMZEddyyWfiN2M66X8rr6zOQPiYhYs2ZNbVz2t3rp5UWEP/7dCwoX/9zNm93/rixNtysid8y6+nXx4DVJUoSP1+yuYW6/urJxbwQAAFmj5y0tAAAAAAAAAGBM44UzAAAAAAAAAKAVvHAGAAAAAAAAALSCpIEAAAAAAAD/TylmuctzUMprojHfe00iqHkQXNz20jJKuaRKuVBmz57dMaxx8jM5ujQ+fimXRaneSvlaNPmeG6fzaHx9rXutR93Xuo2aJ0DrTRP6RdTzDWjSwP7+/o7huXPndgzPmDFjyDKUcjm5nAW6XTqPHk9ab5rfRJMC3nLLLR3Dt912W8ewSxq4atWqjmHNU+DO3aF0mySwSR6q8WrUvXBuunNK2VMzSYPccpskw8ooXehd8g49mXtJXLKlTEbUTF3pNpUushHlG5gbp8sZrqRsbrmZhIWaZEVvTtnEPErrSi/WLkGPJhJ0x5Uee6UMu04m6VrmGBoubZzHmfK2lQhvpBINNkkImJmm6fW2lCA2c31rkqhuW7nhj1Zt3fcHk7mWD8Yl13MJvFxZ3LXeJetyCQE1+Vk2aWDmPhuRTwaWTRqYSXQckbsHuXGuHJlryGDTZROFuqRxbhv0gW+wdbi6yyQJ7iVBots3bpyb141z+6LbB7ctZc5jtx/c8e+OuWyCQHfuuHGuLNnridtnmQSObrtcomj3O9CN21oJArPX8W31oRwAgPGGkBoAAAAAAAAAgFbwwhkAAAAAAAAA0IpRF1IDAAAAAABgtMiEe9EQQ6Uweb2GitRwOOvWrSvOo+UuhYPU/5em1zjCLuyU0vjJGr5IQxeVptd6dCG3lO47DaGmdatxgrUetIwaLk3L7MKnlcqo82iMZo0DrSGl9FgohTd0IbR0uzV83PLlyzuG77///o5hjcH8hz/8oWP49ttv7xi+8847O4Zd3HLdVxq+KnM8DKVJDOdt1Zh44Vw6Edw0KhNT1MVga7LcjG4v9BHN4lK3UbaIep27mHN6ASvdCNw0mVibTeK4umOmFD868yPCXXRL8bhdLD7d/668ulxdjosrquMy8RgzF+Am8ZibxDJuGj+6NE3TGMNqpG4mIxmnPFNXpWtR01jLTWSOq1L9ZWO8AgAAAACAsjHxwhkAAGw7Mh8Ns4nfsrLLc2VxSbjcB0k3nUtqpgnBNFt7hG8x5D7sZpMBZsdlkpx1M84lK2vyIbQbLhmc4z6euTp2y3N15+bNyO4HV5fuY7Q7DpsmdBysfJkP/RG5D36u3rLJELP7y53/2Xmzx1PT88ntm2xSTlcn2SSPvXx4pXUXAAAghjMAAAAAAAAAoBW0cAYAAAAAAEjK9ILK9ijYRHtMZEJqltanPSK03DqP9rzQnhK6vDVr1nQML1iwoGN49uzZtTJpbGENs6mhOrXHSSmUZymGc6YHj/YQGhgY6BhesWJFx7DWk/ZO0zJpHeg2ut5tugzdbh3WfV2KZaw9ZbTHjetdo/Vy3333dQxrTGaNwXz33Xd3DGuM5wceeKBjeOXKlR3DLm657ouRjtnsrg3bas8fWjgDAAAAAAAAAFoxJls4Z74YtJFIymkyT6a8+mXRxTlssq4myfNcDED9GuZiTuq4UhbViObxDLfktimT3E/H6XZn4l66uirF3svE3cvsg0yMP11ONs7iljJxTduOpdpNeYYraWAmu/Fo2sYmZWmaTLU0TdO4j5lkgypzjdPl6jRNj/EmiSYBAAAAABjvxuQLZwAAMPZku5hlXt5nEwlmPkIMxk2XTYbmPhxnE/Ppx0L3EVK7TUbkP+K68rp1ZMdlE8llP3pmPhpnuX2YSVQX4ZPBuSR8bnlu/7vlZY7F7DGXTejoPlD3kuTRjct+pM3si16SErr6zXxIjcjvr16SBmauHW4/uGSAbj/0cqxnP6K2PR0AABgfeOEMAAAAAACQlPmIoh+aMrFeh6IfhzK9IktxejUWcSmW8erVq4ecf/fdd+8Y3nXXXWtl0jjPs2bN6hjW+Mb6sa8U41llekTqhzyNTb18+fKOYY01rPU0ffr0jmHdBi2z9hafNGlSrYylZahSAwYd1p7Yuq+1DiLqMZhvv/32IYd1+mXLlnUMa71rjGY9ft3Hdt2/3Z53peOl1+VvS4jhDAAAAAAAAABoxZho4Zz5YqBfGZrEAm2iaezaJl9BtEtdk8y4ma67mS6ZrntfKeup665Xyijr5tNpMt17M11AdZ5MDOdMF1T9Cue64+rXxExX7Ex8Zh2X6eI6UrFrt+aXvyYx3bPdsrudpkkM6ra45WbiMZemaau8meu41m9mP7UR09shpjMAAAAAALRwBgAAAAAAAAC0ZEy0cAYAANuOpr0HehnXSyLBbGt21xPF9WjJLN/13HE9ibI9sTI9oAYb5+bN1nsm+VvTxJLdcPvVJWZz3Pa7ebP7JyN7TGSTPGZ6rg22vGxSxzaTy2UT//VyXrttzSbca/O8y55fvSQ+dLKJH7PTNe0VCowlpWPanS/d0POo1BM4Uwa9X+n/9V6gMXUHBgY6hjXOr4v7q/PstttuHcPz58/vGJ49e3bHsPaSLvXYLfVAjohYu3Ztx7DGpr733ns7hu+5554hl9nX19cxXIpDrcMa0zmi3Dtct1v3nQ5rL+uVK1d2DN93330dw3feeWetTBqj+Y477ugY1nrS40GPJz0etcxNenCX/l8aJmZzc7RwBgAAAAAAAAC0ghfOAAAAAAAAAIBWjLqQGm11o22SRLCNBGDZeUrLyXSfa5I00HU50K57me6XmaR2atKkSbVxWp5Md0jdblde7Yrhylvqspjp5ui64+g4HdauK24a141Vy1M65t00mWNxpI7xpsvNdLVuokm3Zj02M93khitJYFvz6Lhst+WtJVPe4ToWdV3ZbuUAAAAAAIxno+6FMwAAAAAAwFg23DGdM0oN70pxfzW2cSkessbkXbNmTW2dOk7XocssNRSbMmVKx7DWqy5v9erVtTLdf//9HcN33XVXx/Af/vCHjmGNTaz1otuo+0FjNE+dOrVjeNq0abUylval1suGDRs6hrWely1b1jF89913dwxrPGatg4h6XGetR40LrY3vtN5KDSabNJZrO0YzMZvzeOEMAABGRLZ1vE6Xna+XpIFONrlWL4m0Mj2PsuVwPX6y3LyZhH6Djcv0oIjI9Uro5Yd9dv+7HgquvC4ZoJu3l94hmZ4b2ePLlc31osr0rBpsXDZB3NboHZM9dnp56ZM9/rPnf6lH22DLd8dJLwkC3Tqy50mbCQJJNggAwNhEDGcAAAAAAAAAQCu2egtn/UKdaf2QaSFQivubXW6pfG19Yc8sJxOPWacpdT/JzOOmycQq3X777TuGXbxjbVGTaTml63atjYYrhrMuxy23FMPZzVPqShLRrDtJJs5zqVVPW7HNM+d6k21qosm57mRaYZaW07TFVxstxTLlbXJNbrqP2ti3mVZfTequrWOGVlkAAAAAgPFuq79wBgAAAAAAGM/GQkxnpQ2hSrGKtVGXa2ylsYU1rq8Oa+zh+fPndwxr/GNtBKINwAYGBmpl0pjMt956a8fw7bff3jGs8Y+1IZ3Wi5ZJYzjvtNNOHcM77rhjrYwa11mPJ63XVatWdQxrfGWNv6wxm/X/WkcREcuXL+8Y1u3WMpUa/Q1H47JeYzTTYKg5QmoAAAAAAAAAAFpBC2cAALDVbI1EYtnwN02TvA2mzXAz2UR12VBK2WRw2W3opT4zYdF6aQXWNHljN/O2uf3Z+TLhuCJyodMGG9dLK5+m53q3rfFK2k4umj0W3fZnzs9elt/2ta7tYx0AAIxfo+6Fc9N4saU4v23J/OgbrpinbcR5zvygbloW3W7tBqLdRCLq3V9cPGZdl3ZX0S42ERHr1q3rGHZdeUoxm90DmS7HlVe77GTiSWfiR5f2ZebYbLL/m2YHb+O4avJgm4nh29ZyS+sZSU0e7po+JDbZT03i3w/X/tdzRePNZ5XqYbjuQwAAAAAAjGaj7oUzAAAAAADAeDYSMZ11HdrQQhtmlBrQaJm0MVimUZTOow20tEHZihUrOobnzJnTMayN2HQbtcHX6tWra2XS+MZ33XXXkP/XZWhDE92G0n7Q/2sc64h6DGetW51H601jMP/hD38Y8v+6zRoTOqLe0E/3ZalBZEmpgY9bXq8xmonZ3B5iOAMAAAAAAAAAWsELZwAAAAAAAABAKwipAQAARhWNxd12Mqy2x7mud65LajYxWdOEW70kCMwmnHOy8eubJmF0y88mYMvWeS/zuvL1UidNu3K2vf97SRCZlZm3l/MwWydtJ0PMnv+Z8vWyH4b73BwOTXI+AACA0WdMvHBukhyt6cNqad1NEl01+XHWS7bsLekDRJPkXm5c5uFvhx06D69JkybV5pk8eXLHsEvepcvRGEwuvlEpdlBE+Qe9SxqoCQF12K1by5t50GuStbytH+RtHa+l8rWVwDJzbJbmcePaSsKn2kqEN1IZ4Ns6robrgbHJg2mTBJCZl0x6zLf5IgkAAADj23DEdC49Q+rzdynGs2oSY1efs/X5ec2aNR3DGku4r6+vY3innXbqGNZt0Gdt9/5A4xOvXLmyY1hjNut7AN3uDRs2dAxrPWgd6DZrDOmI+nbqMjWe8sDAQMewxnRetmxZx7Bus8ah1m2KqMfj7vadRbfDmXcg3b4/5Pls+BBSAwAAAAAAAADQCl44AwAAAAAAAABawQtnAAAAAAAAAEArxkQM54xSnJamiTSaxJRtYrjipGaWq/GDNOZwRC6+rdanxl528Zl1Ho0B5ObT8rnyapymJrF1XVk0VpOLY6TTaP1mEvO0Fd9YNYkF3LQsOi4TT7xJ/N0mCYeaxikvyZS/Sey1tmLQD9c8bcWTLq27aXzmNq6vTeJ+Z+YhZli7sudKNslb24nfsud/03Mqezxlr78jcXy29ftsMNlkeG7fZPdrL8kg29zX2QR5Te5Dm4xETgHd/9nl95I0MXs8Za8TveyLzP7JJtLMavtc72V53BcBABgfxs0LZwAAAAAAgPGgjSSCpSRupWH9wFVKKlhaXkT9w582INOkfprsbvLkyR3DpYZuuj5tEBZRbzSmw5rYsNSYqtRITrdRE/hNnTq1VkbdTq1bXYcmEdR16rBusy7PfbAd7qSA3SYhzKwDI4eQGgAAAAAAAACAVvDCGQAAAAAAAADQCl44AwAAAAAAAABaMSZjOGdisDRJatZWWdpOntKmTJIZF9NI4yC5hHougV6JrlvjCLl1a+wgFxeqFGsqor6fdLkapymivo1umzNJAlUbx2uTpGZuXFsJDLuN59SWpgkBdVyTpIFOaTtHMqZUW+tqkrixiTaSHrr52kpOOVL1MJ60ebxn67vtRIJOdruGO0Fcdt6R0Mv+Ue4e3sv2Z8e5dfQyb/a4a/I7t5tyZLWdmC67jqb34+z+yibq6yVBYi/7J5P4vBcjkVy0zcSkxN4E/kfpfHDPnXoN7TaGbilGc+ma3eQ3tD6Hl+JGd5tsNhNXujTc7b7QdwS6jatXr+4Y1njNEeX3F6X3OqXh0vKavBfoNWZzt8sbbBy2Dlo4AwAAAAAAAABawQtnAAAAAAAAAEAreOEMAAAAAAAAAGjFmIzh7DSJ7aJcrJ8myxmp2LRN4kc3ieEb4WM2q1LMoIcffrg2j8ZsnjhxYm0ajV+kMZpcfKMdd9yxuFyl5XvwwQdr0+g4F+dZtzsTh7YUW+v/b+9edptYoiiAGolISEwYIcGE//8upMCQCeIR0L2DqyuRykl6d9Xxg3itmTvtfrdjV1edncwzW2N2b12l2XlOVT94th7k1nJnayhu1Tk75WdKck5mahdv1VWr3pPW2tz6+yXV6FLTGQCAU0m+B2/VhT92DeeZPIDx7+Pv69Xv3LMZRSvrGI/b2L4ytjPMZNdsrXO13vIpajjvPQ+X9FuQh55NgzMAcNmO3QjfHSSYTkuD2TpDA1eCvyppoF1q5QdAst703Bw70Oxw6A/mS36sdz+ASxsEVu7h9BqrQiJHK6Hd3fd/9+fasR9edgZ6AgA8RkkNAAAAAABaaHAGAAAAAKDFsy2pkdSYHV3D0LHZoYDj8RzrKCXzVDWcv379eu91NYxyHG756tWrJ18fDofD69ev771Ozv+3b9/uvR7rSx8OD/ehOg5bNaaq4aNbtbUqxxpymdRNGrf3WDWcu47DeMxn6l3PLnfc79+/fz/5+nDYrmX12Lq2zJyTZLj3sc5t13K25pmpJ52YrZkPAAAdtr7/b/3m2WpX2fqt25Gds/o6sfWdfLVO9DFqEe9d5t5tSn6THqMu9J6/c9n0cAYAAAAAoMWz7eEMADwPaa+SlV4QK2FgaVhdava9p9j/rhEXq+9dCaDrDtzrDiEc960ahbFyvZ4iIDBd7+womnOFYZ4jwC89N+l5rSSj2fYsDwBAD2cAAAAAAFro4QwAAABwZfbWeB5tjcqZycHZer33/aNTjNY4Rn3l1XrHx6i3vFqTWY3m5+1qGpyTm+MYxeVnzQ7P3dqn5DgkwxuT4YjjP5u7u7vN91TLvbm5ufd6HB778uXDy3hcVzJU8Pv37/de//jxY3O5SRhhsr3jPFUYYbKuLdUyxtC6JHAzCRBI5tkyM9Q0uX6T5Y7bn4Q9Vrb2uxruPV4j1TLG85YEWCb3+rju8f47HI4XWLm1nHRo/Mw8M8vY2l5foAAAALhGSmoAAAAAANDiano4AwCsSkc7rITwJbqD77oDEle2bzbUrToPaZBgJd3XjhFIe7ejO/hvZaTKynlNznV6zFeCBE8xvHp2ven57w4NPNcx6RiB+tiyAIDT0eAMAAAAwD17S3YmD422HgZtlUzcqhM9U/5v78OtvfN31EveWuax19nR2cGDwOvybBuck5vn2D1S2PbmzZt7r5MeG2Pt2uo8jrVrk3mSGs4zH5DJtiT71PEPIJlnpj5zsr3JsZv5MjBTw3mmHnPac2609aWsq0Z20sNyppZ1VRt6az2fP3/efE+X9+/f737PeBySnl1Jz7TxddqLcuR/EwAAAH8zNZwBAAAAAGjxbHs4AwDPQ1pftHvabC3h1fV2DjdMj925argmVo5lZaXWbzoCIZ0vGZVTjZZYqeG7cn11D4WdHcGzUsN55Z5Ip3Ves6f4DKv2YaVO+Dk+6wCAy6LBGQAAAIAn7Q32TB7UddSF7vx7xzJmymHu+fsp1jHzUNCDRP6kpAYAAAAAAC30cOasvnz5cu5NWPL27dsH02aGICdBclvvqZ4mjmGEydDVcZ5xGdV7Voa2/mnm2M2Eu80spxpa+vHjx2QTOaLb29tzbwIAAADwBz2cAQAAAABooYczAHASaeDWrDQ0ayUMsFItLw2NS7Y5DduqRqQkI1seW0equ17fuH1VaF4l3YdTBE6uhLqN+1vtfxokWEmvzXMEBFbT0tDAS7JyLY5WAiIr3SGHK+GKxyaoEPodI1B47315jPt4737tnf8S9nF1mT4/2UsPZwAAAAAAWsQ9nD3NAAAAAADgKXo4AwAAAADQQg1nAAAAAC7OKUbbX8OI/mvYRy6LBmcAoF0aTJW8tzsMLlUFk6VhXVWo20rQ36w0cG0lNKxS7cOvX7+i5SWhiStBjal0vSvXejJf57IOh/5wwUoaGjcbGpguq9L9OVFJ7+HZcL3ZAMrHVJ9Dle4wwOSzSAMJAPydlNQAAAAAAKCFBmcAAAAAAFpocAYAAAAAoIUazgAAAAA8aTZn45TUfofLoMEZADiJ2aCv6sfMSmhYFaT18uXDr0TdP6Kq9VbbnAR4pcekkoawrQQJVvs6u83pfqVheOl7q+1Nj12quu7Gaem1ubL/lTRw8tjT0mOeTkuv1+p4Vuciva+r0Mxk+9Jrs7Jyba4EE3YGTq581ml0AoDzUVIDAAAAAIAWGpwBAAAAAGihpAYAAAAAu5yjprNyOfB30MMZAAAAAIAWL/7xeAgAKFxi8jj/effu3YNpaSjbSuBapQoSS8PFkmkroYSVKrxtRRXy+PPnz2i91TaPwXQ3NzcP5kmDL6tzWG1veg4raUBeNe3u7m5zed0/VVYCMtNr+NOnT5NbRyeBg5fD94nroYczXIfkPtTDGQAAAACAFmo4AwAAALBE72Pgf3o4AwAAAADQQoMzAAAAAAAtlNQAAPjLXFMo2YcPHx5Mq4LvqvC2ShWGVwXarQQurgQ4VvPNSsMbV0Ke0u29vb2dXgfMMLQfAM5HD2cAAAAAAFpocAYAAAAAoIUGZwAAAAAAWmhwBgAAAACgxYt/pCkAAAAAANBAD2cAAAAAAFpocAYAAAAAoIUGZwAAAAAAWmhwBgAAAACghQZnAAAAAABaaHAGAAAAAKCFBmcAAAAAAFpocAYAAAAAoIUGZwAAAAAAWvwLo2ydpDDuiXMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verify a test sample\n",
    "for data, label in test_data:\n",
    "    view_image_data(data[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: /home/diogommiranda/tese/cosine_decay_tests/CROSS VALIDATION/results_resnet34/\n",
      "\n",
      "Starting Hyperparameter Tuning Grid Search...\n",
      "============================================================\n",
      "Testing Combination 1/1: LR=0.0002, L2_Reg=0.0005\n",
      "============================================================\n",
      "  Saving results for this combo to: /home/diogommiranda/tese/cosine_decay_tests/CROSS VALIDATION/results_resnet34/LR0_0.0002_L2_0.0005\n",
      "------------------------------------------------------------\n",
      "Training Fold 1/5 for LR=0.0002 and Reg=0.0005...\n",
      "  Train samples: 706, Validation samples: 183\n",
      "Calculating minmax across 706 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 706\n",
      "\n",
      "No mask applied.\n",
      "\n",
      "\n",
      "No mask applied.\n",
      "\n",
      "  Fold train label counts: {0: 456, 1: 250}\n",
      "  Fold Class Weights: {0: 0.7741228070175439, 1: 1.412}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745677491.627774  362576 service.cc:145] XLA service 0x7f8950004370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745677491.627888  362576 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2025-04-26 15:24:53.402209: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-26 15:24:55.667701: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745677507.186387  362576 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_32', 536 bytes spill stores, 536 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_31', 280 bytes spill stores, 280 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_36', 528 bytes spill stores, 528 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_30', 280 bytes spill stores, 280 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_28', 268 bytes spill stores, 268 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_29', 624 bytes spill stores, 580 bytes spill loads\n",
      "\n",
      "I0000 00:00:1745677507.238905  362576 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7764 - auc: 0.8060 - loss: 7.3111"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745677531.678394  362576 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_32', 48 bytes spill stores, 48 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_28', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_29', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 171ms/step - accuracy: 0.7767 - auc: 0.8064 - loss: 7.3009 - val_accuracy: 0.6776 - val_auc: 0.7775 - val_loss: 4.9897\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8013 - auc: 0.8398 - loss: 4.4620 - val_accuracy: 0.6503 - val_auc: 0.7969 - val_loss: 4.3076\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.8282 - auc: 0.9003 - loss: 3.2073 - val_accuracy: 0.3497 - val_auc: 0.7753 - val_loss: 3.7160\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8508 - auc: 0.9230 - loss: 2.5666 - val_accuracy: 0.3497 - val_auc: 0.8006 - val_loss: 4.3067\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9014 - auc: 0.9498 - loss: 2.1149 - val_accuracy: 0.5082 - val_auc: 0.7945 - val_loss: 3.0458\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 0.9106 - auc: 0.9662 - loss: 1.8651 - val_accuracy: 0.3497 - val_auc: 0.7945 - val_loss: 3.6022\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9368 - auc: 0.9728 - loss: 1.6479 - val_accuracy: 0.5574 - val_auc: 0.7812 - val_loss: 2.4772\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.9160 - auc: 0.9563 - loss: 1.6076 - val_accuracy: 0.3607 - val_auc: 0.7529 - val_loss: 2.8435\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.9452 - auc: 0.9755 - loss: 1.4702 - val_accuracy: 0.6120 - val_auc: 0.7864 - val_loss: 2.0948\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9654 - auc: 0.9941 - loss: 1.2948 - val_accuracy: 0.7213 - val_auc: 0.7727 - val_loss: 1.9524\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.9692 - auc: 0.9922 - loss: 1.2229 - val_accuracy: 0.6667 - val_auc: 0.7233 - val_loss: 1.9409\n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9849 - auc: 0.9995 - loss: 1.0857 - val_accuracy: 0.5628 - val_auc: 0.7298 - val_loss: 2.0825\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.9879 - auc: 0.9995 - loss: 1.0419 - val_accuracy: 0.4372 - val_auc: 0.6760 - val_loss: 3.1111\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.9993 - auc: 0.9944 - loss: 0.9693 - val_accuracy: 0.6885 - val_auc: 0.7140 - val_loss: 2.0538\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9962 - auc: 0.9986 - loss: 0.9318 - val_accuracy: 0.6885 - val_auc: 0.7484 - val_loss: 2.0217\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.8834 - val_accuracy: 0.7104 - val_auc: 0.7329 - val_loss: 1.9669\n",
      "Epoch 17/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9968 - auc: 0.9942 - loss: 0.8620 - val_accuracy: 0.7486 - val_auc: 0.7050 - val_loss: 2.4776\n",
      "Epoch 18/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.9960 - auc: 0.9998 - loss: 0.8480 - val_accuracy: 0.6885 - val_auc: 0.7287 - val_loss: 1.9951\n",
      "Epoch 19/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8080 - val_accuracy: 0.6667 - val_auc: 0.7208 - val_loss: 2.0172\n",
      "Epoch 20/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7884 - val_accuracy: 0.6831 - val_auc: 0.7207 - val_loss: 2.0569\n",
      "Epoch 21/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7734 - val_accuracy: 0.7104 - val_auc: 0.7245 - val_loss: 2.0710\n",
      "Epoch 22/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7678 - val_accuracy: 0.6776 - val_auc: 0.7211 - val_loss: 2.1156\n",
      "Epoch 23/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7540 - val_accuracy: 0.6831 - val_auc: 0.7262 - val_loss: 2.1172\n",
      "Epoch 24/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7508 - val_accuracy: 0.6831 - val_auc: 0.7283 - val_loss: 2.1525\n",
      "Epoch 25/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7475 - val_accuracy: 0.6721 - val_auc: 0.7272 - val_loss: 2.1680\n",
      "Epoch 26/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7461 - val_accuracy: 0.6995 - val_auc: 0.7322 - val_loss: 2.1697\n",
      "Epoch 27/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7479 - val_accuracy: 0.6995 - val_auc: 0.7319 - val_loss: 2.1603\n",
      "Epoch 28/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7461 - val_accuracy: 0.6995 - val_auc: 0.7317 - val_loss: 2.1685\n",
      "Epoch 29/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7426 - val_accuracy: 0.6885 - val_auc: 0.7319 - val_loss: 2.1731\n",
      "Epoch 30/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7417 - val_accuracy: 0.6995 - val_auc: 0.7317 - val_loss: 2.1713\n",
      "Epoch 31/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7406 - val_accuracy: 0.6995 - val_auc: 0.7310 - val_loss: 2.1602\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "  History saved to: /home/diogommiranda/tese/cosine_decay_tests/CROSS VALIDATION/results_resnet34/LR0_0.0002_L2_0.0005/fold_1/history_fold_1.csv\n",
      "    Fold 1 - Best Epoch 11: Val Loss=1.9409, Acc=0.6667, AUC=0.7233\n",
      "    Fold 1 finished in 471.26 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 2/5 for LR=0.0002 and Reg=0.0005...\n",
      "  Train samples: 713, Validation samples: 176\n",
      "Calculating minmax across 713 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 713\n",
      "\n",
      "No mask applied.\n",
      "\n",
      "\n",
      "No mask applied.\n",
      "\n",
      "  Fold train label counts: {0: 452, 1: 261}\n",
      "  Fold Class Weights: {0: 0.7887168141592921, 1: 1.3659003831417624}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 152ms/step - accuracy: 0.6650 - auc: 0.6960 - loss: 7.0994 - val_accuracy: 0.3011 - val_auc: 0.9152 - val_loss: 5.4928\n",
      "Epoch 2/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8226 - auc: 0.8748 - loss: 3.9558 - val_accuracy: 0.3125 - val_auc: 0.8154 - val_loss: 3.7400\n",
      "Epoch 3/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8641 - auc: 0.9410 - loss: 2.7722 - val_accuracy: 0.7102 - val_auc: 0.9113 - val_loss: 2.6486\n",
      "Epoch 4/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.8622 - auc: 0.9136 - loss: 2.2951 - val_accuracy: 0.5625 - val_auc: 0.9150 - val_loss: 2.8503\n",
      "Epoch 5/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.8605 - auc: 0.9321 - loss: 1.9958 - val_accuracy: 0.3636 - val_auc: 0.8694 - val_loss: 2.8302\n",
      "Epoch 6/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.9158 - auc: 0.9558 - loss: 1.7403 - val_accuracy: 0.3011 - val_auc: 0.8729 - val_loss: 4.1637\n",
      "Epoch 7/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9195 - auc: 0.9695 - loss: 1.5746 - val_accuracy: 0.7045 - val_auc: 0.8069 - val_loss: 1.9616\n",
      "Epoch 8/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.9429 - auc: 0.9739 - loss: 1.4770 - val_accuracy: 0.3011 - val_auc: 0.8787 - val_loss: 2.9784\n",
      "Epoch 9/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.9634 - auc: 0.9891 - loss: 1.3252 - val_accuracy: 0.3011 - val_auc: 0.8850 - val_loss: 3.6283\n",
      "Epoch 10/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9524 - auc: 0.9780 - loss: 1.3336 - val_accuracy: 0.3295 - val_auc: 0.7658 - val_loss: 2.6386\n",
      "Epoch 11/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.9657 - auc: 0.9890 - loss: 1.1891 - val_accuracy: 0.3068 - val_auc: 0.8310 - val_loss: 3.0452\n",
      "Epoch 12/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9612 - auc: 0.9928 - loss: 1.1446 - val_accuracy: 0.7670 - val_auc: 0.8501 - val_loss: 1.5699\n",
      "Epoch 13/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 0.9761 - auc: 0.9898 - loss: 1.0846 - val_accuracy: 0.8239 - val_auc: 0.8706 - val_loss: 1.5680\n",
      "Epoch 14/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9926 - auc: 0.9989 - loss: 0.9943 - val_accuracy: 0.7670 - val_auc: 0.8565 - val_loss: 1.5424\n",
      "Epoch 15/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9998 - auc: 0.9833 - loss: 0.9108 - val_accuracy: 0.5227 - val_auc: 0.8984 - val_loss: 2.0017\n",
      "Epoch 16/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9945 - auc: 0.9988 - loss: 0.9137 - val_accuracy: 0.8239 - val_auc: 0.8679 - val_loss: 1.4815\n",
      "Epoch 17/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9956 - auc: 0.9944 - loss: 0.8689 - val_accuracy: 0.8409 - val_auc: 0.9011 - val_loss: 1.3285\n",
      "Epoch 18/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8270 - val_accuracy: 0.8352 - val_auc: 0.8997 - val_loss: 1.3345\n",
      "Epoch 19/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8076 - val_accuracy: 0.8352 - val_auc: 0.9001 - val_loss: 1.3442\n",
      "Epoch 20/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7876 - val_accuracy: 0.8295 - val_auc: 0.8816 - val_loss: 1.3939\n",
      "Epoch 21/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7744 - val_accuracy: 0.8295 - val_auc: 0.8895 - val_loss: 1.3777\n",
      "Epoch 22/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7643 - val_accuracy: 0.8295 - val_auc: 0.8768 - val_loss: 1.3964\n",
      "Epoch 23/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7577 - val_accuracy: 0.8295 - val_auc: 0.8754 - val_loss: 1.4232\n",
      "Epoch 24/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 0.7544 - val_accuracy: 0.8295 - val_auc: 0.8755 - val_loss: 1.4328\n",
      "Epoch 25/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7535 - val_accuracy: 0.8295 - val_auc: 0.8768 - val_loss: 1.4368\n",
      "Epoch 26/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7516 - val_accuracy: 0.8352 - val_auc: 0.8713 - val_loss: 1.4381\n",
      "Epoch 27/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7502 - val_accuracy: 0.8295 - val_auc: 0.8777 - val_loss: 1.4410\n",
      "Epoch 28/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7489 - val_accuracy: 0.8352 - val_auc: 0.8728 - val_loss: 1.4434\n",
      "Epoch 29/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7487 - val_accuracy: 0.8352 - val_auc: 0.8728 - val_loss: 1.4384\n",
      "Epoch 30/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7473 - val_accuracy: 0.8352 - val_auc: 0.8728 - val_loss: 1.4424\n",
      "Epoch 31/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7466 - val_accuracy: 0.8295 - val_auc: 0.8744 - val_loss: 1.4368\n",
      "Epoch 32/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7443 - val_accuracy: 0.8352 - val_auc: 0.8738 - val_loss: 1.4407\n",
      "Epoch 33/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7446 - val_accuracy: 0.8295 - val_auc: 0.8747 - val_loss: 1.4366\n",
      "Epoch 34/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7419 - val_accuracy: 0.8295 - val_auc: 0.8750 - val_loss: 1.4402\n",
      "Epoch 35/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7400 - val_accuracy: 0.8295 - val_auc: 0.8704 - val_loss: 1.4346\n",
      "Epoch 36/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7385 - val_accuracy: 0.8352 - val_auc: 0.8766 - val_loss: 1.4315\n",
      "Epoch 37/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7374 - val_accuracy: 0.8352 - val_auc: 0.8767 - val_loss: 1.4316\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "  History saved to: /home/diogommiranda/tese/cosine_decay_tests/CROSS VALIDATION/results_resnet34/LR0_0.0002_L2_0.0005/fold_2/history_fold_2.csv\n",
      "    Fold 2 - Best Epoch 17: Val Loss=1.3285, Acc=0.8409, AUC=0.9011\n",
      "    Fold 2 finished in 554.39 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 3/5 for LR=0.0002 and Reg=0.0005...\n",
      "  Train samples: 708, Validation samples: 181\n",
      "Calculating minmax across 708 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 708\n",
      "\n",
      "No mask applied.\n",
      "\n",
      "\n",
      "No mask applied.\n",
      "\n",
      "  Fold train label counts: {0: 452, 1: 256}\n",
      "  Fold Class Weights: {0: 0.7831858407079646, 1: 1.3828125}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 100ms/step - accuracy: 0.6444 - auc: 0.7095 - loss: 7.2722 - val_accuracy: 0.3204 - val_auc: 0.9373 - val_loss: 5.4675\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.7680 - auc: 0.8245 - loss: 4.2596 - val_accuracy: 0.4807 - val_auc: 0.9447 - val_loss: 3.5590\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.8433 - auc: 0.9027 - loss: 3.0338 - val_accuracy: 0.8398 - val_auc: 0.9404 - val_loss: 2.6756\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9011 - auc: 0.9403 - loss: 2.4082 - val_accuracy: 0.8232 - val_auc: 0.9116 - val_loss: 2.3051\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8914 - auc: 0.9382 - loss: 2.1068 - val_accuracy: 0.8785 - val_auc: 0.9441 - val_loss: 1.9404\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.8957 - auc: 0.9549 - loss: 1.8488 - val_accuracy: 0.8232 - val_auc: 0.9500 - val_loss: 1.9871\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.9304 - auc: 0.9627 - loss: 1.6388 - val_accuracy: 0.3204 - val_auc: 0.9439 - val_loss: 3.5590\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9091 - auc: 0.9550 - loss: 1.6218 - val_accuracy: 0.3536 - val_auc: 0.9291 - val_loss: 2.7163\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.9525 - auc: 0.9824 - loss: 1.4193 - val_accuracy: 0.4254 - val_auc: 0.8995 - val_loss: 2.7079\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9262 - auc: 0.9765 - loss: 1.3907 - val_accuracy: 0.5249 - val_auc: 0.9394 - val_loss: 2.1227\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.9748 - auc: 0.9924 - loss: 1.2236 - val_accuracy: 0.4917 - val_auc: 0.9436 - val_loss: 2.6559\n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9905 - auc: 0.9995 - loss: 1.1413 - val_accuracy: 0.6022 - val_auc: 0.9365 - val_loss: 2.1946\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9898 - auc: 0.9987 - loss: 1.0747 - val_accuracy: 0.8287 - val_auc: 0.9178 - val_loss: 1.5586\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9704 - auc: 0.9863 - loss: 1.1289 - val_accuracy: 0.8343 - val_auc: 0.9223 - val_loss: 1.4684\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9966 - auc: 1.0000 - loss: 0.9845 - val_accuracy: 0.8674 - val_auc: 0.9256 - val_loss: 1.3498\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9234 - val_accuracy: 0.8619 - val_auc: 0.9272 - val_loss: 1.3336\n",
      "Epoch 17/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.8894 - val_accuracy: 0.8674 - val_auc: 0.9212 - val_loss: 1.3188\n",
      "Epoch 18/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8595 - val_accuracy: 0.8785 - val_auc: 0.9234 - val_loss: 1.2924\n",
      "Epoch 19/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8387 - val_accuracy: 0.8785 - val_auc: 0.9255 - val_loss: 1.2889\n",
      "Epoch 20/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8207 - val_accuracy: 0.8785 - val_auc: 0.9259 - val_loss: 1.3257\n",
      "Epoch 21/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8044 - val_accuracy: 0.8895 - val_auc: 0.9210 - val_loss: 1.3035\n",
      "Epoch 22/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7932 - val_accuracy: 0.8840 - val_auc: 0.9240 - val_loss: 1.3261\n",
      "Epoch 23/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7839 - val_accuracy: 0.8895 - val_auc: 0.9222 - val_loss: 1.3159\n",
      "Epoch 24/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7799 - val_accuracy: 0.8895 - val_auc: 0.9219 - val_loss: 1.2758\n",
      "Epoch 25/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7785 - val_accuracy: 0.8895 - val_auc: 0.9221 - val_loss: 1.3182\n",
      "Epoch 26/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7760 - val_accuracy: 0.8895 - val_auc: 0.9153 - val_loss: 1.3113\n",
      "Epoch 27/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7756 - val_accuracy: 0.8895 - val_auc: 0.9228 - val_loss: 1.3189\n",
      "Epoch 28/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7759 - val_accuracy: 0.8895 - val_auc: 0.9155 - val_loss: 1.3029\n",
      "Epoch 29/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7730 - val_accuracy: 0.8895 - val_auc: 0.9155 - val_loss: 1.3138\n",
      "Epoch 30/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7731 - val_accuracy: 0.8895 - val_auc: 0.9156 - val_loss: 1.3030\n",
      "Epoch 31/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7717 - val_accuracy: 0.8895 - val_auc: 0.9156 - val_loss: 1.3139\n",
      "Epoch 32/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7688 - val_accuracy: 0.8895 - val_auc: 0.9176 - val_loss: 1.3237\n",
      "Epoch 33/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7682 - val_accuracy: 0.8895 - val_auc: 0.9154 - val_loss: 1.3030\n",
      "Epoch 34/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7690 - val_accuracy: 0.8950 - val_auc: 0.9239 - val_loss: 1.3183\n",
      "Epoch 35/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7641 - val_accuracy: 0.9006 - val_auc: 0.9242 - val_loss: 1.3224\n",
      "Epoch 36/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 0.9888 - loss: 0.7639 - val_accuracy: 0.8895 - val_auc: 0.9161 - val_loss: 1.3067\n",
      "Epoch 37/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7633 - val_accuracy: 0.9006 - val_auc: 0.9249 - val_loss: 1.3267\n",
      "Epoch 38/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7593 - val_accuracy: 0.9006 - val_auc: 0.9246 - val_loss: 1.3210\n",
      "Epoch 39/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7579 - val_accuracy: 0.8895 - val_auc: 0.9155 - val_loss: 1.2934\n",
      "Epoch 40/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7542 - val_accuracy: 0.8950 - val_auc: 0.9179 - val_loss: 1.3131\n",
      "Epoch 41/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7527 - val_accuracy: 0.9006 - val_auc: 0.9179 - val_loss: 1.3149\n",
      "Epoch 42/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7481 - val_accuracy: 0.8950 - val_auc: 0.9180 - val_loss: 1.3067\n",
      "Epoch 43/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7462 - val_accuracy: 0.9006 - val_auc: 0.9193 - val_loss: 1.3260\n",
      "Epoch 44/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7429 - val_accuracy: 0.8950 - val_auc: 0.9181 - val_loss: 1.3137\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "  History saved to: /home/diogommiranda/tese/cosine_decay_tests/CROSS VALIDATION/results_resnet34/LR0_0.0002_L2_0.0005/fold_3/history_fold_3.csv\n",
      "    Fold 3 - Best Epoch 24: Val Loss=1.2758, Acc=0.8895, AUC=0.9219\n",
      "    Fold 3 finished in 648.43 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 4/5 for LR=0.0002 and Reg=0.0005...\n",
      "  Train samples: 713, Validation samples: 176\n",
      "Calculating minmax across 713 files...\n",
      "Calculated Min: -0.3496308922767639, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 713\n",
      "\n",
      "No mask applied.\n",
      "\n",
      "\n",
      "No mask applied.\n",
      "\n",
      "  Fold train label counts: {0: 454, 1: 259}\n",
      "  Fold Class Weights: {0: 0.7852422907488987, 1: 1.3764478764478765}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 142ms/step - accuracy: 0.6503 - auc: 0.7240 - loss: 6.9952 - val_accuracy: 0.3295 - val_auc: 0.7576 - val_loss: 4.5019\n",
      "Epoch 2/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.8175 - auc: 0.8739 - loss: 3.7136 - val_accuracy: 0.3352 - val_auc: 0.8036 - val_loss: 3.2882\n",
      "Epoch 3/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.8586 - auc: 0.9480 - loss: 2.5735 - val_accuracy: 0.5568 - val_auc: 0.8572 - val_loss: 2.6107\n",
      "Epoch 4/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8632 - auc: 0.9109 - loss: 2.1814 - val_accuracy: 0.3182 - val_auc: 0.7570 - val_loss: 3.0472\n",
      "Epoch 5/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.8793 - auc: 0.9448 - loss: 1.8642 - val_accuracy: 0.4318 - val_auc: 0.7828 - val_loss: 2.4032\n",
      "Epoch 6/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9209 - auc: 0.9479 - loss: 1.6893 - val_accuracy: 0.4148 - val_auc: 0.7773 - val_loss: 2.4943\n",
      "Epoch 7/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.9385 - auc: 0.9760 - loss: 1.4861 - val_accuracy: 0.7443 - val_auc: 0.8246 - val_loss: 1.7598\n",
      "Epoch 8/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9619 - auc: 0.9771 - loss: 1.3898 - val_accuracy: 0.3125 - val_auc: 0.7150 - val_loss: 3.9272\n",
      "Epoch 9/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9732 - auc: 0.9952 - loss: 1.2181 - val_accuracy: 0.3125 - val_auc: 0.6285 - val_loss: 4.7875\n",
      "Epoch 10/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.9687 - auc: 0.9837 - loss: 1.2272 - val_accuracy: 0.6080 - val_auc: 0.8214 - val_loss: 1.8061\n",
      "Epoch 11/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9802 - auc: 0.9912 - loss: 1.0910 - val_accuracy: 0.3125 - val_auc: 0.8026 - val_loss: 3.2459\n",
      "Epoch 12/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9836 - auc: 0.9972 - loss: 1.0524 - val_accuracy: 0.5568 - val_auc: 0.8210 - val_loss: 2.0420\n",
      "Epoch 13/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.9855 - auc: 0.9913 - loss: 0.9970 - val_accuracy: 0.7898 - val_auc: 0.8171 - val_loss: 1.6971\n",
      "Epoch 14/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.9888 - auc: 0.9999 - loss: 0.9223 - val_accuracy: 0.7273 - val_auc: 0.7973 - val_loss: 1.5163\n",
      "Epoch 15/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9998 - auc: 0.9833 - loss: 0.8584 - val_accuracy: 0.4659 - val_auc: 0.8239 - val_loss: 2.5134\n",
      "Epoch 16/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 0.9934 - auc: 1.0000 - loss: 0.8334 - val_accuracy: 0.7045 - val_auc: 0.8069 - val_loss: 1.5307\n",
      "Epoch 17/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.9985 - auc: 0.9944 - loss: 0.7996 - val_accuracy: 0.7386 - val_auc: 0.8294 - val_loss: 1.4514\n",
      "Epoch 18/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7800 - val_accuracy: 0.7500 - val_auc: 0.8385 - val_loss: 1.4066\n",
      "Epoch 19/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7592 - val_accuracy: 0.7216 - val_auc: 0.8363 - val_loss: 1.5065\n",
      "Epoch 20/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7396 - val_accuracy: 0.7614 - val_auc: 0.8358 - val_loss: 1.4225\n",
      "Epoch 21/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7268 - val_accuracy: 0.7727 - val_auc: 0.8350 - val_loss: 1.4235\n",
      "Epoch 22/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7165 - val_accuracy: 0.7670 - val_auc: 0.8379 - val_loss: 1.4391\n",
      "Epoch 23/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7105 - val_accuracy: 0.7727 - val_auc: 0.8297 - val_loss: 1.4590\n",
      "Epoch 24/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 0.7074 - val_accuracy: 0.7727 - val_auc: 0.8295 - val_loss: 1.4640\n",
      "Epoch 25/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7066 - val_accuracy: 0.7727 - val_auc: 0.8323 - val_loss: 1.4605\n",
      "Epoch 26/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7047 - val_accuracy: 0.7727 - val_auc: 0.8275 - val_loss: 1.4732\n",
      "Epoch 27/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7034 - val_accuracy: 0.7727 - val_auc: 0.8264 - val_loss: 1.4654\n",
      "Epoch 28/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7021 - val_accuracy: 0.7727 - val_auc: 0.8262 - val_loss: 1.4690\n",
      "Epoch 29/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7021 - val_accuracy: 0.7784 - val_auc: 0.8285 - val_loss: 1.4616\n",
      "Epoch 30/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7006 - val_accuracy: 0.7727 - val_auc: 0.8258 - val_loss: 1.4556\n",
      "Epoch 31/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7001 - val_accuracy: 0.7784 - val_auc: 0.8232 - val_loss: 1.4628\n",
      "Epoch 32/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.6979 - val_accuracy: 0.7727 - val_auc: 0.8273 - val_loss: 1.4694\n",
      "Epoch 33/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.6983 - val_accuracy: 0.7727 - val_auc: 0.8257 - val_loss: 1.4539\n",
      "Epoch 34/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 74ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.6956 - val_accuracy: 0.7727 - val_auc: 0.8262 - val_loss: 1.4555\n",
      "Epoch 35/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.6938 - val_accuracy: 0.7727 - val_auc: 0.8272 - val_loss: 1.4523\n",
      "Epoch 36/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.6923 - val_accuracy: 0.7727 - val_auc: 0.8259 - val_loss: 1.4464\n",
      "Epoch 37/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.6914 - val_accuracy: 0.7727 - val_auc: 0.8218 - val_loss: 1.4566\n",
      "Epoch 38/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.6893 - val_accuracy: 0.7784 - val_auc: 0.8275 - val_loss: 1.4508\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "  History saved to: /home/diogommiranda/tese/cosine_decay_tests/CROSS VALIDATION/results_resnet34/LR0_0.0002_L2_0.0005/fold_4/history_fold_4.csv\n",
      "    Fold 4 - Best Epoch 18: Val Loss=1.4066, Acc=0.7500, AUC=0.8385\n",
      "    Fold 4 finished in 566.19 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 5/5 for LR=0.0002 and Reg=0.0005...\n",
      "  Train samples: 716, Validation samples: 173\n",
      "Calculating minmax across 716 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.544045925140381\n",
      "Shuffling with buffer size: 716\n",
      "\n",
      "No mask applied.\n",
      "\n",
      "\n",
      "No mask applied.\n",
      "\n",
      "  Fold train label counts: {0: 486, 1: 230}\n",
      "  Fold Class Weights: {0: 0.7366255144032922, 1: 1.5565217391304347}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 135ms/step - accuracy: 0.6940 - auc: 0.7727 - loss: 7.3534 - val_accuracy: 0.4855 - val_auc: 0.7603 - val_loss: 5.6110\n",
      "Epoch 2/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.7705 - auc: 0.8502 - loss: 4.3895 - val_accuracy: 0.5202 - val_auc: 0.7745 - val_loss: 4.3483\n",
      "Epoch 3/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 99ms/step - accuracy: 0.7707 - auc: 0.8516 - loss: 3.2704 - val_accuracy: 0.6301 - val_auc: 0.8194 - val_loss: 2.9114\n",
      "Epoch 4/100\n",
      "\u001b[1m  2/179\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 123ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4389"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 16:03:31.663083: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 16777248 bytes after encountering the first element of size 16777248 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.8737 - auc: 0.9416 - loss: 2.5010 - val_accuracy: 0.5607 - val_auc: 0.7956 - val_loss: 2.8394\n",
      "Epoch 5/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 97ms/step - accuracy: 0.8823 - auc: 0.9229 - loss: 2.2716 - val_accuracy: 0.5607 - val_auc: 0.7288 - val_loss: 2.5020\n",
      "Epoch 6/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 0.9264 - auc: 0.9617 - loss: 1.9063 - val_accuracy: 0.5029 - val_auc: 0.7802 - val_loss: 2.7510\n",
      "Epoch 7/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.9288 - auc: 0.9773 - loss: 1.6909 - val_accuracy: 0.6301 - val_auc: 0.6806 - val_loss: 2.0768\n",
      "Epoch 8/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 103ms/step - accuracy: 0.9453 - auc: 0.9685 - loss: 1.6305 - val_accuracy: 0.6590 - val_auc: 0.7577 - val_loss: 1.9077\n",
      "Epoch 9/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9345 - auc: 0.9763 - loss: 1.4879 - val_accuracy: 0.6069 - val_auc: 0.7646 - val_loss: 2.0305\n",
      "Epoch 10/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 90ms/step - accuracy: 0.9817 - auc: 0.9915 - loss: 1.2916 - val_accuracy: 0.7283 - val_auc: 0.8307 - val_loss: 1.7430\n",
      "Epoch 11/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9853 - auc: 0.9804 - loss: 1.2153 - val_accuracy: 0.7399 - val_auc: 0.7856 - val_loss: 1.8835\n",
      "Epoch 12/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 90ms/step - accuracy: 0.9809 - auc: 0.9913 - loss: 1.1933 - val_accuracy: 0.4971 - val_auc: 0.7931 - val_loss: 2.9765\n",
      "Epoch 13/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 0.9945 - auc: 0.9999 - loss: 1.0585 - val_accuracy: 0.7110 - val_auc: 0.8188 - val_loss: 1.6472\n",
      "Epoch 14/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9947 - auc: 1.0000 - loss: 1.0116 - val_accuracy: 0.7283 - val_auc: 0.8113 - val_loss: 1.5767\n",
      "Epoch 15/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9869 - auc: 0.9883 - loss: 1.0284 - val_accuracy: 0.6358 - val_auc: 0.8010 - val_loss: 1.7828\n",
      "Epoch 16/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.9712 - auc: 0.9964 - loss: 1.0329 - val_accuracy: 0.5491 - val_auc: 0.8382 - val_loss: 2.3103\n",
      "Epoch 17/100\n",
      "\u001b[1m  1/179\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 178ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9224"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 16:06:57.734002: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 14442528 bytes after encountering the first element of size 14442528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9981 - auc: 1.0000 - loss: 0.9106 - val_accuracy: 0.7514 - val_auc: 0.8449 - val_loss: 1.6084\n",
      "Epoch 18/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9959 - auc: 1.0000 - loss: 0.8882 - val_accuracy: 0.7630 - val_auc: 0.8410 - val_loss: 1.5407\n",
      "Epoch 19/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8517 - val_accuracy: 0.7399 - val_auc: 0.8363 - val_loss: 1.6119\n",
      "Epoch 20/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8329 - val_accuracy: 0.7630 - val_auc: 0.8367 - val_loss: 1.4622\n",
      "Epoch 21/100\n",
      "\u001b[1m  1/179\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 166ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 16:07:58.521298: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 16777248 bytes after encountering the first element of size 16777248 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8206 - val_accuracy: 0.7399 - val_auc: 0.8438 - val_loss: 1.6142\n",
      "Epoch 22/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8093 - val_accuracy: 0.7283 - val_auc: 0.8349 - val_loss: 1.6949\n",
      "Epoch 23/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8010 - val_accuracy: 0.7457 - val_auc: 0.8334 - val_loss: 1.7498\n",
      "Epoch 24/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7993 - val_accuracy: 0.7341 - val_auc: 0.8374 - val_loss: 1.6781\n",
      "Epoch 25/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7970 - val_accuracy: 0.7399 - val_auc: 0.8357 - val_loss: 1.6719\n",
      "Epoch 26/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7935 - val_accuracy: 0.7341 - val_auc: 0.8398 - val_loss: 1.7067\n",
      "Epoch 27/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7930 - val_accuracy: 0.7341 - val_auc: 0.8385 - val_loss: 1.7030\n",
      "Epoch 28/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7937 - val_accuracy: 0.7341 - val_auc: 0.8343 - val_loss: 1.7417\n",
      "Epoch 29/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7916 - val_accuracy: 0.7399 - val_auc: 0.8341 - val_loss: 1.7447\n",
      "Epoch 30/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 89ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7897 - val_accuracy: 0.7399 - val_auc: 0.8341 - val_loss: 1.7361\n",
      "Epoch 31/100\n",
      "\u001b[1m  1/179\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 162ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 16:10:30.892972: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 16777248 bytes after encountering the first element of size 16777248 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7885 - val_accuracy: 0.7399 - val_auc: 0.8340 - val_loss: 1.7399\n",
      "Epoch 32/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7894 - val_accuracy: 0.7283 - val_auc: 0.8381 - val_loss: 1.7048\n",
      "Epoch 33/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7846 - val_accuracy: 0.7341 - val_auc: 0.8350 - val_loss: 1.7366\n",
      "Epoch 34/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7861 - val_accuracy: 0.7341 - val_auc: 0.8337 - val_loss: 1.7148\n",
      "Epoch 35/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7829 - val_accuracy: 0.7341 - val_auc: 0.8344 - val_loss: 1.7333\n",
      "Epoch 36/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.7815 - val_accuracy: 0.7399 - val_auc: 0.8358 - val_loss: 1.7452\n",
      "Epoch 37/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7790 - val_accuracy: 0.7341 - val_auc: 0.8339 - val_loss: 1.7409\n",
      "Epoch 38/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7776 - val_accuracy: 0.7341 - val_auc: 0.8337 - val_loss: 1.7053\n",
      "Epoch 39/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7731 - val_accuracy: 0.7341 - val_auc: 0.8344 - val_loss: 1.7820\n",
      "Epoch 40/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.7709 - val_accuracy: 0.7399 - val_auc: 0.8347 - val_loss: 1.6603\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "  History saved to: /home/diogommiranda/tese/cosine_decay_tests/CROSS VALIDATION/results_resnet34/LR0_0.0002_L2_0.0005/fold_5/history_fold_5.csv\n",
      "    Fold 5 - Best Epoch 20: Val Loss=1.4622, Acc=0.7630, AUC=0.8367\n",
      "    Fold 5 finished in 691.24 seconds.\n",
      "--------------------------------------------------\n",
      "Results for LR=0.0002, L2_Reg=0.0005 (Across 5 Folds):\n",
      "  Avg Val Loss: 1.4828 +/- 0.2378\n",
      "  Avg Val Acc:  0.7820 +/- 0.0771\n",
      "  Avg Val AUC:  0.8443 +/- 0.0692\n",
      "--------------------------------------------------\n",
      "Combination 1 finished in 2931.64 seconds.\n"
     ]
    }
   ],
   "source": [
    "N_SPLITS = 5 # Number of splits for cross-validation\n",
    "NUM_EPOCHS = 100 # Number of epochs for training\n",
    "DROPOUT_RATE = 0.0 # Dropout rate for the model\n",
    "REDUCE_LR_FACTOR = 0.2 # Factor to reduce learning rate (lr_reducer)\n",
    "REDUCE_LR_PATIENCE = 6 # Patience for reducing learning rate (lr_reducer)\n",
    "REDUCE_LR_MIN = 1e-7 # Minimum learning rate (lr_reducer)\n",
    "EARLY_STOP_PATIENCE = 20 # Patience for early stopping (early_stopper)\n",
    "\n",
    "# considerar learning rate=1e-3 se for com cosine decay\n",
    "#learning_rates_to_try = [5e-4, 2e-4, 1e-4] \n",
    "#reg_factors_to_try = [5e-4, 2e-4, 1e-4]\n",
    "reg_factors_to_try = [5e-4]\n",
    "learning_rates_to_try = [2e-4]\n",
    "\n",
    "tuning_results = []\n",
    "total_combinations = len(learning_rates_to_try) * len(reg_factors_to_try)\n",
    "current_combination_no = 0\n",
    "\n",
    "SAVE_DATA = True # Save training data and plots\n",
    "\n",
    "if SAVE_DATA:\n",
    "    if ROI_MASK_PATH is None:\n",
    "        RESULTS_BASE_DIR = \"/home/diogommiranda/tese/outputs/cosine_decay_tests/CROSS VALIDATION/results_resnet34/\"\n",
    "        os.makedirs(RESULTS_BASE_DIR, exist_ok=True)\n",
    "        print(f\"Results will be saved to: {RESULTS_BASE_DIR}\")\n",
    "    else:\n",
    "        RESULTS_BASE_DIR = \"/home/diogommiranda/tese/outputs/testes_mask/cosine_decay/CROSS VALIDATION/results_resnet34/\"\n",
    "        os.makedirs(RESULTS_BASE_DIR, exist_ok=True)\n",
    "        print(f\"Results will be saved to: {RESULTS_BASE_DIR}\")\n",
    "\n",
    "# Set up StratifiedGroupKFold by subjects\n",
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=seed)\n",
    "subject_ids_list = [extract_subject_id(p) for p in train_paths]\n",
    "subject_ids = np.array(subject_ids_list)\n",
    "\n",
    "print(\"\\nStarting Hyperparameter Tuning Grid Search...\")\n",
    "overall_start_time = time.time()\n",
    "\n",
    "for current_lr in learning_rates_to_try:\n",
    "    for current_reg in reg_factors_to_try:\n",
    "        current_combination_no += 1\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Testing Combination {current_combination_no}/{total_combinations}: LR={current_lr}, L2_Reg={current_reg}\")\n",
    "        print(\"=\" * 60)\n",
    "        start_time_combination = time.time()\n",
    "        \n",
    "        combo_dir_name = f\"LR0_{current_lr}_L2_{current_reg}\"\n",
    "        combo_results_dir = os.path.join(RESULTS_BASE_DIR, combo_dir_name)\n",
    "        os.makedirs(combo_results_dir, exist_ok=True)\n",
    "        print(f\"  Saving results for this combo to: {combo_results_dir}\")\n",
    "        \n",
    "        # Store results for the current hyperparameter combination\n",
    "        current_combo_losses = []\n",
    "        current_combo_accuracies = []\n",
    "        current_combo_aucs = []\n",
    "        current_combo_best_epoch = []\n",
    "\n",
    "        # Store results for each fold\n",
    "        fold_val_losses = []\n",
    "        fold_val_accuracies = []\n",
    "        fold_val_aucs = []\n",
    "        fold_no = 1\n",
    "\n",
    "        # K-Fold Cross-Validation\n",
    "        for train_indices, val_indices in sgkf.split(train_paths, train_labels, groups=subject_ids):\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"Training Fold {fold_no}/{N_SPLITS} for LR={current_lr} and Reg={current_reg}...\")\n",
    "            start_time_fold = time.time()\n",
    "\n",
    "            # Get the paths and labels for the current fold\n",
    "            fold_train_paths = train_paths[train_indices]\n",
    "            fold_train_labels = train_labels[train_indices]\n",
    "            fold_val_paths = train_paths[val_indices]\n",
    "            fold_val_labels = train_labels[val_indices]\n",
    "\n",
    "            # Verify that the training and validation sets have no overlapping subjects\n",
    "            train_subjects = set(subject_ids[train_indices])\n",
    "            val_subjects = set(subject_ids[val_indices])\n",
    "            if not train_subjects.isdisjoint(val_subjects):\n",
    "                print(f\"WARNING: Fold {fold_no} has overlapping subjects!\")\n",
    "                break\n",
    "            print(f\"  Train samples: {len(fold_train_paths)}, Validation samples: {len(fold_val_paths)}\")\n",
    "\n",
    "            # Calculate minmax parameters for the current training fold\n",
    "            fold_min, fold_max = calculate_min_max(fold_train_paths)\n",
    "\n",
    "            # Create fold train dataset\n",
    "            fold_train_data = create_dataset(\n",
    "                paths=fold_train_paths,\n",
    "                labels=fold_train_labels,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                volume_shape=VOLUME_SHAPE,\n",
    "                is_training=True, \n",
    "                seed=seed,\n",
    "                min_val=fold_min, \n",
    "                max_val=fold_max,\n",
    "                mask_path=None\n",
    "            )\n",
    "            \n",
    "            # Create fold validation dataset\n",
    "            fold_val_data = create_dataset(\n",
    "                paths=fold_val_paths,\n",
    "                labels=fold_val_labels,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                volume_shape=VOLUME_SHAPE,\n",
    "                is_training=False, \n",
    "                seed=None,\n",
    "                min_val=fold_min, \n",
    "                max_val=fold_max,\n",
    "                mask_path=None\n",
    "            )\n",
    "\n",
    "            if fold_train_data is None or fold_val_data is None:\n",
    "                print(f\"ERROR: Could not create datasets for fold {fold_no}. Skipping.\")\n",
    "                break\n",
    "\n",
    "            # Compute class weights for the current fold\n",
    "            unique_classes, class_counts = np.unique(fold_train_labels, return_counts=True)\n",
    "            print(f\"  Fold train label counts: {dict(zip(unique_classes, class_counts))}\")\n",
    "            fold_class_weights = class_weight.compute_class_weight('balanced', classes=unique_classes, y=fold_train_labels)\n",
    "            fold_class_weight_dict = dict(zip(unique_classes, fold_class_weights))\n",
    "            print(f\"  Fold Class Weights: {fold_class_weight_dict}\")\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            # Build the model\n",
    "            model = Resnet3DBuilder.build_resnet_34((91, 109, 91, 1), 1, reg_factor=current_reg, dropout_rate=DROPOUT_RATE)\n",
    "    \n",
    "            # Cosine decay scheduler\n",
    "            steps_per_epoch = math.ceil(len(fold_train_data) / BATCH_SIZE)\n",
    "            decay_steps = steps_per_epoch * NUM_EPOCHS\n",
    "            COSINE_ALPHA_FACTOR = 1e-6/current_lr # Alpha factor for cosine decay: finishes last epoch (NUM_EPOCHS) in 1e-6\n",
    "    \n",
    "            # Choose either cosine_decay or lr_reducer\n",
    "            cosine_decay = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=current_lr,\n",
    "                                                                     decay_steps=decay_steps,\n",
    "                                                                     alpha=COSINE_ALPHA_FACTOR,\n",
    "                                                                     name='CosineDecay')\n",
    "    \n",
    "            #lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "            #                                                  factor=REDUCE_LR_FACTOR,\n",
    "            #                                                  patience=REDUCE_LR_PATIENCE,\n",
    "            #                                                  min_lr=REDUCE_LR_MIN,\n",
    "            #                                                  verbose=1)\n",
    " \n",
    "            early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                            patience=EARLY_STOP_PATIENCE,\n",
    "                                                            restore_best_weights=True,\n",
    "                                                            verbose=1)\n",
    "    \n",
    "            callbacks_list = [early_stopper]\n",
    "\n",
    "            auc_metric = tf.keras.metrics.AUC(name='auc')\n",
    "\n",
    "            # Compile the model\n",
    "            model.compile(loss=\"binary_crossentropy\",\n",
    "                        optimizer= tf.keras.optimizers.Adam(learning_rate=cosine_decay, # for tuning\n",
    "                                                            clipnorm=1.0),\n",
    "                        metrics=[\"accuracy\", auc_metric])\n",
    "\n",
    "            history = model.fit(\n",
    "                fold_train_data,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                validation_data=fold_val_data,\n",
    "                class_weight=fold_class_weight_dict,\n",
    "                verbose=1,\n",
    "                callbacks=callbacks_list\n",
    "            )\n",
    "            \n",
    "            # Save the data for current fold\n",
    "            if SAVE_DATA:\n",
    "                fold_dir = os.path.join(combo_results_dir, f\"fold_{fold_no}\")\n",
    "                os.makedirs(fold_dir, exist_ok=True)\n",
    "                history_df = pd.DataFrame(history.history)\n",
    "                history_df.insert(0, 'epoch', range(1, len(history_df) + 1))\n",
    "                history_csv_path = os.path.join(fold_dir, f\"history_fold_{fold_no}.csv\")\n",
    "                try:\n",
    "                    history_df.to_csv(history_csv_path, index=False)\n",
    "                    print(f\"  History saved to: {history_csv_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error saving history: {e}\")\n",
    "                # Save plots\n",
    "                plot_loss_curves(history, fold_dir)\n",
    "\n",
    "            # Evaluate the fold\n",
    "            best_epoch_index = np.argmin(history.history['val_loss'])\n",
    "            best_epoch = best_epoch_index + 1\n",
    "            val_loss_best = history.history['val_loss'][best_epoch_index]\n",
    "            val_accuracy_best = history.history['val_accuracy'][best_epoch_index]\n",
    "            val_auc_best = history.history['val_auc'][best_epoch_index]\n",
    "            print(f\"    Fold {fold_no} - Best Epoch {best_epoch}: Val Loss={val_loss_best:.4f}, Acc={val_accuracy_best:.4f}, AUC={val_auc_best:.4f}\")\n",
    "    \n",
    "            current_combo_losses.append(val_loss_best)\n",
    "            current_combo_accuracies.append(val_accuracy_best)\n",
    "            current_combo_aucs.append(val_auc_best)\n",
    "            current_combo_best_epoch.append(best_epoch)\n",
    "\n",
    "            # Clean up\n",
    "            del history_df\n",
    "            del history \n",
    "            del fold_train_data\n",
    "            del fold_val_data\n",
    "            del model\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "\n",
    "            end_time_fold = time.time()\n",
    "            print(f\"    Fold {fold_no} finished in {end_time_fold - start_time_fold:.2f} seconds.\")\n",
    "            fold_no += 1\n",
    "\n",
    "        # Aggregate results for the current hyperparameter combination\n",
    "        if len(current_combo_losses) == N_SPLITS:\n",
    "            avg_loss = np.mean(current_combo_losses)\n",
    "            std_loss = np.std(current_combo_losses)\n",
    "            avg_acc = np.mean(current_combo_accuracies)\n",
    "            std_acc = np.std(current_combo_accuracies)\n",
    "            avg_auc = np.mean(current_combo_aucs)\n",
    "            std_auc = np.std(current_combo_aucs)\n",
    "\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"Results for LR={current_lr}, L2_Reg={current_reg} (Across {N_SPLITS} Folds):\")\n",
    "            print(f\"  Avg Val Loss: {avg_loss:.4f} +/- {std_loss:.4f}\")\n",
    "            print(f\"  Avg Val Acc:  {avg_acc:.4f} +/- {std_acc:.4f}\")\n",
    "            print(f\"  Avg Val AUC:  {avg_auc:.4f} +/- {std_auc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "\n",
    "            # Store results\n",
    "            tuning_results.append({\n",
    "                'learning_rate': current_lr,\n",
    "                'reg_factor': current_reg,\n",
    "                'avg_val_loss': avg_loss,\n",
    "                'std_val_loss': std_loss,\n",
    "                'avg_val_accuracy': avg_acc,\n",
    "                'std_val_accuracy': std_acc,\n",
    "                'avg_val_auc': avg_auc,\n",
    "                'std_val_auc': std_auc,\n",
    "                'individual_losses': [round(loss, 4) for loss in current_combo_losses],\n",
    "                'individual_accuracies': [round(acc, 4) for acc in current_combo_accuracies],\n",
    "                'individual_aucs': [round(auc, 4) for auc in current_combo_aucs],\n",
    "                'best_epoch_per_fold': list(current_combo_best_epoch)\n",
    "            })\n",
    "\n",
    "        end_time_combination = time.time()\n",
    "        print(f\"Combination {current_combination_no} finished in {end_time_combination - start_time_combination:.2f} seconds.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "857587ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Tuning Results Summary:\n",
      "   learning_rate  reg_factor  avg_val_loss  avg_val_accuracy  avg_val_auc  \\\n",
      "0         0.0002      0.0005        1.4828             0.782       0.8443   \n",
      "\n",
      "   std_val_loss  std_val_accuracy  std_val_auc  \\\n",
      "0        0.2378            0.0771       0.0692   \n",
      "\n",
      "                          individual_losses  \\\n",
      "0  [1.9409, 1.3285, 1.2758, 1.4066, 1.4622]   \n",
      "\n",
      "                   individual_accuracies  \\\n",
      "0  [0.6667, 0.8409, 0.8895, 0.75, 0.763]   \n",
      "\n",
      "                            individual_aucs   best_epoch_per_fold  \n",
      "0  [0.7233, 0.9011, 0.9219, 0.8385, 0.8367]  [11, 17, 24, 18, 20]  \n",
      "\n",
      " --- Best Hyperparameters Found ---\n",
      "learning_rate                                              0.0002\n",
      "reg_factor                                                 0.0005\n",
      "avg_val_loss                                             1.482795\n",
      "avg_val_accuracy                                         0.782017\n",
      "avg_val_auc                                              0.844294\n",
      "std_val_loss                                             0.237824\n",
      "std_val_accuracy                                         0.077089\n",
      "std_val_auc                                              0.069237\n",
      "individual_losses        [1.9409, 1.3285, 1.2758, 1.4066, 1.4622]\n",
      "individual_accuracies       [0.6667, 0.8409, 0.8895, 0.75, 0.763]\n",
      "individual_aucs          [0.7233, 0.9011, 0.9219, 0.8385, 0.8367]\n",
      "best_epoch_per_fold                          [11, 17, 24, 18, 20]\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Selected best parameters: LR=0.0002, L2_Reg=0.0005\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "if not tuning_results:\n",
    "    print(\"No tuning results were recorded.\")\n",
    "else:\n",
    "    \n",
    "    results_df = pd.DataFrame(tuning_results)\n",
    "    results_df = results_df.sort_values(by='avg_val_loss', ascending=False)\n",
    "\n",
    "    print(\"\\nTuning Results Summary:\")\n",
    "    display_cols = ['learning_rate', 'reg_factor', 'avg_val_loss', 'avg_val_accuracy', 'avg_val_auc', 'std_val_loss', 'std_val_accuracy', 'std_val_auc', 'individual_losses', 'individual_accuracies', 'individual_aucs', 'best_epoch_per_fold']\n",
    "    print(results_df[display_cols].round(4))\n",
    "\n",
    "    best_combination = results_df.iloc[0]\n",
    "\n",
    "    print(\"\\n --- Best Hyperparameters Found ---\")\n",
    "    print(best_combination[display_cols])\n",
    "\n",
    "    best_lr_final = best_combination['learning_rate']\n",
    "    best_reg_final = best_combination['reg_factor']\n",
    "    print(f\"\\nSelected best parameters: LR={best_lr_final}, L2_Reg={best_reg_final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158e0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4859d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
