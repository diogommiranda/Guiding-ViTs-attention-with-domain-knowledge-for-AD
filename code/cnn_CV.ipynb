{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa1e0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 15:40:07.946762: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-29 15:40:09.216114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 15:40:12.091542: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-29 15:40:12.361011: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-29 15:40:12.361075: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-29 15:40:12.372428: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-29 15:40:12.372505: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-29 15:40:12.372547: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-29 15:40:12.693391: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-29 15:40:12.693478: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-29 15:40:12.693486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-04-29 15:40:12.693535: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-29 15:40:12.693923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:05:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Add this at the very top\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Restrict TensorFlow to only allocate memory dynamically\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "# Load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "from Resnet3D_model import Resnet3DBuilder\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, f1_score, matthews_corrcoef, roc_auc_score, roc_curve, accuracy_score, recall_score, confusion_matrix\n",
    "from data_utils_CV import get_paths_and_labels, calculate_min_max, create_dataset, clean_zone_identifier_files, extract_subject_id\n",
    "from plotting_utils import view_image, view_random_image, plot_loss_curves, make_confusion_matrix, view_image_data\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccca6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set for reproducibility (seed=42)\n",
      "PYTHONHASHSEED set to: 42\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(f\"Seeds set for reproducibility (seed={seed})\")\n",
    "print(f\"PYTHONHASHSEED set to: {os.environ.get('PYTHONHASHSEED')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6be449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision policy set to: mixed_float16\n"
     ]
    }
   ],
   "source": [
    "# Set mixed precision policy to 'mixed_float16'\n",
    "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.set_global_policy(policy)\n",
    "print('Mixed precision policy set to:', policy.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0dbea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class map: {'smci': 0, 'pmci': 1}\n",
      "Scanning /home/diogommiranda/tese/datasets/mni_reg_CV/smci_pmci/train...\n",
      "Found 575 files for class 'smci'\n",
      "Found 314 files for class 'pmci'\n",
      "Calculating minmax across 889 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 889\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "Class map: {'smci': 0, 'pmci': 1}\n",
      "Scanning /home/diogommiranda/tese/datasets/mni_reg_CV/smci_pmci/test...\n",
      "Found 143 files for class 'smci'\n",
      "Found 78 files for class 'pmci'\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NORMALIZATION = \"mni_reg_CV\" # Choose intensity normalization method: \"minmax\"\n",
    "DATASET = \"smci_pmci\" # Choose dataset: \"smci_pmci\" or \"nc_ad\"\n",
    "DATA_DIR = Path(\"/home/diogommiranda/tese/datasets/\") / NORMALIZATION / DATASET\n",
    "VOLUME_SHAPE = (91, 109, 91) # Expected volume shape of the PET images\n",
    "BATCH_SIZE = 4 # Set batch size\n",
    "\n",
    "USE_MASK = True # Set to True to use the ROI mask, False to use the whole brain\n",
    "\n",
    "if USE_MASK:\n",
    "    ROI_MASK_PATH = str(Path(\"/home/diogommiranda/tese/masks/ROI_MASK.nii\"))\n",
    "else:\n",
    "    ROI_MASK_PATH = None\n",
    "\n",
    "# Get train paths and labels to calculate minmax values\n",
    "train_paths, train_labels_list, class_map = get_paths_and_labels(DATA_DIR, 'train')\n",
    "train_paths = np.array(train_paths)\n",
    "train_labels = np.array(train_labels_list)\n",
    "\n",
    "# Calculate minmax values for train set\n",
    "minmax_min, minmax_max = calculate_min_max(train_paths)\n",
    "\n",
    "# Create train dataset\n",
    "train_data = create_dataset(\n",
    "    paths=train_paths,\n",
    "    labels=train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    volume_shape=VOLUME_SHAPE,\n",
    "    is_training=True,\n",
    "    seed=seed,\n",
    "    min_val=minmax_min, \n",
    "    max_val=minmax_max, \n",
    "    mask_path=ROI_MASK_PATH\n",
    "    )\n",
    "\n",
    "# Create test set with the minmax values from train\n",
    "test_paths, test_labels, _ = get_paths_and_labels(DATA_DIR, 'test', class_map=class_map)\n",
    "test_data = create_dataset(\n",
    "    paths=test_paths,\n",
    "    labels=test_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    volume_shape=VOLUME_SHAPE,\n",
    "    is_training=False,\n",
    "    seed=None,\n",
    "    min_val=minmax_min, \n",
    "    max_val=minmax_max,\n",
    "    mask_path=ROI_MASK_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84def554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify data with a test sample\n",
    "for data, label in test_data:\n",
    "    view_image_data(data[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/\n",
      "\n",
      "Starting Hyperparameter Tuning Grid Search...\n",
      "============================================================\n",
      "Testing Combination 1/1: LR=1.1e-05, L2_Reg=2e-04\n",
      "============================================================\n",
      "  Saving results for this combo to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04\n",
      "------------------------------------------------------------\n",
      "Training Fold 1/5 for LR=1.1e-05 and Reg=2e-04...\n",
      "  Train samples: 706, Validation samples: 183\n",
      "Calculating minmax across 706 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 706\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "  Fold train label counts: {0: 456, 1: 250}\n",
      "  Fold Class Weights: {0: 0.7741228070175439, 1: 1.412}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745822929.573554 1681620 service.cc:145] XLA service 0x7ff2d0005660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745822929.573768 1681620 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2025-04-28 07:48:53.632319: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-28 07:48:57.824438: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745822951.112729 1681620 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_32', 536 bytes spill stores, 536 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_31', 280 bytes spill stores, 280 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_36', 528 bytes spill stores, 528 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_30', 280 bytes spill stores, 280 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_28', 268 bytes spill stores, 268 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_29', 624 bytes spill stores, 580 bytes spill loads\n",
      "\n",
      "I0000 00:00:1745822951.171737 1681620 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7293 - auc: 0.7231 - loss: 3.8329"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745822976.701711 1681619 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_32', 48 bytes spill stores, 48 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_28', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_29', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 184ms/step - accuracy: 0.7297 - auc: 0.7242 - loss: 3.8318 - val_accuracy: 0.3497 - val_auc: 0.7559 - val_loss: 4.6668\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.8540 - auc: 0.9110 - loss: 3.5342 - val_accuracy: 0.3497 - val_auc: 0.7358 - val_loss: 5.7540\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8830 - auc: 0.9470 - loss: 3.4153 - val_accuracy: 0.3770 - val_auc: 0.7092 - val_loss: 4.6886\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9304 - auc: 0.9734 - loss: 3.3226 - val_accuracy: 0.3497 - val_auc: 0.7265 - val_loss: 5.5025\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9453 - auc: 0.9846 - loss: 3.2400 - val_accuracy: 0.6230 - val_auc: 0.7621 - val_loss: 4.0548\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9549 - auc: 0.9851 - loss: 3.1946 - val_accuracy: 0.7650 - val_auc: 0.6849 - val_loss: 4.3954\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9806 - auc: 0.9903 - loss: 3.1436 - val_accuracy: 0.3825 - val_auc: 0.7256 - val_loss: 5.5054\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9445 - auc: 0.9714 - loss: 3.2074 - val_accuracy: 0.5410 - val_auc: 0.7281 - val_loss: 4.3576\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9683 - auc: 0.9922 - loss: 3.0838 - val_accuracy: 0.7650 - val_auc: 0.7082 - val_loss: 4.2723\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9819 - auc: 0.9934 - loss: 3.0274 - val_accuracy: 0.7486 - val_auc: 0.7059 - val_loss: 4.9836\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9846 - auc: 0.9911 - loss: 3.0121 - val_accuracy: 0.7705 - val_auc: 0.6915 - val_loss: 4.2479\n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 0.9926 - auc: 0.9991 - loss: 2.9411 - val_accuracy: 0.7486 - val_auc: 0.7327 - val_loss: 3.8406\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9813 - auc: 0.9975 - loss: 2.9494 - val_accuracy: 0.7705 - val_auc: 0.6979 - val_loss: 4.3950\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9933 - auc: 0.9933 - loss: 2.8915 - val_accuracy: 0.5191 - val_auc: 0.7331 - val_loss: 4.5556\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9970 - auc: 0.9999 - loss: 2.8419 - val_accuracy: 0.7760 - val_auc: 0.6983 - val_loss: 4.4526\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9989 - auc: 0.9944 - loss: 2.8020 - val_accuracy: 0.6940 - val_auc: 0.7464 - val_loss: 3.8558\n",
      "Epoch 17/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9899 - auc: 0.9938 - loss: 2.7969 - val_accuracy: 0.6284 - val_auc: 0.7524 - val_loss: 3.6667\n",
      "Epoch 18/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9950 - auc: 0.9993 - loss: 2.7655 - val_accuracy: 0.7650 - val_auc: 0.7249 - val_loss: 3.8028\n",
      "Epoch 19/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9948 - auc: 0.9995 - loss: 2.7305 - val_accuracy: 0.7650 - val_auc: 0.7128 - val_loss: 4.1211\n",
      "Epoch 20/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9948 - auc: 0.9999 - loss: 2.6936 - val_accuracy: 0.7650 - val_auc: 0.7255 - val_loss: 4.5169\n",
      "Epoch 21/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9923 - auc: 0.9988 - loss: 2.6806 - val_accuracy: 0.6503 - val_auc: 0.7538 - val_loss: 3.6830\n",
      "Epoch 22/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9975 - auc: 0.9942 - loss: 2.6482 - val_accuracy: 0.6503 - val_auc: 0.7479 - val_loss: 3.5568\n",
      "Epoch 23/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.5804 - val_accuracy: 0.7705 - val_auc: 0.7159 - val_loss: 3.9412\n",
      "Epoch 24/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9972 - auc: 0.9993 - loss: 2.5683 - val_accuracy: 0.5410 - val_auc: 0.7346 - val_loss: 4.0853\n",
      "Epoch 25/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9954 - auc: 0.9953 - loss: 2.5563 - val_accuracy: 0.7596 - val_auc: 0.7243 - val_loss: 4.7044\n",
      "Epoch 26/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9959 - auc: 0.9995 - loss: 2.4930 - val_accuracy: 0.7158 - val_auc: 0.6794 - val_loss: 6.0033\n",
      "Epoch 27/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9907 - auc: 0.9943 - loss: 2.4935 - val_accuracy: 0.6776 - val_auc: 0.7308 - val_loss: 3.5515\n",
      "Epoch 28/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9940 - auc: 0.9999 - loss: 2.4316 - val_accuracy: 0.6339 - val_auc: 0.7485 - val_loss: 3.4806\n",
      "Epoch 29/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9998 - auc: 1.0000 - loss: 2.3756 - val_accuracy: 0.5792 - val_auc: 0.7451 - val_loss: 3.3847\n",
      "Epoch 30/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9999 - auc: 1.0000 - loss: 2.3417 - val_accuracy: 0.7377 - val_auc: 0.7317 - val_loss: 3.6700\n",
      "Epoch 31/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3070 - val_accuracy: 0.7978 - val_auc: 0.7314 - val_loss: 3.7504\n",
      "Epoch 32/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9942 - auc: 0.9998 - loss: 2.2923 - val_accuracy: 0.6995 - val_auc: 0.7231 - val_loss: 3.0892\n",
      "Epoch 33/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2445 - val_accuracy: 0.7650 - val_auc: 0.7107 - val_loss: 4.1612\n",
      "Epoch 34/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9664 - auc: 0.9916 - loss: 2.3025 - val_accuracy: 0.6940 - val_auc: 0.7128 - val_loss: 3.4497\n",
      "Epoch 35/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9995 - auc: 0.9940 - loss: 2.1862 - val_accuracy: 0.7760 - val_auc: 0.7291 - val_loss: 3.6263\n",
      "Epoch 36/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9994 - auc: 0.9940 - loss: 2.1638 - val_accuracy: 0.5301 - val_auc: 0.7220 - val_loss: 3.7289\n",
      "Epoch 37/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.1248 - val_accuracy: 0.6995 - val_auc: 0.7265 - val_loss: 3.2099\n",
      "Epoch 38/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9958 - auc: 1.0000 - loss: 2.1016 - val_accuracy: 0.6721 - val_auc: 0.7296 - val_loss: 3.3057\n",
      "Epoch 39/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.0635 - val_accuracy: 0.7432 - val_auc: 0.6983 - val_loss: 3.5278\n",
      "Epoch 40/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0348 - val_accuracy: 0.7158 - val_auc: 0.7350 - val_loss: 3.2127\n",
      "Epoch 41/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9996 - auc: 1.0000 - loss: 2.0029 - val_accuracy: 0.7104 - val_auc: 0.7433 - val_loss: 2.9714\n",
      "Epoch 42/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.9778 - val_accuracy: 0.7596 - val_auc: 0.6752 - val_loss: 3.4657\n",
      "Epoch 43/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9433 - val_accuracy: 0.5738 - val_auc: 0.7342 - val_loss: 3.3718\n",
      "Epoch 44/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9100 - val_accuracy: 0.7049 - val_auc: 0.7228 - val_loss: 2.8792\n",
      "Epoch 45/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8772 - val_accuracy: 0.7158 - val_auc: 0.7133 - val_loss: 3.0480\n",
      "Epoch 46/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8427 - val_accuracy: 0.6940 - val_auc: 0.7290 - val_loss: 2.9671\n",
      "Epoch 47/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.8094 - val_accuracy: 0.6885 - val_auc: 0.7197 - val_loss: 2.9716\n",
      "Epoch 48/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7718 - val_accuracy: 0.6940 - val_auc: 0.7279 - val_loss: 2.8953\n",
      "Epoch 49/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7334 - val_accuracy: 0.7486 - val_auc: 0.7145 - val_loss: 2.9633\n",
      "Epoch 50/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9992 - auc: 1.0000 - loss: 1.6961 - val_accuracy: 0.6831 - val_auc: 0.7440 - val_loss: 2.7327\n",
      "Epoch 51/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9894 - auc: 0.9995 - loss: 1.6859 - val_accuracy: 0.7213 - val_auc: 0.7111 - val_loss: 3.1490\n",
      "Epoch 52/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9910 - auc: 0.9877 - loss: 1.7399 - val_accuracy: 0.6667 - val_auc: 0.7306 - val_loss: 2.7525\n",
      "Epoch 53/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6193 - val_accuracy: 0.6230 - val_auc: 0.7125 - val_loss: 2.6454\n",
      "Epoch 54/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5992 - val_accuracy: 0.7213 - val_auc: 0.7110 - val_loss: 2.7432\n",
      "Epoch 55/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.5764 - val_accuracy: 0.6940 - val_auc: 0.7101 - val_loss: 2.7746\n",
      "Epoch 56/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.5563 - val_accuracy: 0.7268 - val_auc: 0.7149 - val_loss: 2.9013\n",
      "Epoch 57/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5331 - val_accuracy: 0.6776 - val_auc: 0.7217 - val_loss: 2.7688\n",
      "Epoch 58/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5096 - val_accuracy: 0.6995 - val_auc: 0.7308 - val_loss: 2.6982\n",
      "Epoch 59/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4853 - val_accuracy: 0.7377 - val_auc: 0.7293 - val_loss: 2.7101\n",
      "Epoch 60/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4600 - val_accuracy: 0.6721 - val_auc: 0.7356 - val_loss: 2.7058\n",
      "Epoch 61/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9987 - auc: 0.9944 - loss: 1.4400 - val_accuracy: 0.7049 - val_auc: 0.7538 - val_loss: 2.3854\n",
      "Epoch 62/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.4061 - val_accuracy: 0.7213 - val_auc: 0.7419 - val_loss: 2.5177\n",
      "Epoch 63/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3793 - val_accuracy: 0.6831 - val_auc: 0.7303 - val_loss: 2.4893\n",
      "Epoch 64/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3495 - val_accuracy: 0.7104 - val_auc: 0.7328 - val_loss: 2.5069\n",
      "Epoch 65/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9890 - auc: 0.9983 - loss: 1.3489 - val_accuracy: 0.5191 - val_auc: 0.7102 - val_loss: 2.3913\n",
      "Epoch 66/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9854 - auc: 0.9976 - loss: 1.3487 - val_accuracy: 0.5738 - val_auc: 0.6997 - val_loss: 2.7283\n",
      "Epoch 67/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2973 - val_accuracy: 0.4918 - val_auc: 0.7119 - val_loss: 3.5397\n",
      "Epoch 68/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2812 - val_accuracy: 0.7104 - val_auc: 0.7175 - val_loss: 2.3201\n",
      "Epoch 69/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.2651 - val_accuracy: 0.6776 - val_auc: 0.7192 - val_loss: 2.3917\n",
      "Epoch 70/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 90ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.2512 - val_accuracy: 0.7814 - val_auc: 0.6799 - val_loss: 3.5298\n",
      "Epoch 71/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9967 - auc: 0.9999 - loss: 1.2482 - val_accuracy: 0.6885 - val_auc: 0.7399 - val_loss: 2.3512\n",
      "Epoch 72/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2245 - val_accuracy: 0.6831 - val_auc: 0.7371 - val_loss: 2.3744\n",
      "Epoch 73/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2074 - val_accuracy: 0.6667 - val_auc: 0.7333 - val_loss: 2.4232\n",
      "Epoch 74/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9986 - auc: 1.0000 - loss: 1.1983 - val_accuracy: 0.5464 - val_auc: 0.7193 - val_loss: 3.6945\n",
      "Epoch 75/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 0.9990 - auc: 1.0000 - loss: 1.1839 - val_accuracy: 0.6667 - val_auc: 0.7461 - val_loss: 2.1688\n",
      "Epoch 76/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.1653 - val_accuracy: 0.6831 - val_auc: 0.7486 - val_loss: 2.3855\n",
      "Epoch 77/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1511 - val_accuracy: 0.6831 - val_auc: 0.7681 - val_loss: 2.3814\n",
      "Epoch 78/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.1356 - val_accuracy: 0.7268 - val_auc: 0.7530 - val_loss: 2.2505\n",
      "Epoch 79/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1199 - val_accuracy: 0.7158 - val_auc: 0.7558 - val_loss: 2.2674\n",
      "Epoch 80/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1028 - val_accuracy: 0.7104 - val_auc: 0.7533 - val_loss: 2.2590\n",
      "Epoch 81/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0842 - val_accuracy: 0.6940 - val_auc: 0.7524 - val_loss: 2.2658\n",
      "Epoch 82/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.0659 - val_accuracy: 0.6885 - val_auc: 0.7512 - val_loss: 2.2703\n",
      "Epoch 83/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9987 - auc: 0.9992 - loss: 1.0559 - val_accuracy: 0.6503 - val_auc: 0.5312 - val_loss: 6.4744\n",
      "Epoch 84/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9735 - auc: 0.9974 - loss: 1.1041 - val_accuracy: 0.6667 - val_auc: 0.7245 - val_loss: 2.4626\n",
      "Epoch 85/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9823 - auc: 0.9849 - loss: 1.1221 - val_accuracy: 0.6831 - val_auc: 0.7236 - val_loss: 2.2925\n",
      "Epoch 86/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9882 - auc: 0.9790 - loss: 1.1172 - val_accuracy: 0.7432 - val_auc: 0.6841 - val_loss: 4.0454\n",
      "Epoch 87/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9957 - auc: 0.9996 - loss: 1.0244 - val_accuracy: 0.6230 - val_auc: 0.7490 - val_loss: 2.2363\n",
      "Epoch 88/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0057 - val_accuracy: 0.6066 - val_auc: 0.7306 - val_loss: 2.3739\n",
      "Epoch 89/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9928 - val_accuracy: 0.3497 - val_auc: 0.5504 - val_loss: 6.9402\n",
      "Epoch 90/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.9933 - auc: 1.0000 - loss: 0.9949 - val_accuracy: 0.7158 - val_auc: 0.7471 - val_loss: 2.1442\n",
      "Epoch 91/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9755 - val_accuracy: 0.7268 - val_auc: 0.7480 - val_loss: 2.1326\n",
      "Epoch 92/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9998 - auc: 1.0000 - loss: 0.9663 - val_accuracy: 0.7596 - val_auc: 0.6989 - val_loss: 3.0502\n",
      "Epoch 93/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.9548 - val_accuracy: 0.7705 - val_auc: 0.7037 - val_loss: 2.7279\n",
      "Epoch 94/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9445 - val_accuracy: 0.7049 - val_auc: 0.7207 - val_loss: 2.2315\n",
      "Epoch 95/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9342 - val_accuracy: 0.5847 - val_auc: 0.7384 - val_loss: 2.5842\n",
      "Epoch 96/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9217 - val_accuracy: 0.5574 - val_auc: 0.7229 - val_loss: 2.6552\n",
      "Epoch 97/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9100 - val_accuracy: 0.6885 - val_auc: 0.7145 - val_loss: 2.2313\n",
      "Epoch 98/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8967 - val_accuracy: 0.6885 - val_auc: 0.7201 - val_loss: 2.2574\n",
      "Epoch 99/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8825 - val_accuracy: 0.6776 - val_auc: 0.7241 - val_loss: 2.3559\n",
      "Epoch 100/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9922 - auc: 0.9996 - loss: 0.8888 - val_accuracy: 0.7158 - val_auc: 0.7205 - val_loss: 2.4037\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "  History saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04/fold_1/history_fold_1.csv\n",
      "    Fold 1 - Best Epoch 91: Val Loss=2.1326, Acc=0.7268, AUC=0.7480\n",
      "    Fold 1 finished in 1481.29 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 2/5 for LR=1.1e-05 and Reg=2e-04...\n",
      "  Train samples: 713, Validation samples: 176\n",
      "Calculating minmax across 713 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 713\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "  Fold train label counts: {0: 452, 1: 261}\n",
      "  Fold Class Weights: {0: 0.7887168141592921, 1: 1.3659003831417624}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 159ms/step - accuracy: 0.6217 - auc: 0.6278 - loss: 3.8625 - val_accuracy: 0.3011 - val_auc: 0.7713 - val_loss: 4.9428\n",
      "Epoch 2/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.8376 - auc: 0.9097 - loss: 3.5420 - val_accuracy: 0.3011 - val_auc: 0.8176 - val_loss: 6.0069\n",
      "Epoch 3/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.9041 - auc: 0.9724 - loss: 3.3619 - val_accuracy: 0.3239 - val_auc: 0.8620 - val_loss: 4.9416\n",
      "Epoch 4/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 92ms/step - accuracy: 0.9058 - auc: 0.9477 - loss: 3.3728 - val_accuracy: 0.5795 - val_auc: 0.8438 - val_loss: 4.0723\n",
      "Epoch 5/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9180 - auc: 0.9733 - loss: 3.2868 - val_accuracy: 0.7727 - val_auc: 0.8381 - val_loss: 3.6497\n",
      "Epoch 6/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9080 - auc: 0.9756 - loss: 3.2556 - val_accuracy: 0.7784 - val_auc: 0.8287 - val_loss: 3.6913\n",
      "Epoch 7/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9624 - auc: 0.9898 - loss: 3.1455 - val_accuracy: 0.6591 - val_auc: 0.8288 - val_loss: 3.8992\n",
      "Epoch 8/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9672 - auc: 0.9838 - loss: 3.1497 - val_accuracy: 0.8068 - val_auc: 0.8647 - val_loss: 3.5222\n",
      "Epoch 9/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9783 - auc: 0.9975 - loss: 3.0467 - val_accuracy: 0.6193 - val_auc: 0.8627 - val_loss: 4.1405\n",
      "Epoch 10/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9769 - auc: 0.9881 - loss: 3.0681 - val_accuracy: 0.7557 - val_auc: 0.7992 - val_loss: 3.9464\n",
      "Epoch 11/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9817 - auc: 0.9917 - loss: 2.9962 - val_accuracy: 0.6136 - val_auc: 0.8146 - val_loss: 3.9679\n",
      "Epoch 12/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9729 - auc: 0.9958 - loss: 2.9971 - val_accuracy: 0.6818 - val_auc: 0.7690 - val_loss: 3.7771\n",
      "Epoch 13/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9779 - auc: 0.9874 - loss: 2.9800 - val_accuracy: 0.7159 - val_auc: 0.7406 - val_loss: 4.4083\n",
      "Epoch 14/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9761 - auc: 0.9970 - loss: 2.9361 - val_accuracy: 0.7500 - val_auc: 0.8038 - val_loss: 3.6627\n",
      "Epoch 15/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9986 - auc: 0.9818 - loss: 2.8566 - val_accuracy: 0.5511 - val_auc: 0.8069 - val_loss: 4.3852\n",
      "Epoch 16/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9885 - auc: 0.9977 - loss: 2.8607 - val_accuracy: 0.7102 - val_auc: 0.7142 - val_loss: 4.3622\n",
      "Epoch 17/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9817 - auc: 0.9905 - loss: 2.8407 - val_accuracy: 0.3409 - val_auc: 0.7202 - val_loss: 6.1402\n",
      "Epoch 18/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9936 - auc: 0.9978 - loss: 2.7914 - val_accuracy: 0.6420 - val_auc: 0.7888 - val_loss: 3.7457\n",
      "Epoch 19/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9872 - auc: 0.9999 - loss: 2.7653 - val_accuracy: 0.7614 - val_auc: 0.8024 - val_loss: 3.4795\n",
      "Epoch 20/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9979 - auc: 0.9999 - loss: 2.7186 - val_accuracy: 0.7500 - val_auc: 0.7970 - val_loss: 3.4901\n",
      "Epoch 21/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9895 - auc: 1.0000 - loss: 2.6901 - val_accuracy: 0.8011 - val_auc: 0.8023 - val_loss: 3.5401\n",
      "Epoch 22/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9996 - auc: 1.0000 - loss: 2.6390 - val_accuracy: 0.7784 - val_auc: 0.8250 - val_loss: 3.3682\n",
      "Epoch 23/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.6070 - val_accuracy: 0.6648 - val_auc: 0.8168 - val_loss: 3.7913\n",
      "Epoch 24/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9977 - auc: 0.9833 - loss: 2.5799 - val_accuracy: 0.7216 - val_auc: 0.8078 - val_loss: 3.5886\n",
      "Epoch 25/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9995 - auc: 0.9944 - loss: 2.5457 - val_accuracy: 0.7273 - val_auc: 0.8180 - val_loss: 3.4556\n",
      "Epoch 26/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9974 - auc: 0.9944 - loss: 2.5107 - val_accuracy: 0.4205 - val_auc: 0.7296 - val_loss: 5.1714\n",
      "Epoch 27/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9929 - auc: 0.9998 - loss: 2.4908 - val_accuracy: 0.8011 - val_auc: 0.8103 - val_loss: 3.3771\n",
      "Epoch 28/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4328 - val_accuracy: 0.7386 - val_auc: 0.8034 - val_loss: 3.3589\n",
      "Epoch 29/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9994 - auc: 1.0000 - loss: 2.4022 - val_accuracy: 0.7386 - val_auc: 0.7605 - val_loss: 4.0299\n",
      "Epoch 30/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3665 - val_accuracy: 0.6818 - val_auc: 0.7966 - val_loss: 3.4997\n",
      "Epoch 31/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9936 - auc: 0.9997 - loss: 2.3419 - val_accuracy: 0.4205 - val_auc: 0.7733 - val_loss: 5.0985\n",
      "Epoch 32/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2906 - val_accuracy: 0.7500 - val_auc: 0.8133 - val_loss: 3.2800\n",
      "Epoch 33/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2584 - val_accuracy: 0.5568 - val_auc: 0.7946 - val_loss: 4.1819\n",
      "Epoch 34/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2179 - val_accuracy: 0.6364 - val_auc: 0.7782 - val_loss: 3.6646\n",
      "Epoch 35/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 90ms/step - accuracy: 0.9932 - auc: 0.9989 - loss: 2.2123 - val_accuracy: 0.7784 - val_auc: 0.7628 - val_loss: 3.4155\n",
      "Epoch 36/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9950 - auc: 0.9994 - loss: 2.1624 - val_accuracy: 0.6989 - val_auc: 0.6805 - val_loss: 4.7590\n",
      "Epoch 37/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.9821 - auc: 0.9927 - loss: 2.1615 - val_accuracy: 0.7500 - val_auc: 0.8193 - val_loss: 2.9255\n",
      "Epoch 38/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0915 - val_accuracy: 0.7670 - val_auc: 0.8041 - val_loss: 2.9408\n",
      "Epoch 39/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0543 - val_accuracy: 0.7102 - val_auc: 0.8036 - val_loss: 3.2398\n",
      "Epoch 40/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9986 - auc: 1.0000 - loss: 2.0292 - val_accuracy: 0.7784 - val_auc: 0.8265 - val_loss: 2.7985\n",
      "Epoch 41/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9945 - val_accuracy: 0.7159 - val_auc: 0.8109 - val_loss: 3.0743\n",
      "Epoch 42/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.9602 - val_accuracy: 0.7841 - val_auc: 0.8168 - val_loss: 2.7877\n",
      "Epoch 43/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9996 - auc: 1.0000 - loss: 1.9264 - val_accuracy: 0.7841 - val_auc: 0.8443 - val_loss: 2.6642\n",
      "Epoch 44/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 1.8898 - val_accuracy: 0.8011 - val_auc: 0.8264 - val_loss: 2.7609\n",
      "Epoch 45/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9991 - auc: 1.0000 - loss: 1.8579 - val_accuracy: 0.5682 - val_auc: 0.8022 - val_loss: 3.6373\n",
      "Epoch 46/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9880 - auc: 0.9942 - loss: 1.8726 - val_accuracy: 0.6250 - val_auc: 0.7927 - val_loss: 3.2559\n",
      "Epoch 47/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9906 - auc: 0.9967 - loss: 1.8355 - val_accuracy: 0.6761 - val_auc: 0.7944 - val_loss: 2.7030\n",
      "Epoch 48/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7812 - val_accuracy: 0.5341 - val_auc: 0.7501 - val_loss: 3.8290\n",
      "Epoch 49/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9985 - auc: 0.9930 - loss: 1.7647 - val_accuracy: 0.7216 - val_auc: 0.7935 - val_loss: 2.6492\n",
      "Epoch 50/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9972 - auc: 0.9999 - loss: 1.7408 - val_accuracy: 0.7045 - val_auc: 0.8020 - val_loss: 2.8080\n",
      "Epoch 51/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9985 - auc: 1.0000 - loss: 1.7152 - val_accuracy: 0.7443 - val_auc: 0.7905 - val_loss: 2.5844\n",
      "Epoch 52/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6902 - val_accuracy: 0.7500 - val_auc: 0.7893 - val_loss: 2.6208\n",
      "Epoch 53/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6677 - val_accuracy: 0.7159 - val_auc: 0.7969 - val_loss: 2.6425\n",
      "Epoch 54/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6435 - val_accuracy: 0.7273 - val_auc: 0.7990 - val_loss: 2.6339\n",
      "Epoch 55/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6200 - val_accuracy: 0.6989 - val_auc: 0.7945 - val_loss: 2.7102\n",
      "Epoch 56/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5936 - val_accuracy: 0.6989 - val_auc: 0.7845 - val_loss: 2.7265\n",
      "Epoch 57/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5677 - val_accuracy: 0.7670 - val_auc: 0.7668 - val_loss: 2.8411\n",
      "Epoch 58/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 0.9919 - auc: 0.9998 - loss: 1.5537 - val_accuracy: 0.7614 - val_auc: 0.8179 - val_loss: 2.4075\n",
      "Epoch 59/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5224 - val_accuracy: 0.7727 - val_auc: 0.7903 - val_loss: 2.5934\n",
      "Epoch 60/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4959 - val_accuracy: 0.7841 - val_auc: 0.7639 - val_loss: 2.7232\n",
      "Epoch 61/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9944 - auc: 1.0000 - loss: 1.4811 - val_accuracy: 0.7216 - val_auc: 0.7830 - val_loss: 2.8974\n",
      "Epoch 62/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4491 - val_accuracy: 0.7500 - val_auc: 0.8121 - val_loss: 2.6331\n",
      "Epoch 63/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4259 - val_accuracy: 0.7216 - val_auc: 0.8003 - val_loss: 2.6546\n",
      "Epoch 64/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4037 - val_accuracy: 0.7330 - val_auc: 0.8095 - val_loss: 2.5348\n",
      "Epoch 65/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3785 - val_accuracy: 0.7330 - val_auc: 0.8071 - val_loss: 2.5204\n",
      "Epoch 66/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9986 - auc: 1.0000 - loss: 1.3575 - val_accuracy: 0.7898 - val_auc: 0.7940 - val_loss: 2.3009\n",
      "Epoch 67/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9922 - auc: 0.9968 - loss: 1.3726 - val_accuracy: 0.6989 - val_auc: 0.5254 - val_loss: 5.8583\n",
      "Epoch 68/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9921 - auc: 0.9942 - loss: 1.3456 - val_accuracy: 0.7045 - val_auc: 0.6300 - val_loss: 4.2801\n",
      "Epoch 69/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3064 - val_accuracy: 0.6364 - val_auc: 0.7898 - val_loss: 2.9624\n",
      "Epoch 70/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2919 - val_accuracy: 0.6307 - val_auc: 0.7770 - val_loss: 3.2888\n",
      "Epoch 71/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.2819 - val_accuracy: 0.7102 - val_auc: 0.7861 - val_loss: 2.5870\n",
      "Epoch 72/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2621 - val_accuracy: 0.7102 - val_auc: 0.7822 - val_loss: 2.4997\n",
      "Epoch 73/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.2469 - val_accuracy: 0.7670 - val_auc: 0.7776 - val_loss: 2.3941\n",
      "Epoch 74/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2306 - val_accuracy: 0.7386 - val_auc: 0.7866 - val_loss: 2.3708\n",
      "Epoch 75/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2130 - val_accuracy: 0.7273 - val_auc: 0.7847 - val_loss: 2.3550\n",
      "Epoch 76/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 1.1956 - val_accuracy: 0.6136 - val_auc: 0.7546 - val_loss: 3.0308\n",
      "Epoch 77/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9915 - auc: 0.9902 - loss: 1.2166 - val_accuracy: 0.4659 - val_auc: 0.7206 - val_loss: 3.4236\n",
      "Epoch 78/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9944 - auc: 0.9997 - loss: 1.1925 - val_accuracy: 0.7955 - val_auc: 0.7879 - val_loss: 2.1776\n",
      "Epoch 79/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9983 - auc: 1.0000 - loss: 1.1592 - val_accuracy: 0.7159 - val_auc: 0.7948 - val_loss: 2.2752\n",
      "Epoch 80/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1401 - val_accuracy: 0.7159 - val_auc: 0.7823 - val_loss: 2.3526\n",
      "Epoch 81/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1286 - val_accuracy: 0.7216 - val_auc: 0.7811 - val_loss: 2.3814\n",
      "Epoch 82/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1138 - val_accuracy: 0.6705 - val_auc: 0.7645 - val_loss: 2.6513\n",
      "Epoch 83/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1001 - val_accuracy: 0.6932 - val_auc: 0.7675 - val_loss: 2.5701\n",
      "Epoch 84/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0845 - val_accuracy: 0.7045 - val_auc: 0.7728 - val_loss: 2.4173\n",
      "Epoch 85/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9889 - loss: 1.0697 - val_accuracy: 0.3636 - val_auc: 0.6305 - val_loss: 5.3458\n",
      "Epoch 86/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9892 - auc: 0.9978 - loss: 1.1003 - val_accuracy: 0.5341 - val_auc: 0.7474 - val_loss: 2.9422\n",
      "Epoch 87/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9808 - auc: 0.9935 - loss: 1.0867 - val_accuracy: 0.7727 - val_auc: 0.7402 - val_loss: 2.2946\n",
      "Epoch 88/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9945 - auc: 1.0000 - loss: 1.0448 - val_accuracy: 0.7386 - val_auc: 0.7968 - val_loss: 2.1728\n",
      "Epoch 89/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0332 - val_accuracy: 0.7386 - val_auc: 0.7167 - val_loss: 3.0641\n",
      "Epoch 90/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.0163 - val_accuracy: 0.5511 - val_auc: 0.7365 - val_loss: 3.4946\n",
      "Epoch 91/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9922 - auc: 0.9902 - loss: 1.0555 - val_accuracy: 0.5568 - val_auc: 0.7082 - val_loss: 3.2533\n",
      "Epoch 92/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9985 - val_accuracy: 0.7386 - val_auc: 0.7800 - val_loss: 2.2296\n",
      "Epoch 93/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9895 - val_accuracy: 0.7557 - val_auc: 0.7684 - val_loss: 2.1752\n",
      "Epoch 94/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9806 - auc: 0.9997 - loss: 1.0232 - val_accuracy: 0.7216 - val_auc: 0.7837 - val_loss: 2.3053\n",
      "Epoch 95/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9692 - val_accuracy: 0.7500 - val_auc: 0.7885 - val_loss: 2.1634\n",
      "Epoch 96/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9569 - val_accuracy: 0.7500 - val_auc: 0.7941 - val_loss: 2.2217\n",
      "Epoch 97/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9448 - val_accuracy: 0.7557 - val_auc: 0.7946 - val_loss: 2.1567\n",
      "Epoch 98/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9340 - val_accuracy: 0.6193 - val_auc: 0.7525 - val_loss: 3.0802\n",
      "Epoch 99/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9209 - val_accuracy: 0.7330 - val_auc: 0.7827 - val_loss: 2.1467\n",
      "Epoch 100/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9058 - val_accuracy: 0.6534 - val_auc: 0.7528 - val_loss: 2.8631\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "  History saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04/fold_2/history_fold_2.csv\n",
      "    Fold 2 - Best Epoch 99: Val Loss=2.1467, Acc=0.7330, AUC=0.7827\n",
      "    Fold 2 finished in 1488.63 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 3/5 for LR=1.1e-05 and Reg=2e-04...\n",
      "  Train samples: 708, Validation samples: 181\n",
      "Calculating minmax across 708 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 708\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "  Fold train label counts: {0: 452, 1: 256}\n",
      "  Fold Class Weights: {0: 0.7831858407079646, 1: 1.3828125}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 101ms/step - accuracy: 0.5526 - auc: 0.6236 - loss: 3.8741 - val_accuracy: 0.3204 - val_auc: 0.8081 - val_loss: 4.9143\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.7811 - auc: 0.8863 - loss: 3.5828 - val_accuracy: 0.3204 - val_auc: 0.8782 - val_loss: 5.1683\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9088 - auc: 0.9533 - loss: 3.3906 - val_accuracy: 0.3370 - val_auc: 0.9157 - val_loss: 4.4387\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9539 - auc: 0.9904 - loss: 3.2346 - val_accuracy: 0.3370 - val_auc: 0.8978 - val_loss: 5.2906\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.9440 - auc: 0.9850 - loss: 3.2364 - val_accuracy: 0.7956 - val_auc: 0.9183 - val_loss: 3.6132\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9331 - auc: 0.9790 - loss: 3.2327 - val_accuracy: 0.8619 - val_auc: 0.9193 - val_loss: 3.4152\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9737 - auc: 0.9772 - loss: 3.1447 - val_accuracy: 0.7735 - val_auc: 0.9136 - val_loss: 3.6184\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9547 - auc: 0.9882 - loss: 3.1405 - val_accuracy: 0.6133 - val_auc: 0.9138 - val_loss: 3.9834\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9852 - auc: 0.9965 - loss: 3.0459 - val_accuracy: 0.8287 - val_auc: 0.9059 - val_loss: 3.4849\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9553 - auc: 0.9837 - loss: 3.1025 - val_accuracy: 0.8398 - val_auc: 0.8987 - val_loss: 3.4253\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9840 - auc: 0.9941 - loss: 3.0083 - val_accuracy: 0.8453 - val_auc: 0.9125 - val_loss: 3.4097\n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9716 - auc: 0.9941 - loss: 2.9981 - val_accuracy: 0.7238 - val_auc: 0.9058 - val_loss: 3.7680\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9846 - auc: 0.9960 - loss: 2.9519 - val_accuracy: 0.6796 - val_auc: 0.5517 - val_loss: 7.9936\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.9469 - auc: 0.9929 - loss: 3.0097 - val_accuracy: 0.8287 - val_auc: 0.9104 - val_loss: 3.4110\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9738 - auc: 0.9921 - loss: 2.9352 - val_accuracy: 0.8398 - val_auc: 0.9066 - val_loss: 3.3183\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.9917 - auc: 0.9957 - loss: 2.8698 - val_accuracy: 0.8398 - val_auc: 0.9111 - val_loss: 3.1879\n",
      "Epoch 17/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.9785 - auc: 0.9857 - loss: 2.8661 - val_accuracy: 0.7901 - val_auc: 0.9036 - val_loss: 3.4771\n",
      "Epoch 18/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.9950 - auc: 1.0000 - loss: 2.7873 - val_accuracy: 0.8122 - val_auc: 0.9036 - val_loss: 3.3670\n",
      "Epoch 19/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9953 - auc: 0.9996 - loss: 2.7797 - val_accuracy: 0.7735 - val_auc: 0.8966 - val_loss: 3.3177\n",
      "Epoch 20/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9865 - auc: 0.9960 - loss: 2.7838 - val_accuracy: 0.8729 - val_auc: 0.9001 - val_loss: 3.2597\n",
      "Epoch 21/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9965 - auc: 0.9998 - loss: 2.7103 - val_accuracy: 0.8398 - val_auc: 0.9006 - val_loss: 3.2897\n",
      "Epoch 22/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9970 - auc: 0.9997 - loss: 2.6795 - val_accuracy: 0.7127 - val_auc: 0.8994 - val_loss: 3.5579\n",
      "Epoch 23/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.6281 - val_accuracy: 0.7735 - val_auc: 0.8890 - val_loss: 3.4069\n",
      "Epoch 24/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.5996 - val_accuracy: 0.7017 - val_auc: 0.8988 - val_loss: 3.6791\n",
      "Epoch 25/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.9960 - auc: 1.0000 - loss: 2.5790 - val_accuracy: 0.8398 - val_auc: 0.8948 - val_loss: 3.1204\n",
      "Epoch 26/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9985 - auc: 1.0000 - loss: 2.5371 - val_accuracy: 0.4420 - val_auc: 0.8930 - val_loss: 4.4982\n",
      "Epoch 27/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9958 - auc: 0.9985 - loss: 2.5273 - val_accuracy: 0.8011 - val_auc: 0.8799 - val_loss: 3.1597\n",
      "Epoch 28/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9977 - auc: 0.9955 - loss: 2.4950 - val_accuracy: 0.8564 - val_auc: 0.8961 - val_loss: 3.0084\n",
      "Epoch 29/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4336 - val_accuracy: 0.8453 - val_auc: 0.8984 - val_loss: 2.9765\n",
      "Epoch 30/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4036 - val_accuracy: 0.7680 - val_auc: 0.7639 - val_loss: 3.6963\n",
      "Epoch 31/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9970 - auc: 0.9943 - loss: 2.3807 - val_accuracy: 0.8122 - val_auc: 0.8918 - val_loss: 2.9719\n",
      "Epoch 32/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3315 - val_accuracy: 0.7790 - val_auc: 0.8898 - val_loss: 3.1305\n",
      "Epoch 33/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.2989 - val_accuracy: 0.8177 - val_auc: 0.8898 - val_loss: 3.0371\n",
      "Epoch 34/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9619 - auc: 0.9746 - loss: 2.4427 - val_accuracy: 0.8177 - val_auc: 0.8662 - val_loss: 3.0715\n",
      "Epoch 35/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9994 - auc: 1.0000 - loss: 2.2333 - val_accuracy: 0.8066 - val_auc: 0.8838 - val_loss: 2.8760\n",
      "Epoch 36/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9888 - loss: 2.2095 - val_accuracy: 0.8122 - val_auc: 0.8897 - val_loss: 2.8452\n",
      "Epoch 37/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.1758 - val_accuracy: 0.8122 - val_auc: 0.8744 - val_loss: 2.8921\n",
      "Epoch 38/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 2.1415 - val_accuracy: 0.8122 - val_auc: 0.8759 - val_loss: 2.8282\n",
      "Epoch 39/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9983 - auc: 0.9944 - loss: 2.1217 - val_accuracy: 0.4751 - val_auc: 0.8802 - val_loss: 3.5179\n",
      "Epoch 40/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0766 - val_accuracy: 0.8564 - val_auc: 0.8930 - val_loss: 2.6299\n",
      "Epoch 41/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0451 - val_accuracy: 0.8287 - val_auc: 0.8974 - val_loss: 2.6032\n",
      "Epoch 42/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0103 - val_accuracy: 0.7680 - val_auc: 0.8488 - val_loss: 2.8079\n",
      "Epoch 43/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9801 - val_accuracy: 0.8287 - val_auc: 0.8859 - val_loss: 2.6318\n",
      "Epoch 44/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9436 - val_accuracy: 0.7901 - val_auc: 0.8408 - val_loss: 2.8746\n",
      "Epoch 45/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.9112 - val_accuracy: 0.8287 - val_auc: 0.8917 - val_loss: 2.4625\n",
      "Epoch 46/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8792 - val_accuracy: 0.8287 - val_auc: 0.8871 - val_loss: 2.5325\n",
      "Epoch 47/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.8423 - val_accuracy: 0.8122 - val_auc: 0.8830 - val_loss: 2.6047\n",
      "Epoch 48/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8058 - val_accuracy: 0.8177 - val_auc: 0.8872 - val_loss: 2.4481\n",
      "Epoch 49/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7679 - val_accuracy: 0.7956 - val_auc: 0.8811 - val_loss: 2.4786\n",
      "Epoch 50/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7299 - val_accuracy: 0.8122 - val_auc: 0.8923 - val_loss: 2.5085\n",
      "Epoch 51/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6899 - val_accuracy: 0.8011 - val_auc: 0.8886 - val_loss: 2.2960\n",
      "Epoch 52/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6483 - val_accuracy: 0.8232 - val_auc: 0.8879 - val_loss: 2.3684\n",
      "Epoch 53/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6067 - val_accuracy: 0.8177 - val_auc: 0.8730 - val_loss: 2.2270\n",
      "Epoch 54/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9741 - auc: 0.9982 - loss: 1.6210 - val_accuracy: 0.7901 - val_auc: 0.8605 - val_loss: 2.5335\n",
      "Epoch 55/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9557 - auc: 0.9882 - loss: 1.6715 - val_accuracy: 0.8508 - val_auc: 0.8918 - val_loss: 2.1896\n",
      "Epoch 56/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9855 - auc: 0.9992 - loss: 1.5584 - val_accuracy: 0.8287 - val_auc: 0.8754 - val_loss: 2.1944\n",
      "Epoch 57/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.5196 - val_accuracy: 0.8232 - val_auc: 0.8738 - val_loss: 2.2106\n",
      "Epoch 58/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9914 - auc: 0.9998 - loss: 1.5288 - val_accuracy: 0.8453 - val_auc: 0.8748 - val_loss: 2.2179\n",
      "Epoch 59/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4867 - val_accuracy: 0.8177 - val_auc: 0.8758 - val_loss: 2.2398\n",
      "Epoch 60/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9986 - auc: 1.0000 - loss: 1.4737 - val_accuracy: 0.8287 - val_auc: 0.8785 - val_loss: 2.1578\n",
      "Epoch 61/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4540 - val_accuracy: 0.8343 - val_auc: 0.8860 - val_loss: 2.1443\n",
      "Epoch 62/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9997 - auc: 0.9775 - loss: 1.4388 - val_accuracy: 0.5580 - val_auc: 0.8757 - val_loss: 3.2304\n",
      "Epoch 63/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9993 - auc: 1.0000 - loss: 1.4293 - val_accuracy: 0.7956 - val_auc: 0.8673 - val_loss: 2.3206\n",
      "Epoch 64/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4069 - val_accuracy: 0.8177 - val_auc: 0.8753 - val_loss: 2.1330\n",
      "Epoch 65/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3842 - val_accuracy: 0.8287 - val_auc: 0.8696 - val_loss: 2.1460\n",
      "Epoch 66/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3654 - val_accuracy: 0.7790 - val_auc: 0.8338 - val_loss: 2.4218\n",
      "Epoch 67/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9786 - auc: 0.9930 - loss: 1.4094 - val_accuracy: 0.7514 - val_auc: 0.7486 - val_loss: 3.3569\n",
      "Epoch 68/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9983 - auc: 0.9970 - loss: 1.3485 - val_accuracy: 0.8453 - val_auc: 0.8825 - val_loss: 1.9771\n",
      "Epoch 69/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3147 - val_accuracy: 0.8232 - val_auc: 0.8830 - val_loss: 2.1344\n",
      "Epoch 70/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.3002 - val_accuracy: 0.8343 - val_auc: 0.8788 - val_loss: 2.1151\n",
      "Epoch 71/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2817 - val_accuracy: 0.5635 - val_auc: 0.8380 - val_loss: 3.3644\n",
      "Epoch 72/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2643 - val_accuracy: 0.8177 - val_auc: 0.8780 - val_loss: 1.9768\n",
      "Epoch 73/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2445 - val_accuracy: 0.8398 - val_auc: 0.8770 - val_loss: 2.0408\n",
      "Epoch 74/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2240 - val_accuracy: 0.8287 - val_auc: 0.8802 - val_loss: 2.0194\n",
      "Epoch 75/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2022 - val_accuracy: 0.8122 - val_auc: 0.8564 - val_loss: 2.1505\n",
      "Epoch 76/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.1806 - val_accuracy: 0.8287 - val_auc: 0.8841 - val_loss: 1.9063\n",
      "Epoch 77/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9957 - auc: 0.9984 - loss: 1.1782 - val_accuracy: 0.8122 - val_auc: 0.8991 - val_loss: 1.7007\n",
      "Epoch 78/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9858 - auc: 0.9992 - loss: 1.1762 - val_accuracy: 0.6243 - val_auc: 0.8909 - val_loss: 2.8625\n",
      "Epoch 79/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9770 - auc: 0.9906 - loss: 1.1932 - val_accuracy: 0.8343 - val_auc: 0.8792 - val_loss: 1.7648\n",
      "Epoch 80/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9973 - auc: 0.9999 - loss: 1.1353 - val_accuracy: 0.8232 - val_auc: 0.8836 - val_loss: 1.9228\n",
      "Epoch 81/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9961 - auc: 0.9999 - loss: 1.1221 - val_accuracy: 0.8398 - val_auc: 0.8826 - val_loss: 1.8676\n",
      "Epoch 82/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0996 - val_accuracy: 0.8398 - val_auc: 0.8795 - val_loss: 1.8566\n",
      "Epoch 83/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0887 - val_accuracy: 0.8508 - val_auc: 0.8797 - val_loss: 1.8421\n",
      "Epoch 84/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0816 - val_accuracy: 0.8453 - val_auc: 0.8904 - val_loss: 1.7769\n",
      "Epoch 85/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0656 - val_accuracy: 0.8453 - val_auc: 0.8917 - val_loss: 1.7705\n",
      "Epoch 86/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0529 - val_accuracy: 0.8343 - val_auc: 0.8827 - val_loss: 1.8166\n",
      "Epoch 87/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0404 - val_accuracy: 0.8398 - val_auc: 0.8845 - val_loss: 1.7953\n",
      "Epoch 88/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0264 - val_accuracy: 0.8343 - val_auc: 0.8797 - val_loss: 1.7719\n",
      "Epoch 89/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0100 - val_accuracy: 0.8122 - val_auc: 0.8809 - val_loss: 1.7442\n",
      "Epoch 90/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.9944 - val_accuracy: 0.8287 - val_auc: 0.8851 - val_loss: 1.7945\n",
      "Epoch 91/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9772 - val_accuracy: 0.7845 - val_auc: 0.8830 - val_loss: 1.6625\n",
      "Epoch 92/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9729 - auc: 0.9954 - loss: 1.0393 - val_accuracy: 0.7182 - val_auc: 0.7278 - val_loss: 2.5095\n",
      "Epoch 93/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9657 - auc: 0.9909 - loss: 1.0519 - val_accuracy: 0.7127 - val_auc: 0.9010 - val_loss: 2.0019\n",
      "Epoch 94/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9997 - auc: 1.0000 - loss: 0.9568 - val_accuracy: 0.7403 - val_auc: 0.7350 - val_loss: 2.5943\n",
      "Epoch 95/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 101ms/step - accuracy: 0.9725 - auc: 0.9897 - loss: 1.0467 - val_accuracy: 0.8177 - val_auc: 0.8853 - val_loss: 1.6484\n",
      "Epoch 96/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 1.0000 - auc: 0.9888 - loss: 0.9406 - val_accuracy: 0.4751 - val_auc: 0.8490 - val_loss: 3.1211\n",
      "Epoch 97/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 100ms/step - accuracy: 0.9999 - auc: 1.0000 - loss: 0.9309 - val_accuracy: 0.8232 - val_auc: 0.8831 - val_loss: 1.6278\n",
      "Epoch 98/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9993 - auc: 1.0000 - loss: 0.9261 - val_accuracy: 0.7624 - val_auc: 0.6927 - val_loss: 2.7853\n",
      "Epoch 99/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9141 - val_accuracy: 0.8232 - val_auc: 0.8664 - val_loss: 1.7391\n",
      "Epoch 100/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9947 - auc: 0.9973 - loss: 0.9408 - val_accuracy: 0.8398 - val_auc: 0.8874 - val_loss: 1.7655\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "  History saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04/fold_3/history_fold_3.csv\n",
      "    Fold 3 - Best Epoch 97: Val Loss=1.6278, Acc=0.8232, AUC=0.8831\n",
      "    Fold 3 finished in 1479.18 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 4/5 for LR=1.1e-05 and Reg=2e-04...\n",
      "  Train samples: 713, Validation samples: 176\n",
      "Calculating minmax across 713 files...\n",
      "Calculated Min: -0.3496308922767639, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 713\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "  Fold train label counts: {0: 454, 1: 259}\n",
      "  Fold Class Weights: {0: 0.7852422907488987, 1: 1.3764478764478765}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 173ms/step - accuracy: 0.5578 - auc: 0.6084 - loss: 3.8651 - val_accuracy: 0.3125 - val_auc: 0.6953 - val_loss: 5.1095\n",
      "Epoch 2/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 95ms/step - accuracy: 0.8077 - auc: 0.8879 - loss: 3.5813 - val_accuracy: 0.3125 - val_auc: 0.5372 - val_loss: 6.3834\n",
      "Epoch 3/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.8800 - auc: 0.9650 - loss: 3.3849 - val_accuracy: 0.3295 - val_auc: 0.8950 - val_loss: 4.4237\n",
      "Epoch 4/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9127 - auc: 0.9490 - loss: 3.3441 - val_accuracy: 0.3182 - val_auc: 0.8207 - val_loss: 5.8781\n",
      "Epoch 5/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 95ms/step - accuracy: 0.9091 - auc: 0.9645 - loss: 3.2947 - val_accuracy: 0.5341 - val_auc: 0.7833 - val_loss: 4.1278\n",
      "Epoch 6/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9310 - auc: 0.9675 - loss: 3.2503 - val_accuracy: 0.7727 - val_auc: 0.8563 - val_loss: 3.6704\n",
      "Epoch 7/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9510 - auc: 0.9857 - loss: 3.1527 - val_accuracy: 0.8295 - val_auc: 0.8863 - val_loss: 3.4284\n",
      "Epoch 8/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9653 - auc: 0.9785 - loss: 3.1482 - val_accuracy: 0.7443 - val_auc: 0.9011 - val_loss: 3.5339\n",
      "Epoch 9/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9823 - auc: 0.9966 - loss: 3.0285 - val_accuracy: 0.7955 - val_auc: 0.8839 - val_loss: 3.3651\n",
      "Epoch 10/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9575 - auc: 0.9874 - loss: 3.0664 - val_accuracy: 0.7273 - val_auc: 0.8039 - val_loss: 3.9374\n",
      "Epoch 11/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9872 - auc: 0.9908 - loss: 2.9769 - val_accuracy: 0.7784 - val_auc: 0.8433 - val_loss: 3.3834\n",
      "Epoch 12/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9798 - auc: 0.9952 - loss: 2.9673 - val_accuracy: 0.7216 - val_auc: 0.7515 - val_loss: 4.3785\n",
      "Epoch 13/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9680 - auc: 0.9738 - loss: 3.0376 - val_accuracy: 0.6989 - val_auc: 0.7588 - val_loss: 4.6572\n",
      "Epoch 14/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9833 - auc: 0.9938 - loss: 2.9238 - val_accuracy: 0.6591 - val_auc: 0.8773 - val_loss: 3.5964\n",
      "Epoch 15/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9927 - auc: 0.9829 - loss: 2.8561 - val_accuracy: 0.4091 - val_auc: 0.8704 - val_loss: 4.7279\n",
      "Epoch 16/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9890 - auc: 0.9963 - loss: 2.8518 - val_accuracy: 0.6989 - val_auc: 0.6051 - val_loss: 5.5608\n",
      "Epoch 17/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9909 - auc: 0.9901 - loss: 2.8235 - val_accuracy: 0.7102 - val_auc: 0.8745 - val_loss: 3.5794\n",
      "Epoch 18/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9949 - auc: 0.9999 - loss: 2.7648 - val_accuracy: 0.8125 - val_auc: 0.8691 - val_loss: 3.1989\n",
      "Epoch 19/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9913 - auc: 0.9998 - loss: 2.7610 - val_accuracy: 0.5625 - val_auc: 0.9047 - val_loss: 3.9288\n",
      "Epoch 20/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9993 - auc: 1.0000 - loss: 2.7109 - val_accuracy: 0.8352 - val_auc: 0.8634 - val_loss: 3.2273\n",
      "Epoch 21/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9990 - auc: 1.0000 - loss: 2.6776 - val_accuracy: 0.8239 - val_auc: 0.8632 - val_loss: 3.3196\n",
      "Epoch 22/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9996 - auc: 1.0000 - loss: 2.6378 - val_accuracy: 0.7727 - val_auc: 0.8382 - val_loss: 3.3974\n",
      "Epoch 23/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.6063 - val_accuracy: 0.5114 - val_auc: 0.8649 - val_loss: 4.1338\n",
      "Epoch 24/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 2.5794 - val_accuracy: 0.8011 - val_auc: 0.8838 - val_loss: 3.1387\n",
      "Epoch 25/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.9965 - auc: 0.9944 - loss: 2.5578 - val_accuracy: 0.7841 - val_auc: 0.8630 - val_loss: 3.0973\n",
      "Epoch 26/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.5084 - val_accuracy: 0.7784 - val_auc: 0.8936 - val_loss: 3.2117\n",
      "Epoch 27/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4708 - val_accuracy: 0.8295 - val_auc: 0.8674 - val_loss: 3.0583\n",
      "Epoch 28/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4307 - val_accuracy: 0.6648 - val_auc: 0.8668 - val_loss: 3.6061\n",
      "Epoch 29/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9968 - auc: 0.9978 - loss: 2.4161 - val_accuracy: 0.3523 - val_auc: 0.8445 - val_loss: 4.8973\n",
      "Epoch 30/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9848 - auc: 0.9983 - loss: 2.4080 - val_accuracy: 0.6989 - val_auc: 0.6817 - val_loss: 4.8831\n",
      "Epoch 31/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9907 - auc: 0.9973 - loss: 2.3676 - val_accuracy: 0.6307 - val_auc: 0.8663 - val_loss: 3.2832\n",
      "Epoch 32/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3040 - val_accuracy: 0.4602 - val_auc: 0.8820 - val_loss: 4.0191\n",
      "Epoch 33/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9955 - auc: 0.9950 - loss: 2.3130 - val_accuracy: 0.5682 - val_auc: 0.8833 - val_loss: 3.4977\n",
      "Epoch 34/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2450 - val_accuracy: 0.6932 - val_auc: 0.8843 - val_loss: 3.1201\n",
      "Epoch 35/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2123 - val_accuracy: 0.8409 - val_auc: 0.8754 - val_loss: 2.7398\n",
      "Epoch 36/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.1803 - val_accuracy: 0.8352 - val_auc: 0.8488 - val_loss: 2.8262\n",
      "Epoch 37/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.1484 - val_accuracy: 0.8182 - val_auc: 0.8662 - val_loss: 2.7017\n",
      "Epoch 38/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9962 - auc: 1.0000 - loss: 2.1210 - val_accuracy: 0.8239 - val_auc: 0.8779 - val_loss: 2.5719\n",
      "Epoch 39/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0745 - val_accuracy: 0.8125 - val_auc: 0.8696 - val_loss: 2.6725\n",
      "Epoch 40/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9927 - auc: 0.9998 - loss: 2.0575 - val_accuracy: 0.7841 - val_auc: 0.8856 - val_loss: 2.6992\n",
      "Epoch 41/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0088 - val_accuracy: 0.8239 - val_auc: 0.8930 - val_loss: 2.5012\n",
      "Epoch 42/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9981 - auc: 0.9944 - loss: 1.9786 - val_accuracy: 0.6989 - val_auc: 0.8461 - val_loss: 2.7151\n",
      "Epoch 43/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9951 - auc: 0.9994 - loss: 1.9656 - val_accuracy: 0.7841 - val_auc: 0.8445 - val_loss: 2.4597\n",
      "Epoch 44/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9886 - auc: 0.9769 - loss: 1.9766 - val_accuracy: 0.7955 - val_auc: 0.8660 - val_loss: 2.5454\n",
      "Epoch 45/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9744 - auc: 0.9957 - loss: 1.9567 - val_accuracy: 0.8352 - val_auc: 0.9061 - val_loss: 2.2858\n",
      "Epoch 46/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9895 - auc: 0.9995 - loss: 1.8960 - val_accuracy: 0.8352 - val_auc: 0.8806 - val_loss: 2.3527\n",
      "Epoch 47/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9977 - auc: 1.0000 - loss: 1.8556 - val_accuracy: 0.7898 - val_auc: 0.8725 - val_loss: 2.5461\n",
      "Epoch 48/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8267 - val_accuracy: 0.8239 - val_auc: 0.8925 - val_loss: 2.3614\n",
      "Epoch 49/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.8045 - val_accuracy: 0.8239 - val_auc: 0.8958 - val_loss: 2.3594\n",
      "Epoch 50/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7816 - val_accuracy: 0.6818 - val_auc: 0.8872 - val_loss: 2.8926\n",
      "Epoch 51/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7566 - val_accuracy: 0.7784 - val_auc: 0.8807 - val_loss: 2.5262\n",
      "Epoch 52/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7342 - val_accuracy: 0.8182 - val_auc: 0.8824 - val_loss: 2.3238\n",
      "Epoch 53/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7049 - val_accuracy: 0.5795 - val_auc: 0.8997 - val_loss: 2.9090\n",
      "Epoch 54/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6784 - val_accuracy: 0.4261 - val_auc: 0.7878 - val_loss: 4.8567\n",
      "Epoch 55/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9919 - auc: 0.9992 - loss: 1.6768 - val_accuracy: 0.7841 - val_auc: 0.8748 - val_loss: 2.3441\n",
      "Epoch 56/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.9986 - auc: 0.9993 - loss: 1.6349 - val_accuracy: 0.8295 - val_auc: 0.8887 - val_loss: 2.1366\n",
      "Epoch 57/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9909 - auc: 0.9994 - loss: 1.6396 - val_accuracy: 0.8011 - val_auc: 0.8512 - val_loss: 2.2277\n",
      "Epoch 58/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5835 - val_accuracy: 0.8125 - val_auc: 0.8949 - val_loss: 2.1913\n",
      "Epoch 59/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9985 - auc: 1.0000 - loss: 1.5669 - val_accuracy: 0.7784 - val_auc: 0.8551 - val_loss: 2.1436\n",
      "Epoch 60/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5411 - val_accuracy: 0.8182 - val_auc: 0.9033 - val_loss: 2.0802\n",
      "Epoch 61/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5180 - val_accuracy: 0.8466 - val_auc: 0.8881 - val_loss: 2.0595\n",
      "Epoch 62/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4944 - val_accuracy: 0.8182 - val_auc: 0.8687 - val_loss: 2.1459\n",
      "Epoch 63/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4701 - val_accuracy: 0.8182 - val_auc: 0.8872 - val_loss: 2.0366\n",
      "Epoch 64/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9953 - auc: 0.9998 - loss: 1.4600 - val_accuracy: 0.3807 - val_auc: 0.7333 - val_loss: 4.9179\n",
      "Epoch 65/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9918 - auc: 0.9976 - loss: 1.4550 - val_accuracy: 0.7670 - val_auc: 0.8697 - val_loss: 2.1718\n",
      "Epoch 66/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9944 - auc: 0.9964 - loss: 1.4437 - val_accuracy: 0.8182 - val_auc: 0.8736 - val_loss: 1.9211\n",
      "Epoch 67/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3941 - val_accuracy: 0.8125 - val_auc: 0.8645 - val_loss: 1.9601\n",
      "Epoch 68/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.3749 - val_accuracy: 0.8125 - val_auc: 0.8470 - val_loss: 2.0108\n",
      "Epoch 69/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3570 - val_accuracy: 0.8239 - val_auc: 0.8515 - val_loss: 1.9682\n",
      "Epoch 70/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3390 - val_accuracy: 0.8295 - val_auc: 0.8563 - val_loss: 1.9691\n",
      "Epoch 71/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9990 - auc: 0.9944 - loss: 1.3288 - val_accuracy: 0.7955 - val_auc: 0.8716 - val_loss: 1.9751\n",
      "Epoch 72/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9967 - auc: 0.9999 - loss: 1.3164 - val_accuracy: 0.8239 - val_auc: 0.8776 - val_loss: 1.8837\n",
      "Epoch 73/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9952 - auc: 0.9924 - loss: 1.3080 - val_accuracy: 0.8750 - val_auc: 0.9205 - val_loss: 1.6695\n",
      "Epoch 74/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9903 - auc: 1.0000 - loss: 1.2870 - val_accuracy: 0.8295 - val_auc: 0.8856 - val_loss: 1.8473\n",
      "Epoch 75/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2606 - val_accuracy: 0.8295 - val_auc: 0.8935 - val_loss: 1.8398\n",
      "Epoch 76/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 1.2456 - val_accuracy: 0.8239 - val_auc: 0.8883 - val_loss: 1.8451\n",
      "Epoch 77/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.2289 - val_accuracy: 0.8409 - val_auc: 0.8812 - val_loss: 1.7894\n",
      "Epoch 78/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2117 - val_accuracy: 0.8409 - val_auc: 0.8612 - val_loss: 1.8421\n",
      "Epoch 79/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1931 - val_accuracy: 0.8011 - val_auc: 0.8644 - val_loss: 1.8800\n",
      "Epoch 80/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1732 - val_accuracy: 0.8295 - val_auc: 0.8606 - val_loss: 1.8250\n",
      "Epoch 81/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1537 - val_accuracy: 0.8295 - val_auc: 0.8587 - val_loss: 1.7891\n",
      "Epoch 82/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1310 - val_accuracy: 0.8125 - val_auc: 0.8597 - val_loss: 1.8949\n",
      "Epoch 83/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1088 - val_accuracy: 0.8466 - val_auc: 0.8754 - val_loss: 1.7027\n",
      "Epoch 84/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0849 - val_accuracy: 0.8352 - val_auc: 0.8696 - val_loss: 1.7154\n",
      "Epoch 85/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9889 - loss: 1.0612 - val_accuracy: 0.8352 - val_auc: 0.8808 - val_loss: 1.6396\n",
      "Epoch 86/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9773 - auc: 0.9953 - loss: 1.1021 - val_accuracy: 0.7045 - val_auc: 0.7394 - val_loss: 2.8925\n",
      "Epoch 87/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9910 - auc: 0.9939 - loss: 1.0658 - val_accuracy: 0.7330 - val_auc: 0.7798 - val_loss: 2.2061\n",
      "Epoch 88/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9805 - auc: 0.9965 - loss: 1.0832 - val_accuracy: 0.7557 - val_auc: 0.7639 - val_loss: 2.4939\n",
      "Epoch 89/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9936 - auc: 0.9999 - loss: 1.0299 - val_accuracy: 0.7955 - val_auc: 0.8200 - val_loss: 1.7179\n",
      "Epoch 90/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.0017 - val_accuracy: 0.8011 - val_auc: 0.8568 - val_loss: 1.7157\n",
      "Epoch 91/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.9959 - val_accuracy: 0.7045 - val_auc: 0.8379 - val_loss: 2.1788\n",
      "Epoch 92/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9887 - val_accuracy: 0.8580 - val_auc: 0.8740 - val_loss: 1.7047\n",
      "Epoch 93/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9999 - auc: 1.0000 - loss: 0.9786 - val_accuracy: 0.3864 - val_auc: 0.7972 - val_loss: 3.8724\n",
      "Epoch 94/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9969 - auc: 1.0000 - loss: 0.9772 - val_accuracy: 0.8239 - val_auc: 0.8607 - val_loss: 1.6092\n",
      "Epoch 95/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9596 - val_accuracy: 0.8182 - val_auc: 0.8630 - val_loss: 1.6463\n",
      "Epoch 96/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9490 - val_accuracy: 0.8409 - val_auc: 0.8758 - val_loss: 1.5893\n",
      "Epoch 97/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9383 - val_accuracy: 0.7273 - val_auc: 0.8646 - val_loss: 2.1491\n",
      "Epoch 98/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9292 - val_accuracy: 0.7670 - val_auc: 0.8753 - val_loss: 1.9273\n",
      "Epoch 99/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 95ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9171 - val_accuracy: 0.8409 - val_auc: 0.8663 - val_loss: 1.5638\n",
      "Epoch 100/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9039 - val_accuracy: 0.8011 - val_auc: 0.9087 - val_loss: 1.7077\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "  History saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04/fold_4/history_fold_4.csv\n",
      "    Fold 4 - Best Epoch 99: Val Loss=1.5638, Acc=0.8409, AUC=0.8663\n",
      "    Fold 4 finished in 1509.80 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 5/5 for LR=1.1e-05 and Reg=2e-04...\n",
      "  Train samples: 716, Validation samples: 173\n",
      "Calculating minmax across 716 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.544045925140381\n",
      "Shuffling with buffer size: 716\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "  Fold train label counts: {0: 486, 1: 230}\n",
      "  Fold Class Weights: {0: 0.7366255144032922, 1: 1.5565217391304347}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 104ms/step - accuracy: 0.5889 - auc: 0.6519 - loss: 3.8691 - val_accuracy: 0.4855 - val_auc: 0.8304 - val_loss: 4.1318\n",
      "Epoch 2/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 0.8191 - auc: 0.8884 - loss: 3.5766 - val_accuracy: 0.4855 - val_auc: 0.8880 - val_loss: 4.3829\n",
      "Epoch 3/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.8701 - auc: 0.9290 - loss: 3.4694 - val_accuracy: 0.6301 - val_auc: 0.8882 - val_loss: 3.8198\n",
      "Epoch 4/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 94ms/step - accuracy: 0.9240 - auc: 0.9792 - loss: 3.2838 - val_accuracy: 0.7803 - val_auc: 0.9124 - val_loss: 3.5611\n",
      "Epoch 5/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9381 - auc: 0.9769 - loss: 3.2612 - val_accuracy: 0.5434 - val_auc: 0.8715 - val_loss: 4.5411\n",
      "Epoch 6/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9852 - auc: 0.9935 - loss: 3.1402 - val_accuracy: 0.8208 - val_auc: 0.8873 - val_loss: 3.5346\n",
      "Epoch 7/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9688 - auc: 0.9914 - loss: 3.1298 - val_accuracy: 0.7399 - val_auc: 0.8921 - val_loss: 3.5703\n",
      "Epoch 8/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9653 - auc: 0.9884 - loss: 3.1096 - val_accuracy: 0.8555 - val_auc: 0.8991 - val_loss: 3.4452\n",
      "Epoch 9/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9786 - auc: 0.9910 - loss: 3.0681 - val_accuracy: 0.6185 - val_auc: 0.8628 - val_loss: 4.1174\n",
      "Epoch 10/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9864 - auc: 0.9966 - loss: 2.9987 - val_accuracy: 0.8035 - val_auc: 0.8815 - val_loss: 3.4174\n",
      "Epoch 11/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9876 - auc: 0.9801 - loss: 2.9731 - val_accuracy: 0.8497 - val_auc: 0.8875 - val_loss: 3.3987\n",
      "Epoch 12/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9837 - auc: 0.9912 - loss: 2.9749 - val_accuracy: 0.7225 - val_auc: 0.8666 - val_loss: 3.5306\n",
      "Epoch 13/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9859 - auc: 0.9994 - loss: 2.8956 - val_accuracy: 0.7688 - val_auc: 0.8542 - val_loss: 3.4825\n",
      "Epoch 14/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9939 - auc: 1.0000 - loss: 2.8570 - val_accuracy: 0.6358 - val_auc: 0.8493 - val_loss: 4.3571\n",
      "Epoch 15/100\n",
      "\u001b[1m  1/179\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 165ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 2.8447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 09:32:08.341764: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 19111968 bytes after encountering the first element of size 19111968 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9889 - auc: 0.9861 - loss: 2.8848 - val_accuracy: 0.6936 - val_auc: 0.8668 - val_loss: 3.5967\n",
      "Epoch 16/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9623 - auc: 0.9845 - loss: 2.9331 - val_accuracy: 0.5549 - val_auc: 0.8668 - val_loss: 4.2312\n",
      "Epoch 17/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9886 - auc: 0.9946 - loss: 2.8110 - val_accuracy: 0.6358 - val_auc: 0.8723 - val_loss: 4.0911\n",
      "Epoch 18/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9862 - auc: 0.9958 - loss: 2.7850 - val_accuracy: 0.6879 - val_auc: 0.8773 - val_loss: 3.6407\n",
      "Epoch 19/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.7023 - val_accuracy: 0.6012 - val_auc: 0.8666 - val_loss: 3.9238\n",
      "Epoch 20/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9959 - auc: 0.9985 - loss: 2.6847 - val_accuracy: 0.5954 - val_auc: 0.7877 - val_loss: 4.6756\n",
      "Epoch 21/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9889 - auc: 0.9926 - loss: 2.6921 - val_accuracy: 0.8035 - val_auc: 0.8908 - val_loss: 3.1451\n",
      "Epoch 22/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9929 - auc: 0.9994 - loss: 2.6287 - val_accuracy: 0.7977 - val_auc: 0.8896 - val_loss: 3.1461\n",
      "Epoch 23/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9992 - auc: 1.0000 - loss: 2.5724 - val_accuracy: 0.5434 - val_auc: 0.6475 - val_loss: 5.9176\n",
      "Epoch 24/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9927 - auc: 0.9995 - loss: 2.5640 - val_accuracy: 0.7052 - val_auc: 0.8940 - val_loss: 3.3775\n",
      "Epoch 25/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9906 - auc: 0.9902 - loss: 2.5494 - val_accuracy: 0.7803 - val_auc: 0.8711 - val_loss: 3.0461\n",
      "Epoch 26/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4741 - val_accuracy: 0.6647 - val_auc: 0.8518 - val_loss: 3.7986\n",
      "Epoch 27/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9989 - auc: 1.0000 - loss: 2.4443 - val_accuracy: 0.5145 - val_auc: 0.5238 - val_loss: 11.0280\n",
      "Epoch 28/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9977 - auc: 0.9986 - loss: 2.4244 - val_accuracy: 0.7630 - val_auc: 0.8939 - val_loss: 2.9867\n",
      "Epoch 29/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9983 - auc: 1.0000 - loss: 2.3781 - val_accuracy: 0.7630 - val_auc: 0.8979 - val_loss: 2.9700\n",
      "Epoch 30/100\n",
      "\u001b[1m  1/179\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 165ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3460"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 09:35:38.353874: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 14442528 bytes after encountering the first element of size 14442528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9992 - auc: 1.0000 - loss: 2.3401 - val_accuracy: 0.6936 - val_auc: 0.8842 - val_loss: 3.3238\n",
      "Epoch 31/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3034 - val_accuracy: 0.8092 - val_auc: 0.8921 - val_loss: 2.7837\n",
      "Epoch 32/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9987 - auc: 1.0000 - loss: 2.2774 - val_accuracy: 0.6821 - val_auc: 0.8488 - val_loss: 3.4684\n",
      "Epoch 33/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2353 - val_accuracy: 0.5723 - val_auc: 0.8539 - val_loss: 3.8568\n",
      "Epoch 34/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9992 - auc: 0.9944 - loss: 2.2083 - val_accuracy: 0.7630 - val_auc: 0.8825 - val_loss: 2.8476\n",
      "Epoch 35/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.1651 - val_accuracy: 0.7803 - val_auc: 0.8908 - val_loss: 2.8375\n",
      "Epoch 36/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9895 - auc: 0.9929 - loss: 2.1657 - val_accuracy: 0.7746 - val_auc: 0.8743 - val_loss: 2.6285\n",
      "Epoch 37/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9958 - auc: 1.0000 - loss: 2.1096 - val_accuracy: 0.6012 - val_auc: 0.8632 - val_loss: 3.6103\n",
      "Epoch 38/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9968 - auc: 0.9999 - loss: 2.0842 - val_accuracy: 0.8208 - val_auc: 0.8783 - val_loss: 2.5530\n",
      "Epoch 39/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9988 - auc: 1.0000 - loss: 2.0406 - val_accuracy: 0.5202 - val_auc: 0.6429 - val_loss: 5.8400\n",
      "Epoch 40/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9992 - auc: 1.0000 - loss: 2.0116 - val_accuracy: 0.8266 - val_auc: 0.9018 - val_loss: 2.4712\n",
      "Epoch 41/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9992 - auc: 0.9944 - loss: 1.9819 - val_accuracy: 0.8613 - val_auc: 0.9064 - val_loss: 2.4321\n",
      "Epoch 42/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9478 - val_accuracy: 0.5318 - val_auc: 0.7766 - val_loss: 4.1473\n",
      "Epoch 43/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9916 - auc: 0.9943 - loss: 1.9394 - val_accuracy: 0.7457 - val_auc: 0.8766 - val_loss: 2.6539\n",
      "Epoch 44/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8883 - val_accuracy: 0.7861 - val_auc: 0.9014 - val_loss: 2.4823\n",
      "Epoch 45/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 1.8569 - val_accuracy: 0.8266 - val_auc: 0.8998 - val_loss: 2.3584\n",
      "Epoch 46/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8243 - val_accuracy: 0.8266 - val_auc: 0.8988 - val_loss: 2.3703\n",
      "Epoch 47/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7918 - val_accuracy: 0.6763 - val_auc: 0.8768 - val_loss: 3.0347\n",
      "Epoch 48/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7554 - val_accuracy: 0.8150 - val_auc: 0.8987 - val_loss: 2.3591\n",
      "Epoch 49/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9993 - auc: 0.9984 - loss: 1.7294 - val_accuracy: 0.6416 - val_auc: 0.8653 - val_loss: 2.6379\n",
      "Epoch 50/100\n",
      "\u001b[1m  2/179\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 130ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 09:40:16.913520: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 16777248 bytes after encountering the first element of size 16777248 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6867 - val_accuracy: 0.7514 - val_auc: 0.8953 - val_loss: 2.3479\n",
      "Epoch 51/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6510 - val_accuracy: 0.7168 - val_auc: 0.8684 - val_loss: 2.4610\n",
      "Epoch 52/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6162 - val_accuracy: 0.6532 - val_auc: 0.8236 - val_loss: 3.2144\n",
      "Epoch 53/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9723 - auc: 0.9944 - loss: 1.6637 - val_accuracy: 0.7052 - val_auc: 0.9139 - val_loss: 2.4785\n",
      "Epoch 54/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9897 - auc: 0.9930 - loss: 1.6069 - val_accuracy: 0.5896 - val_auc: 0.8456 - val_loss: 3.0970\n",
      "Epoch 55/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5619 - val_accuracy: 0.8324 - val_auc: 0.8967 - val_loss: 2.0683\n",
      "Epoch 56/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.9995 - auc: 0.9999 - loss: 1.5393 - val_accuracy: 0.7225 - val_auc: 0.8525 - val_loss: 2.5213\n",
      "Epoch 57/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9925 - auc: 0.9969 - loss: 1.5471 - val_accuracy: 0.8092 - val_auc: 0.9036 - val_loss: 2.1054\n",
      "Epoch 58/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5066 - val_accuracy: 0.8266 - val_auc: 0.9075 - val_loss: 1.9796\n",
      "Epoch 59/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4877 - val_accuracy: 0.8439 - val_auc: 0.9116 - val_loss: 1.9719\n",
      "Epoch 60/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.9974 - auc: 0.9999 - loss: 1.4774 - val_accuracy: 0.6532 - val_auc: 0.8852 - val_loss: 2.5418\n",
      "Epoch 61/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4505 - val_accuracy: 0.8324 - val_auc: 0.9060 - val_loss: 1.9520\n",
      "Epoch 62/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4323 - val_accuracy: 0.8439 - val_auc: 0.9045 - val_loss: 1.9105\n",
      "Epoch 63/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.4119 - val_accuracy: 0.8382 - val_auc: 0.9024 - val_loss: 1.9048\n",
      "Epoch 64/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9992 - auc: 0.9944 - loss: 1.3909 - val_accuracy: 0.5838 - val_auc: 0.7969 - val_loss: 3.4716\n",
      "Epoch 65/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3704 - val_accuracy: 0.8266 - val_auc: 0.8923 - val_loss: 1.9309\n",
      "Epoch 66/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3485 - val_accuracy: 0.7572 - val_auc: 0.8761 - val_loss: 2.1789\n",
      "Epoch 67/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9977 - auc: 1.0000 - loss: 1.3335 - val_accuracy: 0.8266 - val_auc: 0.8964 - val_loss: 1.9716\n",
      "Epoch 68/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.3116 - val_accuracy: 0.8497 - val_auc: 0.9026 - val_loss: 1.8407\n",
      "Epoch 69/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9894 - auc: 0.9993 - loss: 1.3165 - val_accuracy: 0.5838 - val_auc: 0.8086 - val_loss: 2.9162\n",
      "Epoch 70/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9856 - auc: 0.9899 - loss: 1.3667 - val_accuracy: 0.5607 - val_auc: 0.7016 - val_loss: 3.8504\n",
      "Epoch 71/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2630 - val_accuracy: 0.8035 - val_auc: 0.8953 - val_loss: 1.8629\n",
      "Epoch 72/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2479 - val_accuracy: 0.7803 - val_auc: 0.8802 - val_loss: 1.9801\n",
      "Epoch 73/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9986 - auc: 1.0000 - loss: 1.2387 - val_accuracy: 0.8035 - val_auc: 0.8779 - val_loss: 1.8971\n",
      "Epoch 74/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9968 - auc: 1.0000 - loss: 1.2290 - val_accuracy: 0.7457 - val_auc: 0.8628 - val_loss: 2.1180\n",
      "Epoch 75/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2074 - val_accuracy: 0.5376 - val_auc: 0.6613 - val_loss: 4.9213\n",
      "Epoch 76/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9983 - auc: 0.9997 - loss: 1.2022 - val_accuracy: 0.7457 - val_auc: 0.8674 - val_loss: 2.0611\n",
      "Epoch 77/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1772 - val_accuracy: 0.7514 - val_auc: 0.8645 - val_loss: 2.0450\n",
      "Epoch 78/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1608 - val_accuracy: 0.8266 - val_auc: 0.8820 - val_loss: 1.8247\n",
      "Epoch 79/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1437 - val_accuracy: 0.8150 - val_auc: 0.8850 - val_loss: 1.8178\n",
      "Epoch 80/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9919 - auc: 0.9983 - loss: 1.1602 - val_accuracy: 0.7919 - val_auc: 0.8525 - val_loss: 1.7033\n",
      "Epoch 81/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1214 - val_accuracy: 0.8035 - val_auc: 0.8928 - val_loss: 1.7113\n",
      "Epoch 82/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1038 - val_accuracy: 0.6243 - val_auc: 0.7970 - val_loss: 3.0836\n",
      "Epoch 83/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9884 - auc: 0.9994 - loss: 1.1171 - val_accuracy: 0.5838 - val_auc: 0.8022 - val_loss: 3.0281\n",
      "Epoch 84/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0796 - val_accuracy: 0.8208 - val_auc: 0.8981 - val_loss: 1.8046\n",
      "Epoch 85/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0669 - val_accuracy: 0.8150 - val_auc: 0.8945 - val_loss: 1.6873\n",
      "Epoch 86/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0532 - val_accuracy: 0.5260 - val_auc: 0.5601 - val_loss: 6.1749\n",
      "Epoch 87/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0422 - val_accuracy: 0.6936 - val_auc: 0.8712 - val_loss: 2.1593\n",
      "Epoch 88/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.0272 - val_accuracy: 0.5202 - val_auc: 0.6332 - val_loss: 4.4930\n",
      "Epoch 89/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9759 - auc: 1.0000 - loss: 1.0388 - val_accuracy: 0.6185 - val_auc: 0.7541 - val_loss: 4.6361\n",
      "Epoch 90/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9911 - auc: 0.9976 - loss: 1.0498 - val_accuracy: 0.7457 - val_auc: 0.8957 - val_loss: 1.7277\n",
      "Epoch 91/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9918 - val_accuracy: 0.7457 - val_auc: 0.8668 - val_loss: 1.9305\n",
      "Epoch 92/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9807 - val_accuracy: 0.7110 - val_auc: 0.8692 - val_loss: 1.9928\n",
      "Epoch 93/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9971 - auc: 0.9889 - loss: 0.9869 - val_accuracy: 0.5665 - val_auc: 0.8180 - val_loss: 2.9034\n",
      "Epoch 94/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9981 - auc: 0.9983 - loss: 0.9910 - val_accuracy: 0.7803 - val_auc: 0.8761 - val_loss: 1.6044\n",
      "Epoch 95/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9511 - val_accuracy: 0.7861 - val_auc: 0.8874 - val_loss: 1.6509\n",
      "Epoch 96/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9403 - val_accuracy: 0.7110 - val_auc: 0.8511 - val_loss: 1.9454\n",
      "Epoch 97/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9322 - val_accuracy: 0.8092 - val_auc: 0.8848 - val_loss: 1.5285\n",
      "Epoch 98/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.9650 - auc: 0.9906 - loss: 1.0521 - val_accuracy: 0.5260 - val_auc: 0.7832 - val_loss: 3.0272\n",
      "Epoch 99/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9905 - auc: 0.9977 - loss: 0.9438 - val_accuracy: 0.7052 - val_auc: 0.8985 - val_loss: 1.7846\n",
      "Epoch 100/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9059 - val_accuracy: 0.8150 - val_auc: 0.8985 - val_loss: 1.4981\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "  History saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04/fold_5/history_fold_5.csv\n",
      "    Fold 5 - Best Epoch 100: Val Loss=1.4981, Acc=0.8150, AUC=0.8985\n",
      "    Fold 5 finished in 1471.90 seconds.\n",
      "--------------------------------------------------\n",
      "Results for LR=1.1e-05, L2_Reg=0.0002 (Across 5 Folds):\n",
      "  Avg Val Loss: 1.7938 +/- 0.2854\n",
      "  Avg Val Acc:  0.7878 +/- 0.0481\n",
      "  Avg Val AUC:  0.8357 +/- 0.0594\n",
      "--------------------------------------------------\n",
      "Combination 1 finished in 7430.91 seconds.\n"
     ]
    }
   ],
   "source": [
    "# ----- Hyperparameter Tuning with K-Fold Cross-Validation -----\n",
    "\n",
    "N_SPLITS = 5 # Number of splits for cross-validation\n",
    "NUM_EPOCHS = 100 # Number of epochs for training\n",
    "DROPOUT_RATE = 0.0 # Dropout rate for the model\n",
    "\n",
    "# para cosine decay\n",
    "#learning_rates_to_try = [5e-4, 2e-4, 1e-4] # adicionar 1e-3? ver os resultados\n",
    "#reg_factors_to_try = [5e-4, 2e-4, 1e-4]\n",
    "\n",
    "#para fixed_lr\n",
    "#learning_rates_to_try = [1e-5, 2e-5] # adicionar 4e-5 ou 5e-6 dependendo dos resultados\n",
    "#reg_factors_to_try = [2e-4, 1e-4] # adicionar 4e-4 ou 5e-5 dependendo dos resultados\n",
    "\n",
    "lr_scheduler = \"fixed_lr\" # Choose between \"cosine_decay\" or \"fixed_lr\"\n",
    "\n",
    "learning_rates_to_try = [1.1e-5]\n",
    "reg_factors_to_try = [2e-4]\n",
    "\n",
    "tuning_results = []\n",
    "total_combinations = len(learning_rates_to_try) * len(reg_factors_to_try)\n",
    "current_combination_no = 0\n",
    "\n",
    "if ROI_MASK_PATH is None:\n",
    "    if lr_scheduler == \"cosine_decay\":\n",
    "        RESULTS_BASE_DIR = \"/home/diogommiranda/tese/outputs/full_brain/cosine_decay/CROSS_VALIDATION/results_resnet34/\"\n",
    "    elif lr_scheduler == \"fixed_lr\":\n",
    "        RESULTS_BASE_DIR = \"/home/diogommiranda/tese/outputs/full_brain/fixed_lr/CROSS_VALIDATION/results_resnet34/\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid string for 'lr_scheduler'. Please set it to 'cosine_decay' or 'fixed_lr'.\")\n",
    "    os.makedirs(RESULTS_BASE_DIR, exist_ok=True)\n",
    "    print(f\"Results will be saved to: {RESULTS_BASE_DIR}\")\n",
    "else:\n",
    "    if lr_scheduler == \"cosine_decay\":\n",
    "        RESULTS_BASE_DIR = \"/home/diogommiranda/tese/outputs/masked/cosine_decay/CROSS_VALIDATION/results_resnet34/\"\n",
    "    elif lr_scheduler == \"fixed_lr\":\n",
    "        RESULTS_BASE_DIR = \"/home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid string for 'lr_scheduler'. Please set it to 'cosine_decay' or 'fixed_lr'.\")\n",
    "    os.makedirs(RESULTS_BASE_DIR, exist_ok=True)\n",
    "    print(f\"Results will be saved to: {RESULTS_BASE_DIR}\")\n",
    "\n",
    "# Set up StratifiedGroupKFold by subjects\n",
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=seed)\n",
    "subject_ids_list = [extract_subject_id(p) for p in train_paths]\n",
    "subject_ids = np.array(subject_ids_list)\n",
    "\n",
    "print(\"\\nStarting Hyperparameter Tuning Grid Search...\")\n",
    "overall_start_time = time.time()\n",
    "\n",
    "for current_lr in learning_rates_to_try:\n",
    "    for current_reg in reg_factors_to_try:\n",
    "        current_combination_no += 1\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Testing Combination {current_combination_no}/{total_combinations}: LR={current_lr:.1e}, L2_Reg={current_reg:.0e}\")\n",
    "        print(\"=\" * 60)\n",
    "        start_time_combination = time.time()\n",
    "        \n",
    "        combo_dir_name = f\"LR0_{current_lr:.1e}_L2_{current_reg:.0e}\"\n",
    "        combo_results_dir = os.path.join(RESULTS_BASE_DIR, combo_dir_name)\n",
    "        os.makedirs(combo_results_dir, exist_ok=True)\n",
    "        print(f\"  Saving results for this combo to: {combo_results_dir}\")\n",
    "        \n",
    "        # Store results for the current hyperparameter combination\n",
    "        current_combo_losses = []\n",
    "        current_combo_accuracies = []\n",
    "        current_combo_aucs = []\n",
    "        current_combo_best_epoch = []\n",
    "\n",
    "        # Store results for each fold\n",
    "        fold_val_losses = []\n",
    "        fold_val_accuracies = []\n",
    "        fold_val_aucs = []\n",
    "        fold_no = 1\n",
    "\n",
    "        # K-Fold Cross-Validation\n",
    "        for train_indices, val_indices in sgkf.split(train_paths, train_labels, groups=subject_ids):\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"Training Fold {fold_no}/{N_SPLITS} for LR={current_lr:.1e} and Reg={current_reg:.0e}...\")\n",
    "            start_time_fold = time.time()\n",
    "\n",
    "            # Get the paths and labels for the current fold\n",
    "            fold_train_paths = train_paths[train_indices]\n",
    "            fold_train_labels = train_labels[train_indices]\n",
    "            fold_val_paths = train_paths[val_indices]\n",
    "            fold_val_labels = train_labels[val_indices]\n",
    "\n",
    "            # Verify that the training and validation sets have no overlapping subjects\n",
    "            train_subjects = set(subject_ids[train_indices])\n",
    "            val_subjects = set(subject_ids[val_indices])\n",
    "            if not train_subjects.isdisjoint(val_subjects):\n",
    "                raise RuntimeError(f\"WARNING: Fold {fold_no} has overlapping subjects!\")\n",
    "                \n",
    "            print(f\"  Train samples: {len(fold_train_paths)}, Validation samples: {len(fold_val_paths)}\")\n",
    "\n",
    "            # Calculate minmax parameters for the current training fold\n",
    "            fold_min, fold_max = calculate_min_max(fold_train_paths)\n",
    "\n",
    "            # Create fold train dataset\n",
    "            fold_train_data = create_dataset(\n",
    "                paths=fold_train_paths,\n",
    "                labels=fold_train_labels,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                volume_shape=VOLUME_SHAPE,\n",
    "                is_training=True, \n",
    "                seed=seed,\n",
    "                min_val=fold_min, \n",
    "                max_val=fold_max,\n",
    "                mask_path=ROI_MASK_PATH\n",
    "            )\n",
    "            \n",
    "            # Create fold validation dataset\n",
    "            fold_val_data = create_dataset(\n",
    "                paths=fold_val_paths,\n",
    "                labels=fold_val_labels,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                volume_shape=VOLUME_SHAPE,\n",
    "                is_training=False, \n",
    "                seed=None,\n",
    "                min_val=fold_min, \n",
    "                max_val=fold_max,\n",
    "                mask_path=ROI_MASK_PATH\n",
    "            )\n",
    "\n",
    "            if fold_train_data is None or fold_val_data is None:\n",
    "                raise RuntimeError(f\"ERROR: Could not create datasets for fold {fold_no}.\")\n",
    "\n",
    "            # Compute class weights for the current fold\n",
    "            unique_classes, class_counts = np.unique(fold_train_labels, return_counts=True)\n",
    "            print(f\"  Fold train label counts: {dict(zip(unique_classes, class_counts))}\")\n",
    "            fold_class_weights = class_weight.compute_class_weight('balanced', classes=unique_classes, y=fold_train_labels)\n",
    "            fold_class_weight_dict = dict(zip(unique_classes, fold_class_weights))\n",
    "            print(f\"  Fold Class Weights: {fold_class_weight_dict}\")\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            # Build the model\n",
    "            model = Resnet3DBuilder.build_resnet_34((91, 109, 91, 1), 1, reg_factor=current_reg, dropout_rate=DROPOUT_RATE)\n",
    "    \n",
    "            # Cosine decay scheduler\n",
    "            steps_per_epoch = math.ceil(len(fold_train_data) / BATCH_SIZE)\n",
    "            decay_steps = steps_per_epoch * NUM_EPOCHS\n",
    "            COSINE_ALPHA_FACTOR = 1e-6/current_lr # Alpha factor for cosine decay: finishes last epoch (NUM_EPOCHS) in 1e-6\n",
    "            cosine_decay = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=current_lr,\n",
    "                                                                     decay_steps=decay_steps,\n",
    "                                                                     alpha=COSINE_ALPHA_FACTOR,\n",
    "                                                                     name='CosineDecay')\n",
    "            \n",
    "            if lr_scheduler == \"cosine_decay\":\n",
    "                # Use cosine decay\n",
    "                optimizer_lr = cosine_decay\n",
    "                EARLY_STOP_PATIENCE = 20 # we use 20 to mitigate the effect of lucky steps at the beginning of the cosine decay\n",
    "            elif lr_scheduler == \"fixed_lr\":\n",
    "                # Use fixed learning rate\n",
    "                optimizer_lr = current_lr\n",
    "                EARLY_STOP_PATIENCE = 10 # we use 10 because with lower learning rates the model converges with more stability\n",
    "            else:\n",
    "                raise ValueError(\"Invalid string for 'lr_scheduler'. Please set it to 'cosine_decay' or 'fixed_lr'.\")\n",
    "            \n",
    "            early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                patience=EARLY_STOP_PATIENCE,\n",
    "                                                restore_best_weights=True,\n",
    "                                                verbose=1)\n",
    "    \n",
    "            callbacks_list = [early_stopper]\n",
    "\n",
    "            auc_metric = tf.keras.metrics.AUC(name='auc')\n",
    "\n",
    "            # Compile the model\n",
    "            model.compile(loss=\"binary_crossentropy\",\n",
    "                          optimizer= tf.keras.optimizers.Adam(learning_rate=optimizer_lr, clipnorm=1.0),\n",
    "                          metrics=[\"accuracy\", auc_metric])\n",
    "\n",
    "            history = model.fit(\n",
    "                fold_train_data,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                validation_data=fold_val_data,\n",
    "                class_weight=fold_class_weight_dict,\n",
    "                verbose=1,\n",
    "                callbacks=callbacks_list\n",
    "            )\n",
    "            \n",
    "            # Save the data for current fold\n",
    "            fold_dir = os.path.join(combo_results_dir, f\"fold_{fold_no}\")\n",
    "            os.makedirs(fold_dir, exist_ok=True)\n",
    "            history_df = pd.DataFrame(history.history)\n",
    "            history_df.insert(0, 'epoch', range(1, len(history_df) + 1))\n",
    "            history_csv_path = os.path.join(fold_dir, f\"history_fold_{fold_no}.csv\")\n",
    "            try:\n",
    "                history_df.to_csv(history_csv_path, index=False)\n",
    "                print(f\"  History saved to: {history_csv_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error saving history: {e}\")\n",
    "            # Save plots\n",
    "            plot_loss_curves(history, fold_dir)\n",
    "\n",
    "            # Evaluate the fold\n",
    "            best_epoch_index = np.argmin(history.history['val_loss'])\n",
    "            best_epoch = best_epoch_index + 1\n",
    "            val_loss_best = history.history['val_loss'][best_epoch_index]\n",
    "            val_accuracy_best = history.history['val_accuracy'][best_epoch_index]\n",
    "            val_auc_best = history.history['val_auc'][best_epoch_index]\n",
    "            print(f\"    Fold {fold_no} - Best Epoch {best_epoch}: Val Loss={val_loss_best:.4f}, Acc={val_accuracy_best:.4f}, AUC={val_auc_best:.4f}\")\n",
    "    \n",
    "            current_combo_losses.append(val_loss_best)\n",
    "            current_combo_accuracies.append(val_accuracy_best)\n",
    "            current_combo_aucs.append(val_auc_best)\n",
    "            current_combo_best_epoch.append(best_epoch)\n",
    "\n",
    "            # Clean up\n",
    "            del history_df\n",
    "            del history \n",
    "            del fold_train_data\n",
    "            del fold_val_data\n",
    "            del model\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "\n",
    "            end_time_fold = time.time()\n",
    "            print(f\"    Fold {fold_no} finished in {end_time_fold - start_time_fold:.2f} seconds.\")\n",
    "            fold_no += 1\n",
    "\n",
    "        # Aggregate results for the current hyperparameter combination\n",
    "        if len(current_combo_losses) == N_SPLITS:\n",
    "            avg_loss = np.mean(current_combo_losses)\n",
    "            std_loss = np.std(current_combo_losses)\n",
    "            avg_acc = np.mean(current_combo_accuracies)\n",
    "            std_acc = np.std(current_combo_accuracies)\n",
    "            avg_auc = np.mean(current_combo_aucs)\n",
    "            std_auc = np.std(current_combo_aucs)\n",
    "\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"Results for LR={current_lr}, L2_Reg={current_reg} (Across {N_SPLITS} Folds):\")\n",
    "            print(f\"  Avg Val Loss: {avg_loss:.4f} +/- {std_loss:.4f}\")\n",
    "            print(f\"  Avg Val Acc:  {avg_acc:.4f} +/- {std_acc:.4f}\")\n",
    "            print(f\"  Avg Val AUC:  {avg_auc:.4f} +/- {std_auc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "\n",
    "            # Store results\n",
    "            tuning_results.append({\n",
    "                'learning_rate': current_lr,\n",
    "                'reg_factor': current_reg,\n",
    "                'avg_val_loss': avg_loss,\n",
    "                'std_val_loss': std_loss,\n",
    "                'avg_val_accuracy': avg_acc,\n",
    "                'std_val_accuracy': std_acc,\n",
    "                'avg_val_auc': avg_auc,\n",
    "                'std_val_auc': std_auc,\n",
    "                'individual_losses': [round(loss, 4) for loss in current_combo_losses],\n",
    "                'individual_accuracies': [round(acc, 4) for acc in current_combo_accuracies],\n",
    "                'individual_aucs': [round(auc, 4) for auc in current_combo_aucs],\n",
    "                'best_epoch_per_fold': list(current_combo_best_epoch)\n",
    "            })\n",
    "\n",
    "        end_time_combination = time.time()\n",
    "        print(f\"Combination {current_combination_no} finished in {end_time_combination - start_time_combination:.2f} seconds.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "857587ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Tuning Results Summary:\n",
      "   learning_rate  reg_factor  avg_val_loss  avg_val_accuracy  avg_val_auc  \\\n",
      "0            0.0      0.0002        1.7938            0.7878       0.8357   \n",
      "\n",
      "   std_val_loss  std_val_accuracy  std_val_auc  \\\n",
      "0        0.2854            0.0481       0.0594   \n",
      "\n",
      "                          individual_losses  \\\n",
      "0  [2.1326, 2.1467, 1.6278, 1.5638, 1.4981]   \n",
      "\n",
      "                    individual_accuracies  \\\n",
      "0  [0.7268, 0.733, 0.8232, 0.8409, 0.815]   \n",
      "\n",
      "                           individual_aucs    best_epoch_per_fold  \n",
      "0  [0.748, 0.7827, 0.8831, 0.8663, 0.8985]  [91, 99, 97, 99, 100]  \n",
      "\n",
      " --- Best Hyperparameters Found ---\n",
      "learning_rate                                            0.000011\n",
      "reg_factor                                                 0.0002\n",
      "avg_val_loss                                             1.793826\n",
      "avg_val_accuracy                                         0.787775\n",
      "avg_val_auc                                              0.835703\n",
      "std_val_loss                                             0.285382\n",
      "std_val_accuracy                                         0.048057\n",
      "std_val_auc                                              0.059374\n",
      "individual_losses        [2.1326, 2.1467, 1.6278, 1.5638, 1.4981]\n",
      "individual_accuracies      [0.7268, 0.733, 0.8232, 0.8409, 0.815]\n",
      "individual_aucs           [0.748, 0.7827, 0.8831, 0.8663, 0.8985]\n",
      "best_epoch_per_fold                         [91, 99, 97, 99, 100]\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Selected best parameters: LR=1.1e-05, L2_Reg=2e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "if not tuning_results:\n",
    "    print(\"No tuning results were recorded.\")\n",
    "else:\n",
    "    \n",
    "    results_df = pd.DataFrame(tuning_results)\n",
    "    results_df = results_df.sort_values(by='avg_val_loss', ascending=False)\n",
    "\n",
    "    print(\"\\nTuning Results Summary:\")\n",
    "    display_cols = ['learning_rate', 'reg_factor', 'avg_val_loss', 'avg_val_accuracy', 'avg_val_auc', 'std_val_loss', 'std_val_accuracy', 'std_val_auc', 'individual_losses', 'individual_accuracies', 'individual_aucs', 'best_epoch_per_fold']\n",
    "    print(results_df[display_cols].round(4))\n",
    "\n",
    "    best_combination = results_df.iloc[0]\n",
    "\n",
    "    print(\"\\n --- Best Hyperparameters Found ---\")\n",
    "    print(best_combination[display_cols])\n",
    "\n",
    "    best_lr_final = best_combination['learning_rate']\n",
    "    best_reg_final = best_combination['reg_factor']\n",
    "    print(f\"\\nSelected best parameters: LR={best_lr_final:.1e}, L2_Reg={best_reg_final:.0e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facddd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67410d07",
   "metadata": {},
   "source": [
    "# --- Train the model with the best hyperparameters and evaluate it on the test set ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efad9e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ROI mask.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if ROI_MASK_PATH is None:\n",
    "    print(\"\\nUsing full brain scan.\\n\")\n",
    "else:\n",
    "    print(\"\\nUsing ROI mask.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a158e0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here CHANNELS last\n",
      "\n",
      "Using fixed learning rate: 1.1e-05\n",
      "\n",
      "Saving model to: /home/diogommiranda/tese/outputs/best_model.weights.h5\n",
      "  Class Weights: {0: 0.7730434782608696, 1: 1.4156050955414012}\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745938202.621540  199452 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_366__5', 12 bytes spill stores, 24 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_354__8', 2424 bytes spill stores, 2376 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_336__7', 1828 bytes spill stores, 1680 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_convert_reduce_fusion_16', 204 bytes spill stores, 204 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_1', 352 bytes spill stores, 352 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_3', 332 bytes spill stores, 332 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_convert_reduce_fusion_14', 204 bytes spill stores, 204 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_5', 352 bytes spill stores, 352 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_59', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6281 - auc: 0.6984 - loss: 3.8488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745938230.981460  199455 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_372__5', 12 bytes spill stores, 24 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_359__8', 2424 bytes spill stores, 2376 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_34', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_342__7', 1828 bytes spill stores, 1680 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 134ms/step - accuracy: 0.6291 - auc: 0.6994 - loss: 3.8479\n",
      "Epoch 2/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.8243 - auc: 0.9085 - loss: 3.5283\n",
      "Epoch 3/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.8842 - auc: 0.9372 - loss: 3.4426\n",
      "Epoch 4/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.9164 - auc: 0.9686 - loss: 3.3218\n",
      "Epoch 5/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.9502 - auc: 0.9805 - loss: 3.2299\n",
      "Epoch 6/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.9544 - auc: 0.9660 - loss: 3.2016\n",
      "Epoch 7/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.9577 - auc: 0.9899 - loss: 3.1389\n",
      "Epoch 8/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.9773 - auc: 0.9963 - loss: 3.0513\n",
      "Epoch 9/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 62ms/step - accuracy: 0.9824 - auc: 0.9956 - loss: 3.0221\n",
      "Epoch 10/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9663 - auc: 0.9866 - loss: 3.0307\n",
      "Epoch 11/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.9692 - auc: 0.9895 - loss: 3.0006\n",
      "Epoch 12/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.9872 - auc: 0.9885 - loss: 2.9703\n",
      "Epoch 13/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.9817 - auc: 0.9908 - loss: 2.9346\n",
      "Epoch 14/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 62ms/step - accuracy: 0.9856 - auc: 0.9860 - loss: 2.9054\n",
      "Epoch 15/15\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.9932 - auc: 0.9985 - loss: 2.8065\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9285 - auc: 0.2728 - loss: 3.2634\n",
      "[4.861815929412842, 0.7239819169044495]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Train the model with the best hyperparameters and evaluate it on the test set ---\n",
    "\n",
    "cosine_scheduler = False # Set to True if using cosine decay, False if using fixed learning rate\n",
    "\n",
    "train_for_more_epochs = False\n",
    "BEST_NUM_EPOCHS = 15 # number of epochs for training\n",
    "\n",
    "# Hyperparameters\n",
    "BEST_LR = 1.1e-5 # learning rate\n",
    "BEST_REG= 2e-4 # l2 regularization factor\n",
    "\n",
    "# Cosine decay parameters\n",
    "DECAY_STEPS_TO_USE = math.ceil(len(train_data) / BATCH_SIZE) * 100 # 100 epochs (used in cross-validation for cosine decay)\n",
    "BEST_ALPHA_FACTOR =  1e-6 / BEST_LR\n",
    "DROPOUT_RATE = 0.0\n",
    "cosine_decay = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=BEST_LR,\n",
    "                                                        decay_steps=DECAY_STEPS_TO_USE,\n",
    "                                                        alpha=BEST_ALPHA_FACTOR,\n",
    "                                                        name='CosineDecay')\n",
    "\n",
    "\n",
    "model = Resnet3DBuilder.build_resnet_34((91, 109, 91, 1), 1, reg_factor=BEST_REG, dropout_rate=DROPOUT_RATE)\n",
    "if train_for_more_epochs:\n",
    "    model.load_weights(\"/home/diogommiranda/tese/outputs/best_model.weights.h5\") # load model to continue training for more epochs\n",
    "    print(f\"\\nLoading model weights to continue training for more epochs.\")\n",
    "        \n",
    "\n",
    "if cosine_scheduler:\n",
    "    # Use cosine decay\n",
    "    optimizer_lr = cosine_decay\n",
    "    print(f\"\\nUsing cosine decay.\\n\")\n",
    "else:\n",
    "    # Use fixed learning rate\n",
    "    optimizer_lr = BEST_LR\n",
    "    print(f\"\\nUsing fixed learning rate: {BEST_LR}\\n\")\n",
    "\n",
    "auc_metric = tf.keras.metrics.AUC(name='auc')\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=optimizer_lr,\n",
    "                                                     clipnorm=1.0),\n",
    "                metrics=[\"accuracy\", auc_metric])\n",
    "\n",
    "\n",
    "# Only save the model if not using cosine decay\n",
    "if not cosine_scheduler:\n",
    "    check_point_filepath = \"/home/diogommiranda/tese/outputs/best_model.weights.h5\"\n",
    "    print(f\"Saving model to: {check_point_filepath}\")\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=check_point_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='loss',\n",
    "        mode='min',\n",
    "        save_best_only=False)\n",
    "    callbacks = [model_checkpoint_callback]\n",
    "else:\n",
    "    callbacks = None\n",
    "\n",
    "# Compute class weights\n",
    "unique_classes, class_counts = np.unique(train_labels, return_counts=True)\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=unique_classes, y=train_labels)\n",
    "class_weight_dict = dict(zip(unique_classes, class_weights))\n",
    "print(f\"  Class Weights: {class_weight_dict}\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=BEST_NUM_EPOCHS,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Plot loss and accuracy curves\n",
    "plot_loss_curves(history)\n",
    "\n",
    "result = model.evaluate(test_data, return_dict=True)\n",
    "print(f\"[{result['loss']}, {result['accuracy']}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7c4859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 09:38:37.470476: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Metrics on Test Set ---\n",
      "Accuracy:    0.7511\n",
      "Sensitivity: 0.6923\n",
      "Specificity: 0.7832 \n",
      "Balanced Accuracy (BACC): 0.7378\n",
      "F1 Score (Weighted):      0.7534\n",
      "Matthews Corr Coef (MCC): 0.4671\n",
      "Area Under the Curve (AUC): 0.8245\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(test_data).flatten()\n",
    "\n",
    "# --- Print evaluation metrics ---\n",
    "y_true = []\n",
    "test_samples = []\n",
    "for sample, label in test_data.as_numpy_iterator():\n",
    "    test_samples.append(sample)\n",
    "    y_true.append(label)\n",
    "y_true = np.concatenate(y_true)\n",
    "\n",
    "\n",
    "test_samples = np.concatenate(test_samples, axis=0)\n",
    "y_true_int = y_true.astype(int)\n",
    "y_pred_int = y_pred.round().astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_true_int, y_pred_int)\n",
    "sensitivity = recall_score(y_true_int, y_pred_int, pos_label=1)\n",
    "specificity = recall_score(y_true_int, y_pred_int, pos_label=0)\n",
    "bacc = balanced_accuracy_score(y_true_int, y_pred_int)\n",
    "f1 = f1_score(y_true_int, y_pred_int, average='weighted')\n",
    "mcc = matthews_corrcoef(y_true_int, y_pred_int)\n",
    "\n",
    "auc_score = result.get('auc')\n",
    "\n",
    "print(f\"\\n--- Evaluation Metrics on Test Set ---\")\n",
    "print(f\"Accuracy:    {accuracy:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f} \")\n",
    "print(f\"Balanced Accuracy (BACC): {bacc:.4f}\")\n",
    "print(f\"F1 Score (Weighted):      {f1:.4f}\") \n",
    "print(f\"Matthews Corr Coef (MCC): {mcc:.4f}\")\n",
    "print(f\"Area Under the Curve (AUC): {auc_score:.4f}\\n\")\n",
    "\n",
    "# --- Plot confusion matrix ---\n",
    "class0, class1 = DATASET.split(\"_\")\n",
    "target_names = [class0, class1]\n",
    "\n",
    "make_confusion_matrix(y_true=y_true,\n",
    "                      y_pred=y_pred.round(),\n",
    "                      classes=target_names,\n",
    "                      figsize=(8, 8),\n",
    "                      text_size=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d55452",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47d0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/saved_models/LR=1.1e-05_L2=2e-04\n"
     ]
    }
   ],
   "source": [
    "save_option = False # Set to True to save the model, confusion matrix, and evaluation metrics\n",
    "\n",
    "if save_option:\n",
    "    \n",
    "    # Configure the right path\n",
    "    if USE_MASK:\n",
    "        dir1 = \"masked/\"\n",
    "    else:\n",
    "        dir1 = \"full_brain/\"\n",
    "    if cosine_scheduler:\n",
    "        dir2 = \"cosine_decay/\"\n",
    "    else:\n",
    "        dir2 = \"fixed_lr/\"\n",
    "        \n",
    "    save_model_dir = \"/home/diogommiranda/tese/outputs/\" + dir1 + dir2 + \"CROSS_VALIDATION/saved_models/\" + f\"LR={BEST_LR:.1e}_L2={BEST_REG:.0e}\"\n",
    "    print(f\"Saving model to: {save_model_dir}\")\n",
    "    os.makedirs(save_model_dir, exist_ok=True)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(os.path.join(save_model_dir, \"model.keras\"))\n",
    "\n",
    "    # Save the confusion matrix plot\n",
    "    make_confusion_matrix(y_true=y_true,\n",
    "                        y_pred=y_pred.round(),\n",
    "                        classes=target_names,\n",
    "                        figsize=(8, 8),\n",
    "                        text_size=15,\n",
    "                        save_dir=save_model_dir)\n",
    "\n",
    "    # Save the test loss and accuracy and the evaluation metrics\n",
    "    result_file_path = os.path.join(save_model_dir, \"resultados.txt\")\n",
    "    with open(result_file_path, \"w\") as f:\n",
    "        f.write(\"[{result['loss']}, {result['accuracy']}]\\n\\n\")\n",
    "        f.write(\"--- Evaluation Metrics on Test Set ---\\n\")\n",
    "        f.write(f\"Accuracy:    {accuracy:.4f}\\n\")\n",
    "        f.write(f\"Sensitivity: {sensitivity:.4f}\\n\")\n",
    "        f.write(f\"Specificity: {specificity:.4f}\\n\")\n",
    "        f.write(f\"Balanced Accuracy (BACC): {bacc:.4f}\\n\")\n",
    "        f.write(f\"F1 Score (Weighted):      {f1:.4f}\\n\")\n",
    "        f.write(f\"Matthews Corr Coef (MCC): {mcc:.4f}\\n\")\n",
    "        f.write(f\"Area Under the Curve (AUC): {auc_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saved_model = tf.keras.models.load_model(\"/home/diogommiranda/tese/outputs/full_brain/fixed_lr/CROSS_VALIDATION/saved_models/LR=1.1e-5 L2=2e-4/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 118ms/step - accuracy: 0.8917 - auc: 0.3368 - loss: 1.7163\n",
      "[1.964396357536316, 0.8461538553237915]\n"
     ]
    }
   ],
   "source": [
    "#result = saved_model.evaluate(test_data, return_dict=True)\n",
    "#print(f\"[{result['loss']}, {result['accuracy']}]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
