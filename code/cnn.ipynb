{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3993ea",
   "metadata": {},
   "source": [
    "# Notebook to train CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa1e0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "# Load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "from Resnet3D_model import Resnet3DBuilder\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, matthews_corrcoef, accuracy_score, recall_score\n",
    "from data_utils import get_paths_and_labels, calculate_min_max, create_dataset, clean_zone_identifier_files, extract_subject_id\n",
    "from plotting_utils import view_image, view_random_image, plot_loss_curves, make_confusion_matrix, view_image_data\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccca6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6be449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision policy set to: mixed_float16\n"
     ]
    }
   ],
   "source": [
    "# Set mixed precision policy to 'mixed_float16'\n",
    "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.set_global_policy(policy)\n",
    "print('Mixed precision policy set to:', policy.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0dbea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class map: {'smci': 0, 'pmci': 1}\n",
      "Scanning /home/diogommiranda/tese/datasets/mni_reg_CV/smci_pmci/train...\n",
      "Found 575 files for class 'smci'\n",
      "Found 314 files for class 'pmci'\n",
      "Calculating minmax across 889 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 889\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "Class map: {'smci': 0, 'pmci': 1}\n",
      "Scanning /home/diogommiranda/tese/datasets/mni_reg_CV/smci_pmci/test...\n",
      "Found 143 files for class 'smci'\n",
      "Found 78 files for class 'pmci'\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NORMALIZATION = \"mni_reg_CV\" # Choose intensity normalization method: \"minmax\"\n",
    "DATASET = \"smci_pmci\" # Choose dataset: \"smci_pmci\" or \"nc_ad\"\n",
    "DATA_DIR = Path(\"/home/diogommiranda/tese/datasets/\") / NORMALIZATION / DATASET\n",
    "VOLUME_SHAPE = (91, 109, 91) # Expected volume shape of the PET images\n",
    "BATCH_SIZE = 4 # Set batch size\n",
    "\n",
    "USE_MASK = True # Set to True to use the ROI mask, False to use the whole brain\n",
    "\n",
    "if USE_MASK:\n",
    "    ROI_MASK_PATH = str(Path(\"/home/diogommiranda/tese/masks/ROI_MASK.nii\"))\n",
    "else:\n",
    "    ROI_MASK_PATH = None\n",
    "\n",
    "# Get train paths and labels to calculate minmax values\n",
    "train_paths, train_labels_list, class_map = get_paths_and_labels(DATA_DIR, 'train')\n",
    "train_paths = np.array(train_paths)\n",
    "train_labels = np.array(train_labels_list)\n",
    "\n",
    "# Calculate minmax values for train set\n",
    "minmax_min, minmax_max = calculate_min_max(train_paths)\n",
    "\n",
    "# Create train dataset\n",
    "train_data = create_dataset(\n",
    "    paths=train_paths,\n",
    "    labels=train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    volume_shape=VOLUME_SHAPE,\n",
    "    is_training=True,\n",
    "    seed=seed,\n",
    "    min_val=minmax_min, \n",
    "    max_val=minmax_max, \n",
    "    mask_path=ROI_MASK_PATH\n",
    "    )\n",
    "\n",
    "# Create test set with the minmax values from train\n",
    "test_paths, test_labels, _ = get_paths_and_labels(DATA_DIR, 'test', class_map=class_map)\n",
    "test_data = create_dataset(\n",
    "    paths=test_paths,\n",
    "    labels=test_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    volume_shape=VOLUME_SHAPE,\n",
    "    is_training=False,\n",
    "    seed=None,\n",
    "    min_val=minmax_min, \n",
    "    max_val=minmax_max,\n",
    "    mask_path=ROI_MASK_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84def554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify data with a test sample\n",
    "for data, label in test_data:\n",
    "    view_image_data(data[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/\n",
      "\n",
      "Starting Hyperparameter Tuning Grid Search...\n",
      "============================================================\n",
      "Testing Combination 1/1: LR=1.1e-05, L2_Reg=2e-04\n",
      "============================================================\n",
      "  Saving results for this combo to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04\n",
      "------------------------------------------------------------\n",
      "Training Fold 1/5 for LR=1.1e-05 and Reg=2e-04...\n",
      "  Train samples: 706, Validation samples: 183\n",
      "Calculating minmax across 706 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 706\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "  Fold train label counts: {0: 456, 1: 250}\n",
      "  Fold Class Weights: {0: 0.7741228070175439, 1: 1.412}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745822929.573554 1681620 service.cc:145] XLA service 0x7ff2d0005660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745822929.573768 1681620 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2025-04-28 07:48:53.632319: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-28 07:48:57.824438: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745822951.112729 1681620 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_32', 536 bytes spill stores, 536 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_31', 280 bytes spill stores, 280 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_36', 528 bytes spill stores, 528 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_30', 280 bytes spill stores, 280 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_28', 268 bytes spill stores, 268 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_29', 624 bytes spill stores, 580 bytes spill loads\n",
      "\n",
      "I0000 00:00:1745822951.171737 1681620 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m176/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7293 - auc: 0.7231 - loss: 3.8329"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745822976.701711 1681619 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_32', 48 bytes spill stores, 48 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_28', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_29', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 184ms/step - accuracy: 0.7297 - auc: 0.7242 - loss: 3.8318 - val_accuracy: 0.3497 - val_auc: 0.7559 - val_loss: 4.6668\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.8540 - auc: 0.9110 - loss: 3.5342 - val_accuracy: 0.3497 - val_auc: 0.7358 - val_loss: 5.7540\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.8830 - auc: 0.9470 - loss: 3.4153 - val_accuracy: 0.3770 - val_auc: 0.7092 - val_loss: 4.6886\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9304 - auc: 0.9734 - loss: 3.3226 - val_accuracy: 0.3497 - val_auc: 0.7265 - val_loss: 5.5025\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9453 - auc: 0.9846 - loss: 3.2400 - val_accuracy: 0.6230 - val_auc: 0.7621 - val_loss: 4.0548\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9549 - auc: 0.9851 - loss: 3.1946 - val_accuracy: 0.7650 - val_auc: 0.6849 - val_loss: 4.3954\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9806 - auc: 0.9903 - loss: 3.1436 - val_accuracy: 0.3825 - val_auc: 0.7256 - val_loss: 5.5054\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9445 - auc: 0.9714 - loss: 3.2074 - val_accuracy: 0.5410 - val_auc: 0.7281 - val_loss: 4.3576\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9683 - auc: 0.9922 - loss: 3.0838 - val_accuracy: 0.7650 - val_auc: 0.7082 - val_loss: 4.2723\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9819 - auc: 0.9934 - loss: 3.0274 - val_accuracy: 0.7486 - val_auc: 0.7059 - val_loss: 4.9836\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9846 - auc: 0.9911 - loss: 3.0121 - val_accuracy: 0.7705 - val_auc: 0.6915 - val_loss: 4.2479\n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 0.9926 - auc: 0.9991 - loss: 2.9411 - val_accuracy: 0.7486 - val_auc: 0.7327 - val_loss: 3.8406\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9813 - auc: 0.9975 - loss: 2.9494 - val_accuracy: 0.7705 - val_auc: 0.6979 - val_loss: 4.3950\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9933 - auc: 0.9933 - loss: 2.8915 - val_accuracy: 0.5191 - val_auc: 0.7331 - val_loss: 4.5556\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9970 - auc: 0.9999 - loss: 2.8419 - val_accuracy: 0.7760 - val_auc: 0.6983 - val_loss: 4.4526\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9989 - auc: 0.9944 - loss: 2.8020 - val_accuracy: 0.6940 - val_auc: 0.7464 - val_loss: 3.8558\n",
      "Epoch 17/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 92ms/step - accuracy: 0.9899 - auc: 0.9938 - loss: 2.7969 - val_accuracy: 0.6284 - val_auc: 0.7524 - val_loss: 3.6667\n",
      "Epoch 18/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9950 - auc: 0.9993 - loss: 2.7655 - val_accuracy: 0.7650 - val_auc: 0.7249 - val_loss: 3.8028\n",
      "Epoch 19/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9948 - auc: 0.9995 - loss: 2.7305 - val_accuracy: 0.7650 - val_auc: 0.7128 - val_loss: 4.1211\n",
      "Epoch 20/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9948 - auc: 0.9999 - loss: 2.6936 - val_accuracy: 0.7650 - val_auc: 0.7255 - val_loss: 4.5169\n",
      "Epoch 21/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9923 - auc: 0.9988 - loss: 2.6806 - val_accuracy: 0.6503 - val_auc: 0.7538 - val_loss: 3.6830\n",
      "Epoch 22/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9975 - auc: 0.9942 - loss: 2.6482 - val_accuracy: 0.6503 - val_auc: 0.7479 - val_loss: 3.5568\n",
      "Epoch 23/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.5804 - val_accuracy: 0.7705 - val_auc: 0.7159 - val_loss: 3.9412\n",
      "Epoch 24/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9972 - auc: 0.9993 - loss: 2.5683 - val_accuracy: 0.5410 - val_auc: 0.7346 - val_loss: 4.0853\n",
      "Epoch 25/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9954 - auc: 0.9953 - loss: 2.5563 - val_accuracy: 0.7596 - val_auc: 0.7243 - val_loss: 4.7044\n",
      "Epoch 26/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9959 - auc: 0.9995 - loss: 2.4930 - val_accuracy: 0.7158 - val_auc: 0.6794 - val_loss: 6.0033\n",
      "Epoch 27/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9907 - auc: 0.9943 - loss: 2.4935 - val_accuracy: 0.6776 - val_auc: 0.7308 - val_loss: 3.5515\n",
      "Epoch 28/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9940 - auc: 0.9999 - loss: 2.4316 - val_accuracy: 0.6339 - val_auc: 0.7485 - val_loss: 3.4806\n",
      "Epoch 29/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9998 - auc: 1.0000 - loss: 2.3756 - val_accuracy: 0.5792 - val_auc: 0.7451 - val_loss: 3.3847\n",
      "Epoch 30/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9999 - auc: 1.0000 - loss: 2.3417 - val_accuracy: 0.7377 - val_auc: 0.7317 - val_loss: 3.6700\n",
      "Epoch 31/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3070 - val_accuracy: 0.7978 - val_auc: 0.7314 - val_loss: 3.7504\n",
      "Epoch 32/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9942 - auc: 0.9998 - loss: 2.2923 - val_accuracy: 0.6995 - val_auc: 0.7231 - val_loss: 3.0892\n",
      "Epoch 33/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2445 - val_accuracy: 0.7650 - val_auc: 0.7107 - val_loss: 4.1612\n",
      "Epoch 34/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9664 - auc: 0.9916 - loss: 2.3025 - val_accuracy: 0.6940 - val_auc: 0.7128 - val_loss: 3.4497\n",
      "Epoch 35/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9995 - auc: 0.9940 - loss: 2.1862 - val_accuracy: 0.7760 - val_auc: 0.7291 - val_loss: 3.6263\n",
      "Epoch 36/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9994 - auc: 0.9940 - loss: 2.1638 - val_accuracy: 0.5301 - val_auc: 0.7220 - val_loss: 3.7289\n",
      "Epoch 37/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.1248 - val_accuracy: 0.6995 - val_auc: 0.7265 - val_loss: 3.2099\n",
      "Epoch 38/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9958 - auc: 1.0000 - loss: 2.1016 - val_accuracy: 0.6721 - val_auc: 0.7296 - val_loss: 3.3057\n",
      "Epoch 39/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.0635 - val_accuracy: 0.7432 - val_auc: 0.6983 - val_loss: 3.5278\n",
      "Epoch 40/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0348 - val_accuracy: 0.7158 - val_auc: 0.7350 - val_loss: 3.2127\n",
      "Epoch 41/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9996 - auc: 1.0000 - loss: 2.0029 - val_accuracy: 0.7104 - val_auc: 0.7433 - val_loss: 2.9714\n",
      "Epoch 42/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.9778 - val_accuracy: 0.7596 - val_auc: 0.6752 - val_loss: 3.4657\n",
      "Epoch 43/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9433 - val_accuracy: 0.5738 - val_auc: 0.7342 - val_loss: 3.3718\n",
      "Epoch 44/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9100 - val_accuracy: 0.7049 - val_auc: 0.7228 - val_loss: 2.8792\n",
      "Epoch 45/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8772 - val_accuracy: 0.7158 - val_auc: 0.7133 - val_loss: 3.0480\n",
      "Epoch 46/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8427 - val_accuracy: 0.6940 - val_auc: 0.7290 - val_loss: 2.9671\n",
      "Epoch 47/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.8094 - val_accuracy: 0.6885 - val_auc: 0.7197 - val_loss: 2.9716\n",
      "Epoch 48/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7718 - val_accuracy: 0.6940 - val_auc: 0.7279 - val_loss: 2.8953\n",
      "Epoch 49/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7334 - val_accuracy: 0.7486 - val_auc: 0.7145 - val_loss: 2.9633\n",
      "Epoch 50/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9992 - auc: 1.0000 - loss: 1.6961 - val_accuracy: 0.6831 - val_auc: 0.7440 - val_loss: 2.7327\n",
      "Epoch 51/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9894 - auc: 0.9995 - loss: 1.6859 - val_accuracy: 0.7213 - val_auc: 0.7111 - val_loss: 3.1490\n",
      "Epoch 52/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9910 - auc: 0.9877 - loss: 1.7399 - val_accuracy: 0.6667 - val_auc: 0.7306 - val_loss: 2.7525\n",
      "Epoch 53/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6193 - val_accuracy: 0.6230 - val_auc: 0.7125 - val_loss: 2.6454\n",
      "Epoch 54/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5992 - val_accuracy: 0.7213 - val_auc: 0.7110 - val_loss: 2.7432\n",
      "Epoch 55/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.5764 - val_accuracy: 0.6940 - val_auc: 0.7101 - val_loss: 2.7746\n",
      "Epoch 56/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.5563 - val_accuracy: 0.7268 - val_auc: 0.7149 - val_loss: 2.9013\n",
      "Epoch 57/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5331 - val_accuracy: 0.6776 - val_auc: 0.7217 - val_loss: 2.7688\n",
      "Epoch 58/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5096 - val_accuracy: 0.6995 - val_auc: 0.7308 - val_loss: 2.6982\n",
      "Epoch 59/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4853 - val_accuracy: 0.7377 - val_auc: 0.7293 - val_loss: 2.7101\n",
      "Epoch 60/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4600 - val_accuracy: 0.6721 - val_auc: 0.7356 - val_loss: 2.7058\n",
      "Epoch 61/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9987 - auc: 0.9944 - loss: 1.4400 - val_accuracy: 0.7049 - val_auc: 0.7538 - val_loss: 2.3854\n",
      "Epoch 62/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.4061 - val_accuracy: 0.7213 - val_auc: 0.7419 - val_loss: 2.5177\n",
      "Epoch 63/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3793 - val_accuracy: 0.6831 - val_auc: 0.7303 - val_loss: 2.4893\n",
      "Epoch 64/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3495 - val_accuracy: 0.7104 - val_auc: 0.7328 - val_loss: 2.5069\n",
      "Epoch 65/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9890 - auc: 0.9983 - loss: 1.3489 - val_accuracy: 0.5191 - val_auc: 0.7102 - val_loss: 2.3913\n",
      "Epoch 66/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9854 - auc: 0.9976 - loss: 1.3487 - val_accuracy: 0.5738 - val_auc: 0.6997 - val_loss: 2.7283\n",
      "Epoch 67/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2973 - val_accuracy: 0.4918 - val_auc: 0.7119 - val_loss: 3.5397\n",
      "Epoch 68/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2812 - val_accuracy: 0.7104 - val_auc: 0.7175 - val_loss: 2.3201\n",
      "Epoch 69/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.2651 - val_accuracy: 0.6776 - val_auc: 0.7192 - val_loss: 2.3917\n",
      "Epoch 70/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 90ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.2512 - val_accuracy: 0.7814 - val_auc: 0.6799 - val_loss: 3.5298\n",
      "Epoch 71/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9967 - auc: 0.9999 - loss: 1.2482 - val_accuracy: 0.6885 - val_auc: 0.7399 - val_loss: 2.3512\n",
      "Epoch 72/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2245 - val_accuracy: 0.6831 - val_auc: 0.7371 - val_loss: 2.3744\n",
      "Epoch 73/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2074 - val_accuracy: 0.6667 - val_auc: 0.7333 - val_loss: 2.4232\n",
      "Epoch 74/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9986 - auc: 1.0000 - loss: 1.1983 - val_accuracy: 0.5464 - val_auc: 0.7193 - val_loss: 3.6945\n",
      "Epoch 75/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 0.9990 - auc: 1.0000 - loss: 1.1839 - val_accuracy: 0.6667 - val_auc: 0.7461 - val_loss: 2.1688\n",
      "Epoch 76/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.1653 - val_accuracy: 0.6831 - val_auc: 0.7486 - val_loss: 2.3855\n",
      "Epoch 77/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1511 - val_accuracy: 0.6831 - val_auc: 0.7681 - val_loss: 2.3814\n",
      "Epoch 78/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.1356 - val_accuracy: 0.7268 - val_auc: 0.7530 - val_loss: 2.2505\n",
      "Epoch 79/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1199 - val_accuracy: 0.7158 - val_auc: 0.7558 - val_loss: 2.2674\n",
      "Epoch 80/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1028 - val_accuracy: 0.7104 - val_auc: 0.7533 - val_loss: 2.2590\n",
      "Epoch 81/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0842 - val_accuracy: 0.6940 - val_auc: 0.7524 - val_loss: 2.2658\n",
      "Epoch 82/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.0659 - val_accuracy: 0.6885 - val_auc: 0.7512 - val_loss: 2.2703\n",
      "Epoch 83/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9987 - auc: 0.9992 - loss: 1.0559 - val_accuracy: 0.6503 - val_auc: 0.5312 - val_loss: 6.4744\n",
      "Epoch 84/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9735 - auc: 0.9974 - loss: 1.1041 - val_accuracy: 0.6667 - val_auc: 0.7245 - val_loss: 2.4626\n",
      "Epoch 85/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9823 - auc: 0.9849 - loss: 1.1221 - val_accuracy: 0.6831 - val_auc: 0.7236 - val_loss: 2.2925\n",
      "Epoch 86/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9882 - auc: 0.9790 - loss: 1.1172 - val_accuracy: 0.7432 - val_auc: 0.6841 - val_loss: 4.0454\n",
      "Epoch 87/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9957 - auc: 0.9996 - loss: 1.0244 - val_accuracy: 0.6230 - val_auc: 0.7490 - val_loss: 2.2363\n",
      "Epoch 88/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0057 - val_accuracy: 0.6066 - val_auc: 0.7306 - val_loss: 2.3739\n",
      "Epoch 89/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9928 - val_accuracy: 0.3497 - val_auc: 0.5504 - val_loss: 6.9402\n",
      "Epoch 90/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 0.9933 - auc: 1.0000 - loss: 0.9949 - val_accuracy: 0.7158 - val_auc: 0.7471 - val_loss: 2.1442\n",
      "Epoch 91/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9755 - val_accuracy: 0.7268 - val_auc: 0.7480 - val_loss: 2.1326\n",
      "Epoch 92/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9998 - auc: 1.0000 - loss: 0.9663 - val_accuracy: 0.7596 - val_auc: 0.6989 - val_loss: 3.0502\n",
      "Epoch 93/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.9548 - val_accuracy: 0.7705 - val_auc: 0.7037 - val_loss: 2.7279\n",
      "Epoch 94/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9445 - val_accuracy: 0.7049 - val_auc: 0.7207 - val_loss: 2.2315\n",
      "Epoch 95/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9342 - val_accuracy: 0.5847 - val_auc: 0.7384 - val_loss: 2.5842\n",
      "Epoch 96/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9217 - val_accuracy: 0.5574 - val_auc: 0.7229 - val_loss: 2.6552\n",
      "Epoch 97/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9100 - val_accuracy: 0.6885 - val_auc: 0.7145 - val_loss: 2.2313\n",
      "Epoch 98/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8967 - val_accuracy: 0.6885 - val_auc: 0.7201 - val_loss: 2.2574\n",
      "Epoch 99/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.8825 - val_accuracy: 0.6776 - val_auc: 0.7241 - val_loss: 2.3559\n",
      "Epoch 100/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9922 - auc: 0.9996 - loss: 0.8888 - val_accuracy: 0.7158 - val_auc: 0.7205 - val_loss: 2.4037\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "  History saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04/fold_1/history_fold_1.csv\n",
      "    Fold 1 - Best Epoch 91: Val Loss=2.1326, Acc=0.7268, AUC=0.7480\n",
      "    Fold 1 finished in 1481.29 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 2/5 for LR=1.1e-05 and Reg=2e-04...\n",
      "  Train samples: 713, Validation samples: 176\n",
      "Calculating minmax across 713 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 713\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "  Fold train label counts: {0: 452, 1: 261}\n",
      "  Fold Class Weights: {0: 0.7887168141592921, 1: 1.3659003831417624}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 159ms/step - accuracy: 0.6217 - auc: 0.6278 - loss: 3.8625 - val_accuracy: 0.3011 - val_auc: 0.7713 - val_loss: 4.9428\n",
      "Epoch 2/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.8376 - auc: 0.9097 - loss: 3.5420 - val_accuracy: 0.3011 - val_auc: 0.8176 - val_loss: 6.0069\n",
      "Epoch 3/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.9041 - auc: 0.9724 - loss: 3.3619 - val_accuracy: 0.3239 - val_auc: 0.8620 - val_loss: 4.9416\n",
      "Epoch 4/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 92ms/step - accuracy: 0.9058 - auc: 0.9477 - loss: 3.3728 - val_accuracy: 0.5795 - val_auc: 0.8438 - val_loss: 4.0723\n",
      "Epoch 5/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9180 - auc: 0.9733 - loss: 3.2868 - val_accuracy: 0.7727 - val_auc: 0.8381 - val_loss: 3.6497\n",
      "Epoch 6/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9080 - auc: 0.9756 - loss: 3.2556 - val_accuracy: 0.7784 - val_auc: 0.8287 - val_loss: 3.6913\n",
      "Epoch 7/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9624 - auc: 0.9898 - loss: 3.1455 - val_accuracy: 0.6591 - val_auc: 0.8288 - val_loss: 3.8992\n",
      "Epoch 8/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9672 - auc: 0.9838 - loss: 3.1497 - val_accuracy: 0.8068 - val_auc: 0.8647 - val_loss: 3.5222\n",
      "Epoch 9/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9783 - auc: 0.9975 - loss: 3.0467 - val_accuracy: 0.6193 - val_auc: 0.8627 - val_loss: 4.1405\n",
      "Epoch 10/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9769 - auc: 0.9881 - loss: 3.0681 - val_accuracy: 0.7557 - val_auc: 0.7992 - val_loss: 3.9464\n",
      "Epoch 11/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9817 - auc: 0.9917 - loss: 2.9962 - val_accuracy: 0.6136 - val_auc: 0.8146 - val_loss: 3.9679\n",
      "Epoch 12/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9729 - auc: 0.9958 - loss: 2.9971 - val_accuracy: 0.6818 - val_auc: 0.7690 - val_loss: 3.7771\n",
      "Epoch 13/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9779 - auc: 0.9874 - loss: 2.9800 - val_accuracy: 0.7159 - val_auc: 0.7406 - val_loss: 4.4083\n",
      "Epoch 14/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9761 - auc: 0.9970 - loss: 2.9361 - val_accuracy: 0.7500 - val_auc: 0.8038 - val_loss: 3.6627\n",
      "Epoch 15/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9986 - auc: 0.9818 - loss: 2.8566 - val_accuracy: 0.5511 - val_auc: 0.8069 - val_loss: 4.3852\n",
      "Epoch 16/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9885 - auc: 0.9977 - loss: 2.8607 - val_accuracy: 0.7102 - val_auc: 0.7142 - val_loss: 4.3622\n",
      "Epoch 17/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9817 - auc: 0.9905 - loss: 2.8407 - val_accuracy: 0.3409 - val_auc: 0.7202 - val_loss: 6.1402\n",
      "Epoch 18/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9936 - auc: 0.9978 - loss: 2.7914 - val_accuracy: 0.6420 - val_auc: 0.7888 - val_loss: 3.7457\n",
      "Epoch 19/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9872 - auc: 0.9999 - loss: 2.7653 - val_accuracy: 0.7614 - val_auc: 0.8024 - val_loss: 3.4795\n",
      "Epoch 20/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9979 - auc: 0.9999 - loss: 2.7186 - val_accuracy: 0.7500 - val_auc: 0.7970 - val_loss: 3.4901\n",
      "Epoch 21/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9895 - auc: 1.0000 - loss: 2.6901 - val_accuracy: 0.8011 - val_auc: 0.8023 - val_loss: 3.5401\n",
      "Epoch 22/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9996 - auc: 1.0000 - loss: 2.6390 - val_accuracy: 0.7784 - val_auc: 0.8250 - val_loss: 3.3682\n",
      "Epoch 23/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.6070 - val_accuracy: 0.6648 - val_auc: 0.8168 - val_loss: 3.7913\n",
      "Epoch 24/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9977 - auc: 0.9833 - loss: 2.5799 - val_accuracy: 0.7216 - val_auc: 0.8078 - val_loss: 3.5886\n",
      "Epoch 25/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9995 - auc: 0.9944 - loss: 2.5457 - val_accuracy: 0.7273 - val_auc: 0.8180 - val_loss: 3.4556\n",
      "Epoch 26/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9974 - auc: 0.9944 - loss: 2.5107 - val_accuracy: 0.4205 - val_auc: 0.7296 - val_loss: 5.1714\n",
      "Epoch 27/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9929 - auc: 0.9998 - loss: 2.4908 - val_accuracy: 0.8011 - val_auc: 0.8103 - val_loss: 3.3771\n",
      "Epoch 28/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4328 - val_accuracy: 0.7386 - val_auc: 0.8034 - val_loss: 3.3589\n",
      "Epoch 29/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9994 - auc: 1.0000 - loss: 2.4022 - val_accuracy: 0.7386 - val_auc: 0.7605 - val_loss: 4.0299\n",
      "Epoch 30/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3665 - val_accuracy: 0.6818 - val_auc: 0.7966 - val_loss: 3.4997\n",
      "Epoch 31/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9936 - auc: 0.9997 - loss: 2.3419 - val_accuracy: 0.4205 - val_auc: 0.7733 - val_loss: 5.0985\n",
      "Epoch 32/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2906 - val_accuracy: 0.7500 - val_auc: 0.8133 - val_loss: 3.2800\n",
      "Epoch 33/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2584 - val_accuracy: 0.5568 - val_auc: 0.7946 - val_loss: 4.1819\n",
      "Epoch 34/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2179 - val_accuracy: 0.6364 - val_auc: 0.7782 - val_loss: 3.6646\n",
      "Epoch 35/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 90ms/step - accuracy: 0.9932 - auc: 0.9989 - loss: 2.2123 - val_accuracy: 0.7784 - val_auc: 0.7628 - val_loss: 3.4155\n",
      "Epoch 36/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9950 - auc: 0.9994 - loss: 2.1624 - val_accuracy: 0.6989 - val_auc: 0.6805 - val_loss: 4.7590\n",
      "Epoch 37/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.9821 - auc: 0.9927 - loss: 2.1615 - val_accuracy: 0.7500 - val_auc: 0.8193 - val_loss: 2.9255\n",
      "Epoch 38/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0915 - val_accuracy: 0.7670 - val_auc: 0.8041 - val_loss: 2.9408\n",
      "Epoch 39/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0543 - val_accuracy: 0.7102 - val_auc: 0.8036 - val_loss: 3.2398\n",
      "Epoch 40/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.9986 - auc: 1.0000 - loss: 2.0292 - val_accuracy: 0.7784 - val_auc: 0.8265 - val_loss: 2.7985\n",
      "Epoch 41/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9945 - val_accuracy: 0.7159 - val_auc: 0.8109 - val_loss: 3.0743\n",
      "Epoch 42/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.9602 - val_accuracy: 0.7841 - val_auc: 0.8168 - val_loss: 2.7877\n",
      "Epoch 43/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9996 - auc: 1.0000 - loss: 1.9264 - val_accuracy: 0.7841 - val_auc: 0.8443 - val_loss: 2.6642\n",
      "Epoch 44/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 1.8898 - val_accuracy: 0.8011 - val_auc: 0.8264 - val_loss: 2.7609\n",
      "Epoch 45/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9991 - auc: 1.0000 - loss: 1.8579 - val_accuracy: 0.5682 - val_auc: 0.8022 - val_loss: 3.6373\n",
      "Epoch 46/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9880 - auc: 0.9942 - loss: 1.8726 - val_accuracy: 0.6250 - val_auc: 0.7927 - val_loss: 3.2559\n",
      "Epoch 47/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9906 - auc: 0.9967 - loss: 1.8355 - val_accuracy: 0.6761 - val_auc: 0.7944 - val_loss: 2.7030\n",
      "Epoch 48/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7812 - val_accuracy: 0.5341 - val_auc: 0.7501 - val_loss: 3.8290\n",
      "Epoch 49/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9985 - auc: 0.9930 - loss: 1.7647 - val_accuracy: 0.7216 - val_auc: 0.7935 - val_loss: 2.6492\n",
      "Epoch 50/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9972 - auc: 0.9999 - loss: 1.7408 - val_accuracy: 0.7045 - val_auc: 0.8020 - val_loss: 2.8080\n",
      "Epoch 51/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9985 - auc: 1.0000 - loss: 1.7152 - val_accuracy: 0.7443 - val_auc: 0.7905 - val_loss: 2.5844\n",
      "Epoch 52/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6902 - val_accuracy: 0.7500 - val_auc: 0.7893 - val_loss: 2.6208\n",
      "Epoch 53/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6677 - val_accuracy: 0.7159 - val_auc: 0.7969 - val_loss: 2.6425\n",
      "Epoch 54/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6435 - val_accuracy: 0.7273 - val_auc: 0.7990 - val_loss: 2.6339\n",
      "Epoch 55/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6200 - val_accuracy: 0.6989 - val_auc: 0.7945 - val_loss: 2.7102\n",
      "Epoch 56/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5936 - val_accuracy: 0.6989 - val_auc: 0.7845 - val_loss: 2.7265\n",
      "Epoch 57/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5677 - val_accuracy: 0.7670 - val_auc: 0.7668 - val_loss: 2.8411\n",
      "Epoch 58/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 0.9919 - auc: 0.9998 - loss: 1.5537 - val_accuracy: 0.7614 - val_auc: 0.8179 - val_loss: 2.4075\n",
      "Epoch 59/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5224 - val_accuracy: 0.7727 - val_auc: 0.7903 - val_loss: 2.5934\n",
      "Epoch 60/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4959 - val_accuracy: 0.7841 - val_auc: 0.7639 - val_loss: 2.7232\n",
      "Epoch 61/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9944 - auc: 1.0000 - loss: 1.4811 - val_accuracy: 0.7216 - val_auc: 0.7830 - val_loss: 2.8974\n",
      "Epoch 62/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4491 - val_accuracy: 0.7500 - val_auc: 0.8121 - val_loss: 2.6331\n",
      "Epoch 63/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4259 - val_accuracy: 0.7216 - val_auc: 0.8003 - val_loss: 2.6546\n",
      "Epoch 64/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4037 - val_accuracy: 0.7330 - val_auc: 0.8095 - val_loss: 2.5348\n",
      "Epoch 65/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3785 - val_accuracy: 0.7330 - val_auc: 0.8071 - val_loss: 2.5204\n",
      "Epoch 66/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9986 - auc: 1.0000 - loss: 1.3575 - val_accuracy: 0.7898 - val_auc: 0.7940 - val_loss: 2.3009\n",
      "Epoch 67/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9922 - auc: 0.9968 - loss: 1.3726 - val_accuracy: 0.6989 - val_auc: 0.5254 - val_loss: 5.8583\n",
      "Epoch 68/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9921 - auc: 0.9942 - loss: 1.3456 - val_accuracy: 0.7045 - val_auc: 0.6300 - val_loss: 4.2801\n",
      "Epoch 69/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3064 - val_accuracy: 0.6364 - val_auc: 0.7898 - val_loss: 2.9624\n",
      "Epoch 70/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2919 - val_accuracy: 0.6307 - val_auc: 0.7770 - val_loss: 3.2888\n",
      "Epoch 71/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.2819 - val_accuracy: 0.7102 - val_auc: 0.7861 - val_loss: 2.5870\n",
      "Epoch 72/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2621 - val_accuracy: 0.7102 - val_auc: 0.7822 - val_loss: 2.4997\n",
      "Epoch 73/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.2469 - val_accuracy: 0.7670 - val_auc: 0.7776 - val_loss: 2.3941\n",
      "Epoch 74/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2306 - val_accuracy: 0.7386 - val_auc: 0.7866 - val_loss: 2.3708\n",
      "Epoch 75/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2130 - val_accuracy: 0.7273 - val_auc: 0.7847 - val_loss: 2.3550\n",
      "Epoch 76/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 1.1956 - val_accuracy: 0.6136 - val_auc: 0.7546 - val_loss: 3.0308\n",
      "Epoch 77/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9915 - auc: 0.9902 - loss: 1.2166 - val_accuracy: 0.4659 - val_auc: 0.7206 - val_loss: 3.4236\n",
      "Epoch 78/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9944 - auc: 0.9997 - loss: 1.1925 - val_accuracy: 0.7955 - val_auc: 0.7879 - val_loss: 2.1776\n",
      "Epoch 79/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9983 - auc: 1.0000 - loss: 1.1592 - val_accuracy: 0.7159 - val_auc: 0.7948 - val_loss: 2.2752\n",
      "Epoch 80/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1401 - val_accuracy: 0.7159 - val_auc: 0.7823 - val_loss: 2.3526\n",
      "Epoch 81/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1286 - val_accuracy: 0.7216 - val_auc: 0.7811 - val_loss: 2.3814\n",
      "Epoch 82/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1138 - val_accuracy: 0.6705 - val_auc: 0.7645 - val_loss: 2.6513\n",
      "Epoch 83/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1001 - val_accuracy: 0.6932 - val_auc: 0.7675 - val_loss: 2.5701\n",
      "Epoch 84/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0845 - val_accuracy: 0.7045 - val_auc: 0.7728 - val_loss: 2.4173\n",
      "Epoch 85/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9889 - loss: 1.0697 - val_accuracy: 0.3636 - val_auc: 0.6305 - val_loss: 5.3458\n",
      "Epoch 86/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9892 - auc: 0.9978 - loss: 1.1003 - val_accuracy: 0.5341 - val_auc: 0.7474 - val_loss: 2.9422\n",
      "Epoch 87/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9808 - auc: 0.9935 - loss: 1.0867 - val_accuracy: 0.7727 - val_auc: 0.7402 - val_loss: 2.2946\n",
      "Epoch 88/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9945 - auc: 1.0000 - loss: 1.0448 - val_accuracy: 0.7386 - val_auc: 0.7968 - val_loss: 2.1728\n",
      "Epoch 89/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0332 - val_accuracy: 0.7386 - val_auc: 0.7167 - val_loss: 3.0641\n",
      "Epoch 90/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.0163 - val_accuracy: 0.5511 - val_auc: 0.7365 - val_loss: 3.4946\n",
      "Epoch 91/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9922 - auc: 0.9902 - loss: 1.0555 - val_accuracy: 0.5568 - val_auc: 0.7082 - val_loss: 3.2533\n",
      "Epoch 92/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9985 - val_accuracy: 0.7386 - val_auc: 0.7800 - val_loss: 2.2296\n",
      "Epoch 93/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9895 - val_accuracy: 0.7557 - val_auc: 0.7684 - val_loss: 2.1752\n",
      "Epoch 94/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9806 - auc: 0.9997 - loss: 1.0232 - val_accuracy: 0.7216 - val_auc: 0.7837 - val_loss: 2.3053\n",
      "Epoch 95/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9692 - val_accuracy: 0.7500 - val_auc: 0.7885 - val_loss: 2.1634\n",
      "Epoch 96/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9569 - val_accuracy: 0.7500 - val_auc: 0.7941 - val_loss: 2.2217\n",
      "Epoch 97/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9448 - val_accuracy: 0.7557 - val_auc: 0.7946 - val_loss: 2.1567\n",
      "Epoch 98/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9340 - val_accuracy: 0.6193 - val_auc: 0.7525 - val_loss: 3.0802\n",
      "Epoch 99/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9209 - val_accuracy: 0.7330 - val_auc: 0.7827 - val_loss: 2.1467\n",
      "Epoch 100/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9058 - val_accuracy: 0.6534 - val_auc: 0.7528 - val_loss: 2.8631\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "  History saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04/fold_2/history_fold_2.csv\n",
      "    Fold 2 - Best Epoch 99: Val Loss=2.1467, Acc=0.7330, AUC=0.7827\n",
      "    Fold 2 finished in 1488.63 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 3/5 for LR=1.1e-05 and Reg=2e-04...\n",
      "  Train samples: 708, Validation samples: 181\n",
      "Calculating minmax across 708 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 708\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "  Fold train label counts: {0: 452, 1: 256}\n",
      "  Fold Class Weights: {0: 0.7831858407079646, 1: 1.3828125}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 101ms/step - accuracy: 0.5526 - auc: 0.6236 - loss: 3.8741 - val_accuracy: 0.3204 - val_auc: 0.8081 - val_loss: 4.9143\n",
      "Epoch 2/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.7811 - auc: 0.8863 - loss: 3.5828 - val_accuracy: 0.3204 - val_auc: 0.8782 - val_loss: 5.1683\n",
      "Epoch 3/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9088 - auc: 0.9533 - loss: 3.3906 - val_accuracy: 0.3370 - val_auc: 0.9157 - val_loss: 4.4387\n",
      "Epoch 4/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9539 - auc: 0.9904 - loss: 3.2346 - val_accuracy: 0.3370 - val_auc: 0.8978 - val_loss: 5.2906\n",
      "Epoch 5/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.9440 - auc: 0.9850 - loss: 3.2364 - val_accuracy: 0.7956 - val_auc: 0.9183 - val_loss: 3.6132\n",
      "Epoch 6/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9331 - auc: 0.9790 - loss: 3.2327 - val_accuracy: 0.8619 - val_auc: 0.9193 - val_loss: 3.4152\n",
      "Epoch 7/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9737 - auc: 0.9772 - loss: 3.1447 - val_accuracy: 0.7735 - val_auc: 0.9136 - val_loss: 3.6184\n",
      "Epoch 8/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9547 - auc: 0.9882 - loss: 3.1405 - val_accuracy: 0.6133 - val_auc: 0.9138 - val_loss: 3.9834\n",
      "Epoch 9/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9852 - auc: 0.9965 - loss: 3.0459 - val_accuracy: 0.8287 - val_auc: 0.9059 - val_loss: 3.4849\n",
      "Epoch 10/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9553 - auc: 0.9837 - loss: 3.1025 - val_accuracy: 0.8398 - val_auc: 0.8987 - val_loss: 3.4253\n",
      "Epoch 11/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9840 - auc: 0.9941 - loss: 3.0083 - val_accuracy: 0.8453 - val_auc: 0.9125 - val_loss: 3.4097\n",
      "Epoch 12/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9716 - auc: 0.9941 - loss: 2.9981 - val_accuracy: 0.7238 - val_auc: 0.9058 - val_loss: 3.7680\n",
      "Epoch 13/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9846 - auc: 0.9960 - loss: 2.9519 - val_accuracy: 0.6796 - val_auc: 0.5517 - val_loss: 7.9936\n",
      "Epoch 14/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - accuracy: 0.9469 - auc: 0.9929 - loss: 3.0097 - val_accuracy: 0.8287 - val_auc: 0.9104 - val_loss: 3.4110\n",
      "Epoch 15/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9738 - auc: 0.9921 - loss: 2.9352 - val_accuracy: 0.8398 - val_auc: 0.9066 - val_loss: 3.3183\n",
      "Epoch 16/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - accuracy: 0.9917 - auc: 0.9957 - loss: 2.8698 - val_accuracy: 0.8398 - val_auc: 0.9111 - val_loss: 3.1879\n",
      "Epoch 17/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.9785 - auc: 0.9857 - loss: 2.8661 - val_accuracy: 0.7901 - val_auc: 0.9036 - val_loss: 3.4771\n",
      "Epoch 18/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.9950 - auc: 1.0000 - loss: 2.7873 - val_accuracy: 0.8122 - val_auc: 0.9036 - val_loss: 3.3670\n",
      "Epoch 19/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9953 - auc: 0.9996 - loss: 2.7797 - val_accuracy: 0.7735 - val_auc: 0.8966 - val_loss: 3.3177\n",
      "Epoch 20/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9865 - auc: 0.9960 - loss: 2.7838 - val_accuracy: 0.8729 - val_auc: 0.9001 - val_loss: 3.2597\n",
      "Epoch 21/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9965 - auc: 0.9998 - loss: 2.7103 - val_accuracy: 0.8398 - val_auc: 0.9006 - val_loss: 3.2897\n",
      "Epoch 22/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9970 - auc: 0.9997 - loss: 2.6795 - val_accuracy: 0.7127 - val_auc: 0.8994 - val_loss: 3.5579\n",
      "Epoch 23/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.6281 - val_accuracy: 0.7735 - val_auc: 0.8890 - val_loss: 3.4069\n",
      "Epoch 24/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.5996 - val_accuracy: 0.7017 - val_auc: 0.8988 - val_loss: 3.6791\n",
      "Epoch 25/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.9960 - auc: 1.0000 - loss: 2.5790 - val_accuracy: 0.8398 - val_auc: 0.8948 - val_loss: 3.1204\n",
      "Epoch 26/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9985 - auc: 1.0000 - loss: 2.5371 - val_accuracy: 0.4420 - val_auc: 0.8930 - val_loss: 4.4982\n",
      "Epoch 27/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9958 - auc: 0.9985 - loss: 2.5273 - val_accuracy: 0.8011 - val_auc: 0.8799 - val_loss: 3.1597\n",
      "Epoch 28/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9977 - auc: 0.9955 - loss: 2.4950 - val_accuracy: 0.8564 - val_auc: 0.8961 - val_loss: 3.0084\n",
      "Epoch 29/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4336 - val_accuracy: 0.8453 - val_auc: 0.8984 - val_loss: 2.9765\n",
      "Epoch 30/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4036 - val_accuracy: 0.7680 - val_auc: 0.7639 - val_loss: 3.6963\n",
      "Epoch 31/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9970 - auc: 0.9943 - loss: 2.3807 - val_accuracy: 0.8122 - val_auc: 0.8918 - val_loss: 2.9719\n",
      "Epoch 32/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3315 - val_accuracy: 0.7790 - val_auc: 0.8898 - val_loss: 3.1305\n",
      "Epoch 33/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.2989 - val_accuracy: 0.8177 - val_auc: 0.8898 - val_loss: 3.0371\n",
      "Epoch 34/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9619 - auc: 0.9746 - loss: 2.4427 - val_accuracy: 0.8177 - val_auc: 0.8662 - val_loss: 3.0715\n",
      "Epoch 35/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9994 - auc: 1.0000 - loss: 2.2333 - val_accuracy: 0.8066 - val_auc: 0.8838 - val_loss: 2.8760\n",
      "Epoch 36/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9888 - loss: 2.2095 - val_accuracy: 0.8122 - val_auc: 0.8897 - val_loss: 2.8452\n",
      "Epoch 37/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.1758 - val_accuracy: 0.8122 - val_auc: 0.8744 - val_loss: 2.8921\n",
      "Epoch 38/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 2.1415 - val_accuracy: 0.8122 - val_auc: 0.8759 - val_loss: 2.8282\n",
      "Epoch 39/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9983 - auc: 0.9944 - loss: 2.1217 - val_accuracy: 0.4751 - val_auc: 0.8802 - val_loss: 3.5179\n",
      "Epoch 40/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0766 - val_accuracy: 0.8564 - val_auc: 0.8930 - val_loss: 2.6299\n",
      "Epoch 41/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0451 - val_accuracy: 0.8287 - val_auc: 0.8974 - val_loss: 2.6032\n",
      "Epoch 42/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0103 - val_accuracy: 0.7680 - val_auc: 0.8488 - val_loss: 2.8079\n",
      "Epoch 43/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9801 - val_accuracy: 0.8287 - val_auc: 0.8859 - val_loss: 2.6318\n",
      "Epoch 44/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9436 - val_accuracy: 0.7901 - val_auc: 0.8408 - val_loss: 2.8746\n",
      "Epoch 45/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.9112 - val_accuracy: 0.8287 - val_auc: 0.8917 - val_loss: 2.4625\n",
      "Epoch 46/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8792 - val_accuracy: 0.8287 - val_auc: 0.8871 - val_loss: 2.5325\n",
      "Epoch 47/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.8423 - val_accuracy: 0.8122 - val_auc: 0.8830 - val_loss: 2.6047\n",
      "Epoch 48/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8058 - val_accuracy: 0.8177 - val_auc: 0.8872 - val_loss: 2.4481\n",
      "Epoch 49/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7679 - val_accuracy: 0.7956 - val_auc: 0.8811 - val_loss: 2.4786\n",
      "Epoch 50/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7299 - val_accuracy: 0.8122 - val_auc: 0.8923 - val_loss: 2.5085\n",
      "Epoch 51/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6899 - val_accuracy: 0.8011 - val_auc: 0.8886 - val_loss: 2.2960\n",
      "Epoch 52/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6483 - val_accuracy: 0.8232 - val_auc: 0.8879 - val_loss: 2.3684\n",
      "Epoch 53/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6067 - val_accuracy: 0.8177 - val_auc: 0.8730 - val_loss: 2.2270\n",
      "Epoch 54/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9741 - auc: 0.9982 - loss: 1.6210 - val_accuracy: 0.7901 - val_auc: 0.8605 - val_loss: 2.5335\n",
      "Epoch 55/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9557 - auc: 0.9882 - loss: 1.6715 - val_accuracy: 0.8508 - val_auc: 0.8918 - val_loss: 2.1896\n",
      "Epoch 56/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9855 - auc: 0.9992 - loss: 1.5584 - val_accuracy: 0.8287 - val_auc: 0.8754 - val_loss: 2.1944\n",
      "Epoch 57/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.5196 - val_accuracy: 0.8232 - val_auc: 0.8738 - val_loss: 2.2106\n",
      "Epoch 58/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9914 - auc: 0.9998 - loss: 1.5288 - val_accuracy: 0.8453 - val_auc: 0.8748 - val_loss: 2.2179\n",
      "Epoch 59/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4867 - val_accuracy: 0.8177 - val_auc: 0.8758 - val_loss: 2.2398\n",
      "Epoch 60/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9986 - auc: 1.0000 - loss: 1.4737 - val_accuracy: 0.8287 - val_auc: 0.8785 - val_loss: 2.1578\n",
      "Epoch 61/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4540 - val_accuracy: 0.8343 - val_auc: 0.8860 - val_loss: 2.1443\n",
      "Epoch 62/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9997 - auc: 0.9775 - loss: 1.4388 - val_accuracy: 0.5580 - val_auc: 0.8757 - val_loss: 3.2304\n",
      "Epoch 63/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9993 - auc: 1.0000 - loss: 1.4293 - val_accuracy: 0.7956 - val_auc: 0.8673 - val_loss: 2.3206\n",
      "Epoch 64/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4069 - val_accuracy: 0.8177 - val_auc: 0.8753 - val_loss: 2.1330\n",
      "Epoch 65/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3842 - val_accuracy: 0.8287 - val_auc: 0.8696 - val_loss: 2.1460\n",
      "Epoch 66/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3654 - val_accuracy: 0.7790 - val_auc: 0.8338 - val_loss: 2.4218\n",
      "Epoch 67/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9786 - auc: 0.9930 - loss: 1.4094 - val_accuracy: 0.7514 - val_auc: 0.7486 - val_loss: 3.3569\n",
      "Epoch 68/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9983 - auc: 0.9970 - loss: 1.3485 - val_accuracy: 0.8453 - val_auc: 0.8825 - val_loss: 1.9771\n",
      "Epoch 69/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3147 - val_accuracy: 0.8232 - val_auc: 0.8830 - val_loss: 2.1344\n",
      "Epoch 70/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.3002 - val_accuracy: 0.8343 - val_auc: 0.8788 - val_loss: 2.1151\n",
      "Epoch 71/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2817 - val_accuracy: 0.5635 - val_auc: 0.8380 - val_loss: 3.3644\n",
      "Epoch 72/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2643 - val_accuracy: 0.8177 - val_auc: 0.8780 - val_loss: 1.9768\n",
      "Epoch 73/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2445 - val_accuracy: 0.8398 - val_auc: 0.8770 - val_loss: 2.0408\n",
      "Epoch 74/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2240 - val_accuracy: 0.8287 - val_auc: 0.8802 - val_loss: 2.0194\n",
      "Epoch 75/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2022 - val_accuracy: 0.8122 - val_auc: 0.8564 - val_loss: 2.1505\n",
      "Epoch 76/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.1806 - val_accuracy: 0.8287 - val_auc: 0.8841 - val_loss: 1.9063\n",
      "Epoch 77/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9957 - auc: 0.9984 - loss: 1.1782 - val_accuracy: 0.8122 - val_auc: 0.8991 - val_loss: 1.7007\n",
      "Epoch 78/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9858 - auc: 0.9992 - loss: 1.1762 - val_accuracy: 0.6243 - val_auc: 0.8909 - val_loss: 2.8625\n",
      "Epoch 79/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9770 - auc: 0.9906 - loss: 1.1932 - val_accuracy: 0.8343 - val_auc: 0.8792 - val_loss: 1.7648\n",
      "Epoch 80/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9973 - auc: 0.9999 - loss: 1.1353 - val_accuracy: 0.8232 - val_auc: 0.8836 - val_loss: 1.9228\n",
      "Epoch 81/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9961 - auc: 0.9999 - loss: 1.1221 - val_accuracy: 0.8398 - val_auc: 0.8826 - val_loss: 1.8676\n",
      "Epoch 82/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0996 - val_accuracy: 0.8398 - val_auc: 0.8795 - val_loss: 1.8566\n",
      "Epoch 83/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0887 - val_accuracy: 0.8508 - val_auc: 0.8797 - val_loss: 1.8421\n",
      "Epoch 84/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0816 - val_accuracy: 0.8453 - val_auc: 0.8904 - val_loss: 1.7769\n",
      "Epoch 85/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0656 - val_accuracy: 0.8453 - val_auc: 0.8917 - val_loss: 1.7705\n",
      "Epoch 86/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0529 - val_accuracy: 0.8343 - val_auc: 0.8827 - val_loss: 1.8166\n",
      "Epoch 87/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0404 - val_accuracy: 0.8398 - val_auc: 0.8845 - val_loss: 1.7953\n",
      "Epoch 88/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0264 - val_accuracy: 0.8343 - val_auc: 0.8797 - val_loss: 1.7719\n",
      "Epoch 89/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0100 - val_accuracy: 0.8122 - val_auc: 0.8809 - val_loss: 1.7442\n",
      "Epoch 90/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.9944 - val_accuracy: 0.8287 - val_auc: 0.8851 - val_loss: 1.7945\n",
      "Epoch 91/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9772 - val_accuracy: 0.7845 - val_auc: 0.8830 - val_loss: 1.6625\n",
      "Epoch 92/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9729 - auc: 0.9954 - loss: 1.0393 - val_accuracy: 0.7182 - val_auc: 0.7278 - val_loss: 2.5095\n",
      "Epoch 93/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9657 - auc: 0.9909 - loss: 1.0519 - val_accuracy: 0.7127 - val_auc: 0.9010 - val_loss: 2.0019\n",
      "Epoch 94/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9997 - auc: 1.0000 - loss: 0.9568 - val_accuracy: 0.7403 - val_auc: 0.7350 - val_loss: 2.5943\n",
      "Epoch 95/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 101ms/step - accuracy: 0.9725 - auc: 0.9897 - loss: 1.0467 - val_accuracy: 0.8177 - val_auc: 0.8853 - val_loss: 1.6484\n",
      "Epoch 96/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 1.0000 - auc: 0.9888 - loss: 0.9406 - val_accuracy: 0.4751 - val_auc: 0.8490 - val_loss: 3.1211\n",
      "Epoch 97/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 100ms/step - accuracy: 0.9999 - auc: 1.0000 - loss: 0.9309 - val_accuracy: 0.8232 - val_auc: 0.8831 - val_loss: 1.6278\n",
      "Epoch 98/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9993 - auc: 1.0000 - loss: 0.9261 - val_accuracy: 0.7624 - val_auc: 0.6927 - val_loss: 2.7853\n",
      "Epoch 99/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9141 - val_accuracy: 0.8232 - val_auc: 0.8664 - val_loss: 1.7391\n",
      "Epoch 100/100\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9947 - auc: 0.9973 - loss: 0.9408 - val_accuracy: 0.8398 - val_auc: 0.8874 - val_loss: 1.7655\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "  History saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04/fold_3/history_fold_3.csv\n",
      "    Fold 3 - Best Epoch 97: Val Loss=1.6278, Acc=0.8232, AUC=0.8831\n",
      "    Fold 3 finished in 1479.18 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 4/5 for LR=1.1e-05 and Reg=2e-04...\n",
      "  Train samples: 713, Validation samples: 176\n",
      "Calculating minmax across 713 files...\n",
      "Calculated Min: -0.3496308922767639, Max: 2.7912356853485107\n",
      "Shuffling with buffer size: 713\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "  Fold train label counts: {0: 454, 1: 259}\n",
      "  Fold Class Weights: {0: 0.7852422907488987, 1: 1.3764478764478765}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 173ms/step - accuracy: 0.5578 - auc: 0.6084 - loss: 3.8651 - val_accuracy: 0.3125 - val_auc: 0.6953 - val_loss: 5.1095\n",
      "Epoch 2/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 95ms/step - accuracy: 0.8077 - auc: 0.8879 - loss: 3.5813 - val_accuracy: 0.3125 - val_auc: 0.5372 - val_loss: 6.3834\n",
      "Epoch 3/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.8800 - auc: 0.9650 - loss: 3.3849 - val_accuracy: 0.3295 - val_auc: 0.8950 - val_loss: 4.4237\n",
      "Epoch 4/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9127 - auc: 0.9490 - loss: 3.3441 - val_accuracy: 0.3182 - val_auc: 0.8207 - val_loss: 5.8781\n",
      "Epoch 5/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 95ms/step - accuracy: 0.9091 - auc: 0.9645 - loss: 3.2947 - val_accuracy: 0.5341 - val_auc: 0.7833 - val_loss: 4.1278\n",
      "Epoch 6/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 0.9310 - auc: 0.9675 - loss: 3.2503 - val_accuracy: 0.7727 - val_auc: 0.8563 - val_loss: 3.6704\n",
      "Epoch 7/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.9510 - auc: 0.9857 - loss: 3.1527 - val_accuracy: 0.8295 - val_auc: 0.8863 - val_loss: 3.4284\n",
      "Epoch 8/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9653 - auc: 0.9785 - loss: 3.1482 - val_accuracy: 0.7443 - val_auc: 0.9011 - val_loss: 3.5339\n",
      "Epoch 9/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9823 - auc: 0.9966 - loss: 3.0285 - val_accuracy: 0.7955 - val_auc: 0.8839 - val_loss: 3.3651\n",
      "Epoch 10/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9575 - auc: 0.9874 - loss: 3.0664 - val_accuracy: 0.7273 - val_auc: 0.8039 - val_loss: 3.9374\n",
      "Epoch 11/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9872 - auc: 0.9908 - loss: 2.9769 - val_accuracy: 0.7784 - val_auc: 0.8433 - val_loss: 3.3834\n",
      "Epoch 12/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9798 - auc: 0.9952 - loss: 2.9673 - val_accuracy: 0.7216 - val_auc: 0.7515 - val_loss: 4.3785\n",
      "Epoch 13/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9680 - auc: 0.9738 - loss: 3.0376 - val_accuracy: 0.6989 - val_auc: 0.7588 - val_loss: 4.6572\n",
      "Epoch 14/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9833 - auc: 0.9938 - loss: 2.9238 - val_accuracy: 0.6591 - val_auc: 0.8773 - val_loss: 3.5964\n",
      "Epoch 15/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9927 - auc: 0.9829 - loss: 2.8561 - val_accuracy: 0.4091 - val_auc: 0.8704 - val_loss: 4.7279\n",
      "Epoch 16/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9890 - auc: 0.9963 - loss: 2.8518 - val_accuracy: 0.6989 - val_auc: 0.6051 - val_loss: 5.5608\n",
      "Epoch 17/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9909 - auc: 0.9901 - loss: 2.8235 - val_accuracy: 0.7102 - val_auc: 0.8745 - val_loss: 3.5794\n",
      "Epoch 18/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9949 - auc: 0.9999 - loss: 2.7648 - val_accuracy: 0.8125 - val_auc: 0.8691 - val_loss: 3.1989\n",
      "Epoch 19/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9913 - auc: 0.9998 - loss: 2.7610 - val_accuracy: 0.5625 - val_auc: 0.9047 - val_loss: 3.9288\n",
      "Epoch 20/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9993 - auc: 1.0000 - loss: 2.7109 - val_accuracy: 0.8352 - val_auc: 0.8634 - val_loss: 3.2273\n",
      "Epoch 21/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9990 - auc: 1.0000 - loss: 2.6776 - val_accuracy: 0.8239 - val_auc: 0.8632 - val_loss: 3.3196\n",
      "Epoch 22/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9996 - auc: 1.0000 - loss: 2.6378 - val_accuracy: 0.7727 - val_auc: 0.8382 - val_loss: 3.3974\n",
      "Epoch 23/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.6063 - val_accuracy: 0.5114 - val_auc: 0.8649 - val_loss: 4.1338\n",
      "Epoch 24/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 2.5794 - val_accuracy: 0.8011 - val_auc: 0.8838 - val_loss: 3.1387\n",
      "Epoch 25/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.9965 - auc: 0.9944 - loss: 2.5578 - val_accuracy: 0.7841 - val_auc: 0.8630 - val_loss: 3.0973\n",
      "Epoch 26/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.5084 - val_accuracy: 0.7784 - val_auc: 0.8936 - val_loss: 3.2117\n",
      "Epoch 27/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4708 - val_accuracy: 0.8295 - val_auc: 0.8674 - val_loss: 3.0583\n",
      "Epoch 28/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4307 - val_accuracy: 0.6648 - val_auc: 0.8668 - val_loss: 3.6061\n",
      "Epoch 29/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9968 - auc: 0.9978 - loss: 2.4161 - val_accuracy: 0.3523 - val_auc: 0.8445 - val_loss: 4.8973\n",
      "Epoch 30/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9848 - auc: 0.9983 - loss: 2.4080 - val_accuracy: 0.6989 - val_auc: 0.6817 - val_loss: 4.8831\n",
      "Epoch 31/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9907 - auc: 0.9973 - loss: 2.3676 - val_accuracy: 0.6307 - val_auc: 0.8663 - val_loss: 3.2832\n",
      "Epoch 32/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3040 - val_accuracy: 0.4602 - val_auc: 0.8820 - val_loss: 4.0191\n",
      "Epoch 33/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9955 - auc: 0.9950 - loss: 2.3130 - val_accuracy: 0.5682 - val_auc: 0.8833 - val_loss: 3.4977\n",
      "Epoch 34/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2450 - val_accuracy: 0.6932 - val_auc: 0.8843 - val_loss: 3.1201\n",
      "Epoch 35/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2123 - val_accuracy: 0.8409 - val_auc: 0.8754 - val_loss: 2.7398\n",
      "Epoch 36/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.1803 - val_accuracy: 0.8352 - val_auc: 0.8488 - val_loss: 2.8262\n",
      "Epoch 37/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.1484 - val_accuracy: 0.8182 - val_auc: 0.8662 - val_loss: 2.7017\n",
      "Epoch 38/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9962 - auc: 1.0000 - loss: 2.1210 - val_accuracy: 0.8239 - val_auc: 0.8779 - val_loss: 2.5719\n",
      "Epoch 39/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0745 - val_accuracy: 0.8125 - val_auc: 0.8696 - val_loss: 2.6725\n",
      "Epoch 40/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9927 - auc: 0.9998 - loss: 2.0575 - val_accuracy: 0.7841 - val_auc: 0.8856 - val_loss: 2.6992\n",
      "Epoch 41/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0088 - val_accuracy: 0.8239 - val_auc: 0.8930 - val_loss: 2.5012\n",
      "Epoch 42/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9981 - auc: 0.9944 - loss: 1.9786 - val_accuracy: 0.6989 - val_auc: 0.8461 - val_loss: 2.7151\n",
      "Epoch 43/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9951 - auc: 0.9994 - loss: 1.9656 - val_accuracy: 0.7841 - val_auc: 0.8445 - val_loss: 2.4597\n",
      "Epoch 44/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9886 - auc: 0.9769 - loss: 1.9766 - val_accuracy: 0.7955 - val_auc: 0.8660 - val_loss: 2.5454\n",
      "Epoch 45/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9744 - auc: 0.9957 - loss: 1.9567 - val_accuracy: 0.8352 - val_auc: 0.9061 - val_loss: 2.2858\n",
      "Epoch 46/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9895 - auc: 0.9995 - loss: 1.8960 - val_accuracy: 0.8352 - val_auc: 0.8806 - val_loss: 2.3527\n",
      "Epoch 47/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9977 - auc: 1.0000 - loss: 1.8556 - val_accuracy: 0.7898 - val_auc: 0.8725 - val_loss: 2.5461\n",
      "Epoch 48/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8267 - val_accuracy: 0.8239 - val_auc: 0.8925 - val_loss: 2.3614\n",
      "Epoch 49/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 87ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.8045 - val_accuracy: 0.8239 - val_auc: 0.8958 - val_loss: 2.3594\n",
      "Epoch 50/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7816 - val_accuracy: 0.6818 - val_auc: 0.8872 - val_loss: 2.8926\n",
      "Epoch 51/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7566 - val_accuracy: 0.7784 - val_auc: 0.8807 - val_loss: 2.5262\n",
      "Epoch 52/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7342 - val_accuracy: 0.8182 - val_auc: 0.8824 - val_loss: 2.3238\n",
      "Epoch 53/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7049 - val_accuracy: 0.5795 - val_auc: 0.8997 - val_loss: 2.9090\n",
      "Epoch 54/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6784 - val_accuracy: 0.4261 - val_auc: 0.7878 - val_loss: 4.8567\n",
      "Epoch 55/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9919 - auc: 0.9992 - loss: 1.6768 - val_accuracy: 0.7841 - val_auc: 0.8748 - val_loss: 2.3441\n",
      "Epoch 56/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.9986 - auc: 0.9993 - loss: 1.6349 - val_accuracy: 0.8295 - val_auc: 0.8887 - val_loss: 2.1366\n",
      "Epoch 57/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 82ms/step - accuracy: 0.9909 - auc: 0.9994 - loss: 1.6396 - val_accuracy: 0.8011 - val_auc: 0.8512 - val_loss: 2.2277\n",
      "Epoch 58/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5835 - val_accuracy: 0.8125 - val_auc: 0.8949 - val_loss: 2.1913\n",
      "Epoch 59/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9985 - auc: 1.0000 - loss: 1.5669 - val_accuracy: 0.7784 - val_auc: 0.8551 - val_loss: 2.1436\n",
      "Epoch 60/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5411 - val_accuracy: 0.8182 - val_auc: 0.9033 - val_loss: 2.0802\n",
      "Epoch 61/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5180 - val_accuracy: 0.8466 - val_auc: 0.8881 - val_loss: 2.0595\n",
      "Epoch 62/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4944 - val_accuracy: 0.8182 - val_auc: 0.8687 - val_loss: 2.1459\n",
      "Epoch 63/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4701 - val_accuracy: 0.8182 - val_auc: 0.8872 - val_loss: 2.0366\n",
      "Epoch 64/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9953 - auc: 0.9998 - loss: 1.4600 - val_accuracy: 0.3807 - val_auc: 0.7333 - val_loss: 4.9179\n",
      "Epoch 65/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9918 - auc: 0.9976 - loss: 1.4550 - val_accuracy: 0.7670 - val_auc: 0.8697 - val_loss: 2.1718\n",
      "Epoch 66/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9944 - auc: 0.9964 - loss: 1.4437 - val_accuracy: 0.8182 - val_auc: 0.8736 - val_loss: 1.9211\n",
      "Epoch 67/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3941 - val_accuracy: 0.8125 - val_auc: 0.8645 - val_loss: 1.9601\n",
      "Epoch 68/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.3749 - val_accuracy: 0.8125 - val_auc: 0.8470 - val_loss: 2.0108\n",
      "Epoch 69/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3570 - val_accuracy: 0.8239 - val_auc: 0.8515 - val_loss: 1.9682\n",
      "Epoch 70/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3390 - val_accuracy: 0.8295 - val_auc: 0.8563 - val_loss: 1.9691\n",
      "Epoch 71/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9990 - auc: 0.9944 - loss: 1.3288 - val_accuracy: 0.7955 - val_auc: 0.8716 - val_loss: 1.9751\n",
      "Epoch 72/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9967 - auc: 0.9999 - loss: 1.3164 - val_accuracy: 0.8239 - val_auc: 0.8776 - val_loss: 1.8837\n",
      "Epoch 73/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9952 - auc: 0.9924 - loss: 1.3080 - val_accuracy: 0.8750 - val_auc: 0.9205 - val_loss: 1.6695\n",
      "Epoch 74/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9903 - auc: 1.0000 - loss: 1.2870 - val_accuracy: 0.8295 - val_auc: 0.8856 - val_loss: 1.8473\n",
      "Epoch 75/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2606 - val_accuracy: 0.8295 - val_auc: 0.8935 - val_loss: 1.8398\n",
      "Epoch 76/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 1.2456 - val_accuracy: 0.8239 - val_auc: 0.8883 - val_loss: 1.8451\n",
      "Epoch 77/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.2289 - val_accuracy: 0.8409 - val_auc: 0.8812 - val_loss: 1.7894\n",
      "Epoch 78/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2117 - val_accuracy: 0.8409 - val_auc: 0.8612 - val_loss: 1.8421\n",
      "Epoch 79/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1931 - val_accuracy: 0.8011 - val_auc: 0.8644 - val_loss: 1.8800\n",
      "Epoch 80/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1732 - val_accuracy: 0.8295 - val_auc: 0.8606 - val_loss: 1.8250\n",
      "Epoch 81/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1537 - val_accuracy: 0.8295 - val_auc: 0.8587 - val_loss: 1.7891\n",
      "Epoch 82/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1310 - val_accuracy: 0.8125 - val_auc: 0.8597 - val_loss: 1.8949\n",
      "Epoch 83/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1088 - val_accuracy: 0.8466 - val_auc: 0.8754 - val_loss: 1.7027\n",
      "Epoch 84/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0849 - val_accuracy: 0.8352 - val_auc: 0.8696 - val_loss: 1.7154\n",
      "Epoch 85/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9889 - loss: 1.0612 - val_accuracy: 0.8352 - val_auc: 0.8808 - val_loss: 1.6396\n",
      "Epoch 86/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9773 - auc: 0.9953 - loss: 1.1021 - val_accuracy: 0.7045 - val_auc: 0.7394 - val_loss: 2.8925\n",
      "Epoch 87/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9910 - auc: 0.9939 - loss: 1.0658 - val_accuracy: 0.7330 - val_auc: 0.7798 - val_loss: 2.2061\n",
      "Epoch 88/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9805 - auc: 0.9965 - loss: 1.0832 - val_accuracy: 0.7557 - val_auc: 0.7639 - val_loss: 2.4939\n",
      "Epoch 89/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9936 - auc: 0.9999 - loss: 1.0299 - val_accuracy: 0.7955 - val_auc: 0.8200 - val_loss: 1.7179\n",
      "Epoch 90/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.0017 - val_accuracy: 0.8011 - val_auc: 0.8568 - val_loss: 1.7157\n",
      "Epoch 91/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 0.9959 - val_accuracy: 0.7045 - val_auc: 0.8379 - val_loss: 2.1788\n",
      "Epoch 92/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9887 - val_accuracy: 0.8580 - val_auc: 0.8740 - val_loss: 1.7047\n",
      "Epoch 93/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9999 - auc: 1.0000 - loss: 0.9786 - val_accuracy: 0.3864 - val_auc: 0.7972 - val_loss: 3.8724\n",
      "Epoch 94/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9969 - auc: 1.0000 - loss: 0.9772 - val_accuracy: 0.8239 - val_auc: 0.8607 - val_loss: 1.6092\n",
      "Epoch 95/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9596 - val_accuracy: 0.8182 - val_auc: 0.8630 - val_loss: 1.6463\n",
      "Epoch 96/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9490 - val_accuracy: 0.8409 - val_auc: 0.8758 - val_loss: 1.5893\n",
      "Epoch 97/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9383 - val_accuracy: 0.7273 - val_auc: 0.8646 - val_loss: 2.1491\n",
      "Epoch 98/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9292 - val_accuracy: 0.7670 - val_auc: 0.8753 - val_loss: 1.9273\n",
      "Epoch 99/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 95ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9171 - val_accuracy: 0.8409 - val_auc: 0.8663 - val_loss: 1.5638\n",
      "Epoch 100/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 88ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9039 - val_accuracy: 0.8011 - val_auc: 0.9087 - val_loss: 1.7077\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "  History saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04/fold_4/history_fold_4.csv\n",
      "    Fold 4 - Best Epoch 99: Val Loss=1.5638, Acc=0.8409, AUC=0.8663\n",
      "    Fold 4 finished in 1509.80 seconds.\n",
      "------------------------------------------------------------\n",
      "Training Fold 5/5 for LR=1.1e-05 and Reg=2e-04...\n",
      "  Train samples: 716, Validation samples: 173\n",
      "Calculating minmax across 716 files...\n",
      "Calculated Min: -0.35769128799438477, Max: 2.544045925140381\n",
      "Shuffling with buffer size: 716\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "\n",
      "Applying mask from /home/diogommiranda/tese/masks/ROI_MASK.nii\n",
      "\n",
      "  Fold train label counts: {0: 486, 1: 230}\n",
      "  Fold Class Weights: {0: 0.7366255144032922, 1: 1.5565217391304347}\n",
      "here CHANNELS last\n",
      "Epoch 1/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 104ms/step - accuracy: 0.5889 - auc: 0.6519 - loss: 3.8691 - val_accuracy: 0.4855 - val_auc: 0.8304 - val_loss: 4.1318\n",
      "Epoch 2/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 93ms/step - accuracy: 0.8191 - auc: 0.8884 - loss: 3.5766 - val_accuracy: 0.4855 - val_auc: 0.8880 - val_loss: 4.3829\n",
      "Epoch 3/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.8701 - auc: 0.9290 - loss: 3.4694 - val_accuracy: 0.6301 - val_auc: 0.8882 - val_loss: 3.8198\n",
      "Epoch 4/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 94ms/step - accuracy: 0.9240 - auc: 0.9792 - loss: 3.2838 - val_accuracy: 0.7803 - val_auc: 0.9124 - val_loss: 3.5611\n",
      "Epoch 5/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9381 - auc: 0.9769 - loss: 3.2612 - val_accuracy: 0.5434 - val_auc: 0.8715 - val_loss: 4.5411\n",
      "Epoch 6/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9852 - auc: 0.9935 - loss: 3.1402 - val_accuracy: 0.8208 - val_auc: 0.8873 - val_loss: 3.5346\n",
      "Epoch 7/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9688 - auc: 0.9914 - loss: 3.1298 - val_accuracy: 0.7399 - val_auc: 0.8921 - val_loss: 3.5703\n",
      "Epoch 8/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9653 - auc: 0.9884 - loss: 3.1096 - val_accuracy: 0.8555 - val_auc: 0.8991 - val_loss: 3.4452\n",
      "Epoch 9/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9786 - auc: 0.9910 - loss: 3.0681 - val_accuracy: 0.6185 - val_auc: 0.8628 - val_loss: 4.1174\n",
      "Epoch 10/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9864 - auc: 0.9966 - loss: 2.9987 - val_accuracy: 0.8035 - val_auc: 0.8815 - val_loss: 3.4174\n",
      "Epoch 11/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9876 - auc: 0.9801 - loss: 2.9731 - val_accuracy: 0.8497 - val_auc: 0.8875 - val_loss: 3.3987\n",
      "Epoch 12/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9837 - auc: 0.9912 - loss: 2.9749 - val_accuracy: 0.7225 - val_auc: 0.8666 - val_loss: 3.5306\n",
      "Epoch 13/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9859 - auc: 0.9994 - loss: 2.8956 - val_accuracy: 0.7688 - val_auc: 0.8542 - val_loss: 3.4825\n",
      "Epoch 14/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9939 - auc: 1.0000 - loss: 2.8570 - val_accuracy: 0.6358 - val_auc: 0.8493 - val_loss: 4.3571\n",
      "Epoch 15/100\n",
      "\u001b[1m  1/179\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 165ms/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 2.8447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 09:32:08.341764: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 19111968 bytes after encountering the first element of size 19111968 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9889 - auc: 0.9861 - loss: 2.8848 - val_accuracy: 0.6936 - val_auc: 0.8668 - val_loss: 3.5967\n",
      "Epoch 16/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9623 - auc: 0.9845 - loss: 2.9331 - val_accuracy: 0.5549 - val_auc: 0.8668 - val_loss: 4.2312\n",
      "Epoch 17/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9886 - auc: 0.9946 - loss: 2.8110 - val_accuracy: 0.6358 - val_auc: 0.8723 - val_loss: 4.0911\n",
      "Epoch 18/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9862 - auc: 0.9958 - loss: 2.7850 - val_accuracy: 0.6879 - val_auc: 0.8773 - val_loss: 3.6407\n",
      "Epoch 19/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.7023 - val_accuracy: 0.6012 - val_auc: 0.8666 - val_loss: 3.9238\n",
      "Epoch 20/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9959 - auc: 0.9985 - loss: 2.6847 - val_accuracy: 0.5954 - val_auc: 0.7877 - val_loss: 4.6756\n",
      "Epoch 21/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9889 - auc: 0.9926 - loss: 2.6921 - val_accuracy: 0.8035 - val_auc: 0.8908 - val_loss: 3.1451\n",
      "Epoch 22/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9929 - auc: 0.9994 - loss: 2.6287 - val_accuracy: 0.7977 - val_auc: 0.8896 - val_loss: 3.1461\n",
      "Epoch 23/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9992 - auc: 1.0000 - loss: 2.5724 - val_accuracy: 0.5434 - val_auc: 0.6475 - val_loss: 5.9176\n",
      "Epoch 24/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9927 - auc: 0.9995 - loss: 2.5640 - val_accuracy: 0.7052 - val_auc: 0.8940 - val_loss: 3.3775\n",
      "Epoch 25/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9906 - auc: 0.9902 - loss: 2.5494 - val_accuracy: 0.7803 - val_auc: 0.8711 - val_loss: 3.0461\n",
      "Epoch 26/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4741 - val_accuracy: 0.6647 - val_auc: 0.8518 - val_loss: 3.7986\n",
      "Epoch 27/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9989 - auc: 1.0000 - loss: 2.4443 - val_accuracy: 0.5145 - val_auc: 0.5238 - val_loss: 11.0280\n",
      "Epoch 28/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9977 - auc: 0.9986 - loss: 2.4244 - val_accuracy: 0.7630 - val_auc: 0.8939 - val_loss: 2.9867\n",
      "Epoch 29/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9983 - auc: 1.0000 - loss: 2.3781 - val_accuracy: 0.7630 - val_auc: 0.8979 - val_loss: 2.9700\n",
      "Epoch 30/100\n",
      "\u001b[1m  1/179\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 165ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3460"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 09:35:38.353874: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 14442528 bytes after encountering the first element of size 14442528 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9992 - auc: 1.0000 - loss: 2.3401 - val_accuracy: 0.6936 - val_auc: 0.8842 - val_loss: 3.3238\n",
      "Epoch 31/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3034 - val_accuracy: 0.8092 - val_auc: 0.8921 - val_loss: 2.7837\n",
      "Epoch 32/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9987 - auc: 1.0000 - loss: 2.2774 - val_accuracy: 0.6821 - val_auc: 0.8488 - val_loss: 3.4684\n",
      "Epoch 33/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2353 - val_accuracy: 0.5723 - val_auc: 0.8539 - val_loss: 3.8568\n",
      "Epoch 34/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9992 - auc: 0.9944 - loss: 2.2083 - val_accuracy: 0.7630 - val_auc: 0.8825 - val_loss: 2.8476\n",
      "Epoch 35/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 2.1651 - val_accuracy: 0.7803 - val_auc: 0.8908 - val_loss: 2.8375\n",
      "Epoch 36/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9895 - auc: 0.9929 - loss: 2.1657 - val_accuracy: 0.7746 - val_auc: 0.8743 - val_loss: 2.6285\n",
      "Epoch 37/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9958 - auc: 1.0000 - loss: 2.1096 - val_accuracy: 0.6012 - val_auc: 0.8632 - val_loss: 3.6103\n",
      "Epoch 38/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.9968 - auc: 0.9999 - loss: 2.0842 - val_accuracy: 0.8208 - val_auc: 0.8783 - val_loss: 2.5530\n",
      "Epoch 39/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9988 - auc: 1.0000 - loss: 2.0406 - val_accuracy: 0.5202 - val_auc: 0.6429 - val_loss: 5.8400\n",
      "Epoch 40/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9992 - auc: 1.0000 - loss: 2.0116 - val_accuracy: 0.8266 - val_auc: 0.9018 - val_loss: 2.4712\n",
      "Epoch 41/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9992 - auc: 0.9944 - loss: 1.9819 - val_accuracy: 0.8613 - val_auc: 0.9064 - val_loss: 2.4321\n",
      "Epoch 42/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9478 - val_accuracy: 0.5318 - val_auc: 0.7766 - val_loss: 4.1473\n",
      "Epoch 43/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9916 - auc: 0.9943 - loss: 1.9394 - val_accuracy: 0.7457 - val_auc: 0.8766 - val_loss: 2.6539\n",
      "Epoch 44/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8883 - val_accuracy: 0.7861 - val_auc: 0.9014 - val_loss: 2.4823\n",
      "Epoch 45/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9833 - loss: 1.8569 - val_accuracy: 0.8266 - val_auc: 0.8998 - val_loss: 2.3584\n",
      "Epoch 46/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8243 - val_accuracy: 0.8266 - val_auc: 0.8988 - val_loss: 2.3703\n",
      "Epoch 47/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7918 - val_accuracy: 0.6763 - val_auc: 0.8768 - val_loss: 3.0347\n",
      "Epoch 48/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7554 - val_accuracy: 0.8150 - val_auc: 0.8987 - val_loss: 2.3591\n",
      "Epoch 49/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9993 - auc: 0.9984 - loss: 1.7294 - val_accuracy: 0.6416 - val_auc: 0.8653 - val_loss: 2.6379\n",
      "Epoch 50/100\n",
      "\u001b[1m  2/179\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 130ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 09:40:16.913520: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 16777248 bytes after encountering the first element of size 16777248 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6867 - val_accuracy: 0.7514 - val_auc: 0.8953 - val_loss: 2.3479\n",
      "Epoch 51/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6510 - val_accuracy: 0.7168 - val_auc: 0.8684 - val_loss: 2.4610\n",
      "Epoch 52/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.6162 - val_accuracy: 0.6532 - val_auc: 0.8236 - val_loss: 3.2144\n",
      "Epoch 53/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9723 - auc: 0.9944 - loss: 1.6637 - val_accuracy: 0.7052 - val_auc: 0.9139 - val_loss: 2.4785\n",
      "Epoch 54/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9897 - auc: 0.9930 - loss: 1.6069 - val_accuracy: 0.5896 - val_auc: 0.8456 - val_loss: 3.0970\n",
      "Epoch 55/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5619 - val_accuracy: 0.8324 - val_auc: 0.8967 - val_loss: 2.0683\n",
      "Epoch 56/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.9995 - auc: 0.9999 - loss: 1.5393 - val_accuracy: 0.7225 - val_auc: 0.8525 - val_loss: 2.5213\n",
      "Epoch 57/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9925 - auc: 0.9969 - loss: 1.5471 - val_accuracy: 0.8092 - val_auc: 0.9036 - val_loss: 2.1054\n",
      "Epoch 58/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5066 - val_accuracy: 0.8266 - val_auc: 0.9075 - val_loss: 1.9796\n",
      "Epoch 59/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4877 - val_accuracy: 0.8439 - val_auc: 0.9116 - val_loss: 1.9719\n",
      "Epoch 60/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.9974 - auc: 0.9999 - loss: 1.4774 - val_accuracy: 0.6532 - val_auc: 0.8852 - val_loss: 2.5418\n",
      "Epoch 61/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4505 - val_accuracy: 0.8324 - val_auc: 0.9060 - val_loss: 1.9520\n",
      "Epoch 62/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4323 - val_accuracy: 0.8439 - val_auc: 0.9045 - val_loss: 1.9105\n",
      "Epoch 63/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.4119 - val_accuracy: 0.8382 - val_auc: 0.9024 - val_loss: 1.9048\n",
      "Epoch 64/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9992 - auc: 0.9944 - loss: 1.3909 - val_accuracy: 0.5838 - val_auc: 0.7969 - val_loss: 3.4716\n",
      "Epoch 65/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3704 - val_accuracy: 0.8266 - val_auc: 0.8923 - val_loss: 1.9309\n",
      "Epoch 66/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3485 - val_accuracy: 0.7572 - val_auc: 0.8761 - val_loss: 2.1789\n",
      "Epoch 67/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9977 - auc: 1.0000 - loss: 1.3335 - val_accuracy: 0.8266 - val_auc: 0.8964 - val_loss: 1.9716\n",
      "Epoch 68/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.3116 - val_accuracy: 0.8497 - val_auc: 0.9026 - val_loss: 1.8407\n",
      "Epoch 69/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9894 - auc: 0.9993 - loss: 1.3165 - val_accuracy: 0.5838 - val_auc: 0.8086 - val_loss: 2.9162\n",
      "Epoch 70/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9856 - auc: 0.9899 - loss: 1.3667 - val_accuracy: 0.5607 - val_auc: 0.7016 - val_loss: 3.8504\n",
      "Epoch 71/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2630 - val_accuracy: 0.8035 - val_auc: 0.8953 - val_loss: 1.8629\n",
      "Epoch 72/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2479 - val_accuracy: 0.7803 - val_auc: 0.8802 - val_loss: 1.9801\n",
      "Epoch 73/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9986 - auc: 1.0000 - loss: 1.2387 - val_accuracy: 0.8035 - val_auc: 0.8779 - val_loss: 1.8971\n",
      "Epoch 74/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9968 - auc: 1.0000 - loss: 1.2290 - val_accuracy: 0.7457 - val_auc: 0.8628 - val_loss: 2.1180\n",
      "Epoch 75/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2074 - val_accuracy: 0.5376 - val_auc: 0.6613 - val_loss: 4.9213\n",
      "Epoch 76/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9983 - auc: 0.9997 - loss: 1.2022 - val_accuracy: 0.7457 - val_auc: 0.8674 - val_loss: 2.0611\n",
      "Epoch 77/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1772 - val_accuracy: 0.7514 - val_auc: 0.8645 - val_loss: 2.0450\n",
      "Epoch 78/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1608 - val_accuracy: 0.8266 - val_auc: 0.8820 - val_loss: 1.8247\n",
      "Epoch 79/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1437 - val_accuracy: 0.8150 - val_auc: 0.8850 - val_loss: 1.8178\n",
      "Epoch 80/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9919 - auc: 0.9983 - loss: 1.1602 - val_accuracy: 0.7919 - val_auc: 0.8525 - val_loss: 1.7033\n",
      "Epoch 81/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1214 - val_accuracy: 0.8035 - val_auc: 0.8928 - val_loss: 1.7113\n",
      "Epoch 82/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.1038 - val_accuracy: 0.6243 - val_auc: 0.7970 - val_loss: 3.0836\n",
      "Epoch 83/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9884 - auc: 0.9994 - loss: 1.1171 - val_accuracy: 0.5838 - val_auc: 0.8022 - val_loss: 3.0281\n",
      "Epoch 84/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0796 - val_accuracy: 0.8208 - val_auc: 0.8981 - val_loss: 1.8046\n",
      "Epoch 85/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0669 - val_accuracy: 0.8150 - val_auc: 0.8945 - val_loss: 1.6873\n",
      "Epoch 86/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0532 - val_accuracy: 0.5260 - val_auc: 0.5601 - val_loss: 6.1749\n",
      "Epoch 87/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0422 - val_accuracy: 0.6936 - val_auc: 0.8712 - val_loss: 2.1593\n",
      "Epoch 88/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 0.9944 - loss: 1.0272 - val_accuracy: 0.5202 - val_auc: 0.6332 - val_loss: 4.4930\n",
      "Epoch 89/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9759 - auc: 1.0000 - loss: 1.0388 - val_accuracy: 0.6185 - val_auc: 0.7541 - val_loss: 4.6361\n",
      "Epoch 90/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9911 - auc: 0.9976 - loss: 1.0498 - val_accuracy: 0.7457 - val_auc: 0.8957 - val_loss: 1.7277\n",
      "Epoch 91/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9918 - val_accuracy: 0.7457 - val_auc: 0.8668 - val_loss: 1.9305\n",
      "Epoch 92/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9807 - val_accuracy: 0.7110 - val_auc: 0.8692 - val_loss: 1.9928\n",
      "Epoch 93/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.9971 - auc: 0.9889 - loss: 0.9869 - val_accuracy: 0.5665 - val_auc: 0.8180 - val_loss: 2.9034\n",
      "Epoch 94/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step - accuracy: 0.9981 - auc: 0.9983 - loss: 0.9910 - val_accuracy: 0.7803 - val_auc: 0.8761 - val_loss: 1.6044\n",
      "Epoch 95/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9511 - val_accuracy: 0.7861 - val_auc: 0.8874 - val_loss: 1.6509\n",
      "Epoch 96/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9403 - val_accuracy: 0.7110 - val_auc: 0.8511 - val_loss: 1.9454\n",
      "Epoch 97/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9322 - val_accuracy: 0.8092 - val_auc: 0.8848 - val_loss: 1.5285\n",
      "Epoch 98/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.9650 - auc: 0.9906 - loss: 1.0521 - val_accuracy: 0.5260 - val_auc: 0.7832 - val_loss: 3.0272\n",
      "Epoch 99/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 78ms/step - accuracy: 0.9905 - auc: 0.9977 - loss: 0.9438 - val_accuracy: 0.7052 - val_auc: 0.8985 - val_loss: 1.7846\n",
      "Epoch 100/100\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.9059 - val_accuracy: 0.8150 - val_auc: 0.8985 - val_loss: 1.4981\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "  History saved to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/LR0_1.1e-05_L2_2e-04/fold_5/history_fold_5.csv\n",
      "    Fold 5 - Best Epoch 100: Val Loss=1.4981, Acc=0.8150, AUC=0.8985\n",
      "    Fold 5 finished in 1471.90 seconds.\n",
      "--------------------------------------------------\n",
      "Results for LR=1.1e-05, L2_Reg=0.0002 (Across 5 Folds):\n",
      "  Avg Val Loss: 1.7938 +/- 0.2854\n",
      "  Avg Val Acc:  0.7878 +/- 0.0481\n",
      "  Avg Val AUC:  0.8357 +/- 0.0594\n",
      "--------------------------------------------------\n",
      "Combination 1 finished in 7430.91 seconds.\n"
     ]
    }
   ],
   "source": [
    "# ----- Hyperparameter Tuning with K-Fold Cross-Validation -----\n",
    "\n",
    "N_SPLITS = 5 # Number of splits for cross-validation\n",
    "NUM_EPOCHS = 100 # Number of epochs for training\n",
    "DROPOUT_RATE = 0.0 # Dropout rate for the model\n",
    "\n",
    "# para cosine decay\n",
    "#learning_rates_to_try = [5e-4, 2e-4, 1e-4] # adicionar 1e-3? ver os resultados\n",
    "#reg_factors_to_try = [5e-4, 2e-4, 1e-4]\n",
    "\n",
    "#para fixed_lr\n",
    "#learning_rates_to_try = [1e-5, 2e-5] # adicionar 4e-5 ou 5e-6 dependendo dos resultados\n",
    "#reg_factors_to_try = [2e-4, 1e-4] # adicionar 4e-4 ou 5e-5 dependendo dos resultados\n",
    "\n",
    "lr_scheduler = \"fixed_lr\" # Choose between \"cosine_decay\" or \"fixed_lr\"\n",
    "\n",
    "learning_rates_to_try = [1.1e-5]\n",
    "reg_factors_to_try = [2e-4]\n",
    "\n",
    "tuning_results = []\n",
    "total_combinations = len(learning_rates_to_try) * len(reg_factors_to_try)\n",
    "current_combination_no = 0\n",
    "\n",
    "if ROI_MASK_PATH is None:\n",
    "    if lr_scheduler == \"cosine_decay\":\n",
    "        RESULTS_BASE_DIR = \"/home/diogommiranda/tese/outputs/full_brain/cosine_decay/CROSS_VALIDATION/results_resnet34/\"\n",
    "    elif lr_scheduler == \"fixed_lr\":\n",
    "        RESULTS_BASE_DIR = \"/home/diogommiranda/tese/outputs/full_brain/fixed_lr/CROSS_VALIDATION/results_resnet34/\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid string for 'lr_scheduler'. Please set it to 'cosine_decay' or 'fixed_lr'.\")\n",
    "    os.makedirs(RESULTS_BASE_DIR, exist_ok=True)\n",
    "    print(f\"Results will be saved to: {RESULTS_BASE_DIR}\")\n",
    "else:\n",
    "    if lr_scheduler == \"cosine_decay\":\n",
    "        RESULTS_BASE_DIR = \"/home/diogommiranda/tese/outputs/masked/cosine_decay/CROSS_VALIDATION/results_resnet34/\"\n",
    "    elif lr_scheduler == \"fixed_lr\":\n",
    "        RESULTS_BASE_DIR = \"/home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/results_resnet34/\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid string for 'lr_scheduler'. Please set it to 'cosine_decay' or 'fixed_lr'.\")\n",
    "    os.makedirs(RESULTS_BASE_DIR, exist_ok=True)\n",
    "    print(f\"Results will be saved to: {RESULTS_BASE_DIR}\")\n",
    "\n",
    "# Set up StratifiedGroupKFold by subjects\n",
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=seed)\n",
    "subject_ids_list = [extract_subject_id(p) for p in train_paths]\n",
    "subject_ids = np.array(subject_ids_list)\n",
    "\n",
    "print(\"\\nStarting Hyperparameter Tuning Grid Search...\")\n",
    "overall_start_time = time.time()\n",
    "\n",
    "# Hyperparameter tuning loop\n",
    "for current_lr in learning_rates_to_try:\n",
    "    for current_reg in reg_factors_to_try:\n",
    "        current_combination_no += 1\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Testing Combination {current_combination_no}/{total_combinations}: LR={current_lr:.1e}, L2_Reg={current_reg:.0e}\")\n",
    "        print(\"=\" * 60)\n",
    "        start_time_combination = time.time()\n",
    "        \n",
    "        combo_dir_name = f\"LR0_{current_lr:.1e}_L2_{current_reg:.0e}\"\n",
    "        combo_results_dir = os.path.join(RESULTS_BASE_DIR, combo_dir_name)\n",
    "        os.makedirs(combo_results_dir, exist_ok=True)\n",
    "        print(f\"  Saving results for this combo to: {combo_results_dir}\")\n",
    "        \n",
    "        # Store results for the current hyperparameter combination\n",
    "        current_combo_losses = []\n",
    "        current_combo_accuracies = []\n",
    "        current_combo_aucs = []\n",
    "        current_combo_best_epoch = []\n",
    "\n",
    "        # Store results for each fold\n",
    "        fold_val_losses = []\n",
    "        fold_val_accuracies = []\n",
    "        fold_val_aucs = []\n",
    "        fold_no = 1\n",
    "\n",
    "        # K-Fold Cross-Validation\n",
    "        for train_indices, val_indices in sgkf.split(train_paths, train_labels, groups=subject_ids):\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"Training Fold {fold_no}/{N_SPLITS} for LR={current_lr:.1e} and Reg={current_reg:.0e}...\")\n",
    "            start_time_fold = time.time()\n",
    "\n",
    "            # Get the paths and labels for the current fold\n",
    "            fold_train_paths = train_paths[train_indices]\n",
    "            fold_train_labels = train_labels[train_indices]\n",
    "            fold_val_paths = train_paths[val_indices]\n",
    "            fold_val_labels = train_labels[val_indices]\n",
    "\n",
    "            # Verify that the training and validation sets have no overlapping subjects\n",
    "            train_subjects = set(subject_ids[train_indices])\n",
    "            val_subjects = set(subject_ids[val_indices])\n",
    "            if not train_subjects.isdisjoint(val_subjects):\n",
    "                raise RuntimeError(f\"WARNING: Fold {fold_no} has overlapping subjects!\")\n",
    "                \n",
    "            print(f\"  Train samples: {len(fold_train_paths)}, Validation samples: {len(fold_val_paths)}\")\n",
    "\n",
    "            # Calculate minmax parameters for the current training fold\n",
    "            fold_min, fold_max = calculate_min_max(fold_train_paths)\n",
    "\n",
    "            # Create fold train dataset\n",
    "            fold_train_data = create_dataset(\n",
    "                paths=fold_train_paths,\n",
    "                labels=fold_train_labels,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                volume_shape=VOLUME_SHAPE,\n",
    "                is_training=True, \n",
    "                seed=seed,\n",
    "                min_val=fold_min, \n",
    "                max_val=fold_max,\n",
    "                mask_path=ROI_MASK_PATH\n",
    "            )\n",
    "            \n",
    "            # Create fold validation dataset\n",
    "            fold_val_data = create_dataset(\n",
    "                paths=fold_val_paths,\n",
    "                labels=fold_val_labels,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                volume_shape=VOLUME_SHAPE,\n",
    "                is_training=False, \n",
    "                seed=None,\n",
    "                min_val=fold_min, \n",
    "                max_val=fold_max,\n",
    "                mask_path=ROI_MASK_PATH\n",
    "            )\n",
    "\n",
    "            if fold_train_data is None or fold_val_data is None:\n",
    "                raise RuntimeError(f\"ERROR: Could not create datasets for fold {fold_no}.\")\n",
    "\n",
    "            # Compute class weights for the current fold\n",
    "            unique_classes, class_counts = np.unique(fold_train_labels, return_counts=True)\n",
    "            print(f\"  Fold train label counts: {dict(zip(unique_classes, class_counts))}\")\n",
    "            fold_class_weights = class_weight.compute_class_weight('balanced', classes=unique_classes, y=fold_train_labels)\n",
    "            fold_class_weight_dict = dict(zip(unique_classes, fold_class_weights))\n",
    "            print(f\"  Fold Class Weights: {fold_class_weight_dict}\")\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            # Build the model\n",
    "            model = Resnet3DBuilder.build_resnet_34((91, 109, 91, 1), 1, reg_factor=current_reg, dropout_rate=DROPOUT_RATE)\n",
    "    \n",
    "            # Cosine decay scheduler\n",
    "            steps_per_epoch = math.ceil(len(fold_train_data) / BATCH_SIZE)\n",
    "            decay_steps = steps_per_epoch * NUM_EPOCHS\n",
    "            COSINE_ALPHA_FACTOR = 1e-6/current_lr # Alpha factor for cosine decay: finishes last epoch (NUM_EPOCHS) in 1e-6\n",
    "            cosine_decay = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=current_lr,\n",
    "                                                                     decay_steps=decay_steps,\n",
    "                                                                     alpha=COSINE_ALPHA_FACTOR,\n",
    "                                                                     name='CosineDecay')\n",
    "            \n",
    "            if lr_scheduler == \"cosine_decay\":\n",
    "                # Use cosine decay\n",
    "                optimizer_lr = cosine_decay\n",
    "                EARLY_STOP_PATIENCE = 20 # we use 20 to mitigate the effect of lucky steps at the beginning of the cosine decay\n",
    "            elif lr_scheduler == \"fixed_lr\":\n",
    "                # Use fixed learning rate\n",
    "                optimizer_lr = current_lr\n",
    "                EARLY_STOP_PATIENCE = 10 # we use 10 because with lower learning rates the model converges with more stability\n",
    "            else:\n",
    "                raise ValueError(\"Invalid string for 'lr_scheduler'. Please set it to 'cosine_decay' or 'fixed_lr'.\")\n",
    "            \n",
    "            early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                patience=EARLY_STOP_PATIENCE,\n",
    "                                                restore_best_weights=True,\n",
    "                                                verbose=1)\n",
    "    \n",
    "            callbacks_list = [early_stopper]\n",
    "\n",
    "            auc_metric = tf.keras.metrics.AUC(name='auc')\n",
    "\n",
    "            # Compile the model\n",
    "            model.compile(loss=\"binary_crossentropy\",\n",
    "                          optimizer= tf.keras.optimizers.Adam(learning_rate=optimizer_lr, clipnorm=1.0),\n",
    "                          metrics=[\"accuracy\", auc_metric])\n",
    "\n",
    "            history = model.fit(\n",
    "                fold_train_data,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                validation_data=fold_val_data,\n",
    "                class_weight=fold_class_weight_dict,\n",
    "                verbose=1,\n",
    "                callbacks=callbacks_list\n",
    "            )\n",
    "            \n",
    "            # Save the data for current fold\n",
    "            fold_dir = os.path.join(combo_results_dir, f\"fold_{fold_no}\")\n",
    "            os.makedirs(fold_dir, exist_ok=True)\n",
    "            history_df = pd.DataFrame(history.history)\n",
    "            history_df.insert(0, 'epoch', range(1, len(history_df) + 1))\n",
    "            history_csv_path = os.path.join(fold_dir, f\"history_fold_{fold_no}.csv\")\n",
    "            try:\n",
    "                history_df.to_csv(history_csv_path, index=False)\n",
    "                print(f\"  History saved to: {history_csv_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error saving history: {e}\")\n",
    "            # Save plots\n",
    "            plot_loss_curves(history, fold_dir)\n",
    "\n",
    "            # Evaluate the fold\n",
    "            best_epoch_index = np.argmin(history.history['val_loss'])\n",
    "            best_epoch = best_epoch_index + 1\n",
    "            val_loss_best = history.history['val_loss'][best_epoch_index]\n",
    "            val_accuracy_best = history.history['val_accuracy'][best_epoch_index]\n",
    "            val_auc_best = history.history['val_auc'][best_epoch_index]\n",
    "            print(f\"    Fold {fold_no} - Best Epoch {best_epoch}: Val Loss={val_loss_best:.4f}, Acc={val_accuracy_best:.4f}, AUC={val_auc_best:.4f}\")\n",
    "    \n",
    "            current_combo_losses.append(val_loss_best)\n",
    "            current_combo_accuracies.append(val_accuracy_best)\n",
    "            current_combo_aucs.append(val_auc_best)\n",
    "            current_combo_best_epoch.append(best_epoch)\n",
    "\n",
    "            # Clean up\n",
    "            del history_df\n",
    "            del history \n",
    "            del fold_train_data\n",
    "            del fold_val_data\n",
    "            del model\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "\n",
    "            end_time_fold = time.time()\n",
    "            print(f\"    Fold {fold_no} finished in {end_time_fold - start_time_fold:.2f} seconds.\")\n",
    "            fold_no += 1\n",
    "\n",
    "        # Aggregate results for the current hyperparameter combination\n",
    "        if len(current_combo_losses) == N_SPLITS:\n",
    "            avg_loss = np.mean(current_combo_losses)\n",
    "            std_loss = np.std(current_combo_losses)\n",
    "            avg_acc = np.mean(current_combo_accuracies)\n",
    "            std_acc = np.std(current_combo_accuracies)\n",
    "            avg_auc = np.mean(current_combo_aucs)\n",
    "            std_auc = np.std(current_combo_aucs)\n",
    "\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"Results for LR={current_lr}, L2_Reg={current_reg} (Across {N_SPLITS} Folds):\")\n",
    "            print(f\"  Avg Val Loss: {avg_loss:.4f} +/- {std_loss:.4f}\")\n",
    "            print(f\"  Avg Val Acc:  {avg_acc:.4f} +/- {std_acc:.4f}\")\n",
    "            print(f\"  Avg Val AUC:  {avg_auc:.4f} +/- {std_auc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "\n",
    "            # Store results\n",
    "            tuning_results.append({\n",
    "                'learning_rate': current_lr,\n",
    "                'reg_factor': current_reg,\n",
    "                'avg_val_loss': avg_loss,\n",
    "                'std_val_loss': std_loss,\n",
    "                'avg_val_accuracy': avg_acc,\n",
    "                'std_val_accuracy': std_acc,\n",
    "                'avg_val_auc': avg_auc,\n",
    "                'std_val_auc': std_auc,\n",
    "                'individual_losses': [round(loss, 4) for loss in current_combo_losses],\n",
    "                'individual_accuracies': [round(acc, 4) for acc in current_combo_accuracies],\n",
    "                'individual_aucs': [round(auc, 4) for auc in current_combo_aucs],\n",
    "                'best_epoch_per_fold': list(current_combo_best_epoch)\n",
    "            })\n",
    "\n",
    "        end_time_combination = time.time()\n",
    "        print(f\"Combination {current_combination_no} finished in {end_time_combination - start_time_combination:.2f} seconds.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857587ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Tuning Results Summary:\n",
      "   learning_rate  reg_factor  avg_val_loss  avg_val_accuracy  avg_val_auc  \\\n",
      "0            0.0      0.0002        1.7938            0.7878       0.8357   \n",
      "\n",
      "   std_val_loss  std_val_accuracy  std_val_auc  \\\n",
      "0        0.2854            0.0481       0.0594   \n",
      "\n",
      "                          individual_losses  \\\n",
      "0  [2.1326, 2.1467, 1.6278, 1.5638, 1.4981]   \n",
      "\n",
      "                    individual_accuracies  \\\n",
      "0  [0.7268, 0.733, 0.8232, 0.8409, 0.815]   \n",
      "\n",
      "                           individual_aucs    best_epoch_per_fold  \n",
      "0  [0.748, 0.7827, 0.8831, 0.8663, 0.8985]  [91, 99, 97, 99, 100]  \n",
      "\n",
      " --- Best Hyperparameters Found ---\n",
      "learning_rate                                            0.000011\n",
      "reg_factor                                                 0.0002\n",
      "avg_val_loss                                             1.793826\n",
      "avg_val_accuracy                                         0.787775\n",
      "avg_val_auc                                              0.835703\n",
      "std_val_loss                                             0.285382\n",
      "std_val_accuracy                                         0.048057\n",
      "std_val_auc                                              0.059374\n",
      "individual_losses        [2.1326, 2.1467, 1.6278, 1.5638, 1.4981]\n",
      "individual_accuracies      [0.7268, 0.733, 0.8232, 0.8409, 0.815]\n",
      "individual_aucs           [0.748, 0.7827, 0.8831, 0.8663, 0.8985]\n",
      "best_epoch_per_fold                         [91, 99, 97, 99, 100]\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Selected best parameters: LR=1.1e-05, L2_Reg=2e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "if not tuning_results:\n",
    "    print(\"No tuning results were recorded.\")\n",
    "else:\n",
    "    \n",
    "    results_df = pd.DataFrame(tuning_results)\n",
    "    results_df = results_df.sort_values(by='avg_val_loss', ascending=True)\n",
    "\n",
    "    print(\"\\nTuning Results Summary:\")\n",
    "    display_cols = ['learning_rate', 'reg_factor', 'avg_val_loss', 'avg_val_accuracy', 'avg_val_auc', 'std_val_loss', 'std_val_accuracy', 'std_val_auc', 'individual_losses', 'individual_accuracies', 'individual_aucs', 'best_epoch_per_fold']\n",
    "    print(results_df[display_cols].round(4))\n",
    "\n",
    "    best_combination = results_df.iloc[0]\n",
    "\n",
    "    print(\"\\n --- Best Hyperparameters Found ---\")\n",
    "    print(best_combination[display_cols])\n",
    "\n",
    "    best_lr_final = best_combination['learning_rate']\n",
    "    best_reg_final = best_combination['reg_factor']\n",
    "    print(f\"\\nSelected best parameters: LR={best_lr_final:.1e}, L2_Reg={best_reg_final:.0e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facddd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67410d07",
   "metadata": {},
   "source": [
    "# --- Train the model with the best hyperparameters and evaluate it on the test set ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efad9e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using full brain scan.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if ROI_MASK_PATH is None:\n",
    "    print(\"\\nUsing full brain scan.\\n\")\n",
    "else:\n",
    "    print(\"\\nUsing ROI mask.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a158e0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here CHANNELS last\n",
      "\n",
      "Using fixed learning rate: 1.1e-05\n",
      "\n",
      "Saving model to: /home/diogommiranda/tese/outputs/best_model.weights.h5\n",
      "  Class Weights: {0: 0.7730434782608696, 1: 1.4156050955414012}\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746445093.154095    1982 service.cc:145] XLA service 0x7fef140016a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746445093.154151    1982 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2025-05-05 12:38:13.874067: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-05-05 12:38:16.633609: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2025-05-05 12:38:21.563183: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746445113.781611    1982 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_366__5', 12 bytes spill stores, 24 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_354__8', 2424 bytes spill stores, 2376 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_336__7', 1828 bytes spill stores, 1680 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_convert_reduce_fusion_16', 204 bytes spill stores, 204 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_1', 352 bytes spill stores, 352 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_3', 332 bytes spill stores, 332 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_convert_reduce_fusion_14', 204 bytes spill stores, 204 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_5', 352 bytes spill stores, 352 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_59', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "I0000 00:00:1746445113.813683    1982 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7319 - auc: 0.7148 - loss: 3.8363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 12:38:50.731167: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1746445142.057882    1983 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_372__5', 12 bytes spill stores, 24 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_359__8', 2424 bytes spill stores, 2376 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_34', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_342__7', 1828 bytes spill stores, 1680 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm70_shflsync_down', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 141ms/step - accuracy: 0.7324 - auc: 0.7159 - loss: 3.8352\n",
      "Epoch 2/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 143ms/step - accuracy: 0.8636 - auc: 0.9249 - loss: 3.5053\n",
      "Epoch 3/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 62ms/step - accuracy: 0.9461 - auc: 0.9882 - loss: 3.2726\n",
      "Epoch 4/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 64ms/step - accuracy: 0.9478 - auc: 0.9825 - loss: 3.2550\n",
      "Epoch 5/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9673 - auc: 0.9944 - loss: 3.1527\n",
      "Epoch 6/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.9785 - auc: 0.9940 - loss: 3.1074\n",
      "Epoch 7/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.9731 - auc: 0.9752 - loss: 3.1654\n",
      "Epoch 8/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9811 - auc: 0.9947 - loss: 3.0285\n",
      "Epoch 9/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9796 - auc: 0.9957 - loss: 2.9819\n",
      "Epoch 10/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.9859 - auc: 0.9940 - loss: 2.9203\n",
      "Epoch 11/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9844 - auc: 0.9910 - loss: 2.9068\n",
      "Epoch 12/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9926 - auc: 0.9940 - loss: 2.8350\n",
      "Epoch 13/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9932 - auc: 0.9960 - loss: 2.7956\n",
      "Epoch 14/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9908 - auc: 0.9980 - loss: 2.7500\n",
      "Epoch 15/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9891 - auc: 0.9991 - loss: 2.7074\n",
      "Epoch 16/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9884 - auc: 0.9955 - loss: 2.6595\n",
      "Epoch 17/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9995 - auc: 1.0000 - loss: 2.5795\n",
      "Epoch 18/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9948 - auc: 1.0000 - loss: 2.5505\n",
      "Epoch 19/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9965 - auc: 1.0000 - loss: 2.5040\n",
      "Epoch 20/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.4396\n",
      "Epoch 21/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9988 - auc: 1.0000 - loss: 2.3854\n",
      "Epoch 22/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9960 - auc: 1.0000 - loss: 2.3485\n",
      "Epoch 23/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.9983 - auc: 1.0000 - loss: 2.2889\n",
      "Epoch 24/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.2301\n",
      "Epoch 25/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.9999 - auc: 0.9955 - loss: 2.1800\n",
      "Epoch 26/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.1329\n",
      "Epoch 27/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 1.0000 - auc: 0.9911 - loss: 2.0672\n",
      "Epoch 28/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0094\n",
      "Epoch 29/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.9514\n",
      "Epoch 30/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8948\n",
      "Epoch 31/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9987 - auc: 1.0000 - loss: 1.8337\n",
      "Epoch 32/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7732\n",
      "Epoch 33/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 62ms/step - accuracy: 0.9978 - auc: 1.0000 - loss: 1.7308\n",
      "Epoch 34/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 1.0000 - auc: 0.9955 - loss: 1.6690\n",
      "Epoch 35/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 1.0000 - auc: 0.9955 - loss: 1.6224\n",
      "Epoch 36/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5730\n",
      "Epoch 37/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.5235\n",
      "Epoch 38/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.9917 - auc: 1.0000 - loss: 1.4898\n",
      "Epoch 39/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4367\n",
      "Epoch 40/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3935\n",
      "Epoch 41/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 1.0000 - auc: 0.9866 - loss: 1.3492\n",
      "Epoch 42/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.3021\n",
      "Epoch 43/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2541\n",
      "Epoch 44/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.2056\n",
      "Epoch 45/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 1.0000 - auc: 0.9955 - loss: 1.1573\n",
      "Epoch 46/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.9926 - auc: 0.9989 - loss: 1.1396\n",
      "Epoch 47/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9965 - auc: 0.9998 - loss: 1.1028\n",
      "Epoch 48/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0750\n",
      "Epoch 49/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0553\n",
      "Epoch 50/50\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0341\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9149 - auc: 0.3249 - loss: 1.3471\n",
      "[1.8720911741256714, 0.8190045356750488]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Train the model with the best hyperparameters and evaluate it on the test set ---\n",
    "\n",
    "cosine_scheduler = False # Set to True if using cosine decay, False if using fixed learning rate\n",
    "\n",
    "train_for_more_epochs = False\n",
    "BEST_NUM_EPOCHS = 50 # number of epochs for training\n",
    "\n",
    "# Hyperparameters\n",
    "BEST_LR = 1.1e-5 # learning rate\n",
    "BEST_REG= 2e-4 # l2 regularization factor\n",
    "\n",
    "# Cosine decay parameters\n",
    "DECAY_STEPS_TO_USE = math.ceil(len(train_data) / BATCH_SIZE) * 100 # 100 epochs (used in cross-validation for cosine decay)\n",
    "BEST_ALPHA_FACTOR =  1e-6 / BEST_LR\n",
    "DROPOUT_RATE = 0.0\n",
    "cosine_decay = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=BEST_LR,\n",
    "                                                        decay_steps=DECAY_STEPS_TO_USE,\n",
    "                                                        alpha=BEST_ALPHA_FACTOR,\n",
    "                                                        name='CosineDecay')\n",
    "\n",
    "\n",
    "model = Resnet3DBuilder.build_resnet_34((91, 109, 91, 1), 1, reg_factor=BEST_REG, dropout_rate=DROPOUT_RATE)\n",
    "if train_for_more_epochs:\n",
    "    model.load_weights(\"/home/diogommiranda/tese/outputs/best_model.weights.h5\") # load model to continue training for more epochs\n",
    "    print(f\"\\nLoading model weights to continue training for more epochs.\")\n",
    "        \n",
    "\n",
    "if cosine_scheduler:\n",
    "    # Use cosine decay\n",
    "    optimizer_lr = cosine_decay\n",
    "    print(f\"\\nUsing cosine decay.\\n\")\n",
    "else:\n",
    "    # Use fixed learning rate\n",
    "    optimizer_lr = BEST_LR\n",
    "    print(f\"\\nUsing fixed learning rate: {BEST_LR}\\n\")\n",
    "\n",
    "auc_metric = tf.keras.metrics.AUC(name='auc')\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=optimizer_lr,\n",
    "                                                     clipnorm=1.0),\n",
    "                metrics=[\"accuracy\", auc_metric])\n",
    "\n",
    "\n",
    "# Only save the model if not using cosine decay\n",
    "if not cosine_scheduler:\n",
    "    check_point_filepath = \"/home/diogommiranda/tese/outputs/best_model.weights.h5\"\n",
    "    print(f\"Saving model to: {check_point_filepath}\")\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=check_point_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='loss',\n",
    "        mode='min',\n",
    "        save_best_only=False)\n",
    "    callbacks = [model_checkpoint_callback]\n",
    "else:\n",
    "    callbacks = None\n",
    "\n",
    "# Compute class weights\n",
    "unique_classes, class_counts = np.unique(train_labels, return_counts=True)\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=unique_classes, y=train_labels)\n",
    "class_weight_dict = dict(zip(unique_classes, class_weights))\n",
    "print(f\"  Class Weights: {class_weight_dict}\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=BEST_NUM_EPOCHS,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Plot loss and accuracy curves\n",
    "plot_loss_curves(history)\n",
    "\n",
    "result = model.evaluate(test_data, return_dict=True)\n",
    "print(f\"[{result['loss']}, {result['accuracy']}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c4859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 12:50:23.676547: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Metrics on Test Set ---\n",
      "Accuracy:    0.8190\n",
      "Sensitivity: 0.6026\n",
      "Specificity: 0.9371 \n",
      "Balanced Accuracy (BACC): 0.7698\n",
      "F1 Score (Weighted):      0.8106\n",
      "Matthews Corr Coef (MCC): 0.5929\n",
      "Area Under the Curve (AUC): 0.8294\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqUAAAJ8CAYAAADH6djVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdM1JREFUeJzt3Xd8Tfcfx/H3DVnIECoxIvbeo2pTatWqolRrr6I1atdWo1q7RYuq+lFt7dEqtffeJfYWKyQikiD390fk1pWoXHJzRF7PPs7jIeece76fm7ryyee7TGaz2SwAAADAQA5GBwAAAACQlAIAAMBwJKUAAAAwHEkpAAAADEdSCgAAAMORlAIAAMBwJKUAAAAwHEkpAAAADJfc6AAAAABeN2FhYYqIiDCkbScnJ7m4uBjS9ssgKQUAAIhHYWFhcnVLIz0MNaR9Hx8fnT17NtElpiSlAAAA8SgiIkJ6GCrnfC2kZE4J2/ijCAX8M1sREREkpQAAAJCU3EWmBE5KzabEO10o8UYOAACA1wZJKQAAAAxH9z0AAIA9mCSZTAnfZiJFpRQAAACGo1IKAABgDyaHqCOh20ykEm/kAAAAeG2QlAIAAMBwdN8DAADYg8lkwESnxDvTiUopAAAADEelFAAAwB6Y6GSTxBs5AAAAXhtUSgEAAOyBMaU2oVIKAAAAw5GUAgAAwHB03wMAANiFAROdEnG9MfFGDgAAgNcGlVIAAAB7YKKTTaiUAgAAwHAkpQAAADAc3fcAAAD2wI5ONkm8kQMAAOC1QaUUAADAHpjoZBMqpQAAADAclVIAAAB7YEypTRJv5AAAAHhtkJQCAADAcHTfAwAA2AMTnWxCpRQAAACGo1IKAABgD0x0sknijRwAAACvDZJSAAAAGI7uewAAAHswmQzovmeiEwAAAPDCqJQCAADYg4Mp6kjoNhMpKqUAAAAwHEkpgAR18uRJVatWTR4eHjKZTFqyZEm8Pv/cuXMymUz66aef4vW5iVmlSpVUqVIlo8MAgP9EUgokQadPn1aHDh2ULVs2ubi4yN3dXWXLltXEiRN1//59u7bdokULHT58WCNGjNCcOXNUokQJu7aXkFq2bCmTySR3d/dYv48nT56UyWSSyWTSN998Y/Pzr1y5oiFDhujAgQPxEC0Au4tepzShj0SKMaVAErNy5Uo1atRIzs7Oat68uQoUKKCIiAht2bJFvXr10tGjR/XDDz/Ype379+9r+/bt+uKLL9SlSxe7tOHn56f79+/L0dHRLs9/nuTJkys0NFTLly9X48aNra7NnTtXLi4uCgsLe6FnX7lyRUOHDlWWLFlUpEiROL9u9erVL9QeACQkklIgCTl79qyaNGkiPz8/rVu3TunTp7dc69y5s06dOqWVK1farf0bN25Ikjw9Pe3WhslkkouLi92e/zzOzs4qW7asfvnllxhJ6bx58/Tuu+9q4cKFCRJLaGioUqRIIScnpwRpD8BTTKaEX6KJJaEAJAZjxoxRSEiIZs6caZWQRsuRI4e6du1q+frhw4caPny4smfPLmdnZ2XJkkX9+/dXeHi41euyZMmi2rVra8uWLXrzzTfl4uKibNmy6eeff7bcM2TIEPn5+UmSevXqJZPJpCxZskiK6vaO/vOThgwZItNT/8CuWbNG5cqVk6enp1KlSqXcuXOrf//+luvPGlO6bt06lS9fXilTppSnp6fq1aunY8eOxdreqVOn1LJlS3l6esrDw0OtWrVSaGjos7+xT/nwww/1559/6s6dO5Zzu3fv1smTJ/Xhhx/GuD8wMFA9e/ZUwYIFlSpVKrm7u6tmzZo6ePCg5Z4NGzaoZMmSkqRWrVpZhgFEv89KlSqpQIEC2rt3rypUqKAUKVJYvi9Pjylt0aKFXFxcYrz/6tWrK3Xq1Lpy5Uqc3ysAxBeSUiAJWb58ubJly6YyZcrE6f62bdtq0KBBKlasmMaPH6+KFStq1KhRatKkSYx7T506pYYNG+qdd97R2LFjlTp1arVs2VJHjx6VJDVo0EDjx4+XJDVt2lRz5szRhAkTbIr/6NGjql27tsLDwzVs2DCNHTtWdevW1datW//zdX///beqV6+u69eva8iQIerRo4e2bdumsmXL6ty5czHub9y4se7evatRo0apcePG+umnnzR06NA4x9mgQQOZTCYtWrTIcm7evHnKkyePihUrFuP+M2fOaMmSJapdu7bGjRunXr166fDhw6pYsaIlQcybN6+GDRsmSWrfvr3mzJmjOXPmqEKFCpbn3Lp1SzVr1lSRIkU0YcIEVa5cOdb4Jk6cqDfeeEMtWrTQo0ePJEnff/+9Vq9ercmTJytDhgxxfq8A/gNjSm1C9z2QRAQHB+vy5cuqV69enO4/ePCgZs+erbZt22r69OmSpE6dOildunT65ptvtH79equkx9/fX5s2bVL58uUlRSV2vr6+mjVrlr755hsVKlRI7u7u6t69u4oVK6aPPvrI5vewZs0aRURE6M8//1TatGnj/LpevXrJy8tL27dvl5eXlySpfv36Klq0qAYPHqzZs2db3V+0aFHNnDnT8vWtW7c0c+ZMffXVV3Fqz83NTbVr19a8efPUunVrRUZGav78+frkk09ivb9gwYI6ceKEHBz+/WHy8ccfK0+ePJo5c6YGDhwob29v1axZU4MGDVLp0qVj/f4FBARo2rRp6tChw3/G5+npqZkzZ6p69eoaPXq0PvzwQ/Xs2VP169d/of8vABAfEm86DcAmwcHBkqISprj4448/JEk9evSwOv/5559LUoyxp/ny5bMkpJL0xhtvKHfu3Dpz5swLx/y06LGoS5cuVWRkZJxec/XqVR04cEAtW7a0JKSSVKhQIb3zzjuW9/mkjh07Wn1dvnx53bp1y/I9jIsPP/xQGzZsUEBAgNatW6eAgIBYu+6lqHGo0Qnpo0ePdOvWLcvQhH379sW5TWdnZ7Vq1SpO91arVk0dOnTQsGHD1KBBA7m4uOj777+Pc1sAEN9ISoEkwt3dXZJ09+7dON1//vx5OTg4KEeOHFbnfXx85OnpqfPnz1udz5w5c4xnpE6dWrdv337BiGP64IMPVLZsWbVt21be3t5q0qSJfvvtt/9MUKPjzJ07d4xrefPm1c2bN3Xv3j2r80+/l9SpU0uSTe+lVq1acnNz06+//qq5c+eqZMmSMb6X0SIjIzV+/HjlzJlTzs7OSps2rd544w0dOnRIQUFBcW4zY8aMNk1q+uabb+Tl5aUDBw5o0qRJSpcuXZxfCyAOoic6JfSRSJGUAkmEu7u7MmTIoCNHjtj0uqcnGj1LsmTJYj1vNptfuI3o8Y7RXF1dtWnTJv3999/6+OOPdejQIX3wwQd65513Ytz7Ml7mvURzdnZWgwYNNHv2bC1evPiZVVJJGjlypHr06KEKFSrof//7n/766y+tWbNG+fPnj3NFWIr6/thi//79un79uiTp8OHDNr0WAOIbSSmQhNSuXVunT5/W9u3bn3uvn5+fIiMjdfLkSavz165d0507dywz6eND6tSprWaqR3u6GitJDg4OqlKlisaNG6d//vlHI0aM0Lp167R+/fpYnx0dp7+/f4xrx48fV9q0aZUyZcqXewPP8OGHH2r//v26e/durJPDoi1YsECVK1fWzJkz1aRJE1WrVk1Vq1aN8T2J6y8IcXHv3j21atVK+fLlU/v27TVmzBjt3r073p4PQEx0slHijRyAzXr37q2UKVOqbdu2unbtWozrp0+f1sSJEyVFdT9LijFDfty4cZKkd999N97iyp49u4KCgnTo0CHLuatXr2rx4sVW9wUGBsZ4bfQi8k8vUxUtffr0KlKkiGbPnm2V5B05ckSrV6+2vE97qFy5soYPH65vv/1WPj4+z7wvWbJkMaqwv//+uy5fvmx1Ljp5ji2Bt1WfPn104cIFzZ49W+PGjVOWLFnUokWLZ34fAcDemH0PJCHZs2fXvHnz9MEHHyhv3rxWOzpt27ZNv//+u1q2bClJKly4sFq0aKEffvhBd+7cUcWKFbVr1y7Nnj1b9evXf+ZyQy+iSZMm6tOnj9577z199tlnCg0N1dSpU5UrVy6riT7Dhg3Tpk2b9O6778rPz0/Xr1/XlClTlClTJpUrV+6Zz//6669Vs2ZNlS5dWm3atNH9+/c1efJkeXh4aMiQIfH2Pp7m4OCgAQMGPPe+2rVra9iwYWrVqpXKlCmjw4cPa+7cucqWLZvVfdmzZ5enp6emTZsmNzc3pUyZUqVKlVLWrFltimvdunWaMmWKBg8ebFmiatasWapUqZIGDhyoMWPG2PQ8AIgPJKVAElO3bl0dOnRIX3/9tZYuXaqpU6fK2dlZhQoV0tixY9WuXTvLvTNmzFC2bNn0008/afHixfLx8VG/fv00ePDgeI0pTZo0Wrx4sXr06KHevXsra9asGjVqlE6ePGmVlNatW1fnzp3Tjz/+qJs3bypt2rSqWLGihg4dKg8Pj2c+v2rVqlq1apUGDx6sQYMGydHRURUrVtRXX31lc0JnD/3799e9e/c0b948/frrrypWrJhWrlypvn37Wt3n6Oio2bNnq1+/furYsaMePnyoWbNm2fQe7t69q9atW6to0aL64osvLOfLly+vrl27auzYsWrQoIHeeuuteHt/QJLFjk42MZltGbkPAACA/xQcHCwPDw85vz1cpuQJu+2x+WGYwtcNVFBQkGXVlcSCSikAAIA9GDHxiIlOAAAAwIujUgoAAGAPjCm1CZVSAAAAGI6kFAAAAIaj+x4AAMAujNhhKfHWG0lKnyMyMlJXrlyRm5tbvG7xBwAA7MdsNuvu3bvKkCGDHBwSb6KWlJCUPseVK1fk6+trdBgAAOAFXLx4UZkyZTKmcSY62YSk9Dnc3NwkSU75WsiUzMngaADEtwsbvjE6BAB2cDc4WDmy+lp+juPVR1L6HNFd9qZkTiSlwGsose14AsA2DL1LPEhKAQAA7MFkMmBHp8SbhDPyFwAAIInatGmT6tSpowwZMshkMmnJkiWWaw8ePFCfPn1UsGBBpUyZUhkyZFDz5s115coVq2cEBgaqWbNmcnd3l6enp9q0aaOQkBCbYyEpBQAAsAeTgzGHDe7du6fChQvru+++i3EtNDRU+/bt08CBA7Vv3z4tWrRI/v7+qlu3rtV9zZo109GjR7VmzRqtWLFCmzZtUvv27W3+dtF9DwAAkETVrFlTNWvWjPWah4eH1qxZY3Xu22+/1ZtvvqkLFy4oc+bMOnbsmFatWqXdu3erRIkSkqTJkyerVq1a+uabb5QhQ4Y4x0KlFAAAwB6il4RK6MOOgoKCZDKZ5OnpKUnavn27PD09LQmpJFWtWlUODg7auXOnTc+mUgoAAPCaCQ4Otvra2dlZzs7OL/XMsLAw9enTR02bNrWsXBIQEKB06dJZ3Zc8eXJ5eXkpICDApudTKQUAAHjN+Pr6ysPDw3KMGjXqpZ734MEDNW7cWGazWVOnTo2nKK1RKQUAALCHF5h4FC9tKmonqyfXYX6ZKml0Qnr+/HmtW7fO6rk+Pj66fv261f0PHz5UYGCgfHx8bGqHSikAAMBrxt3d3ep40aQ0OiE9efKk/v77b6VJk8bqeunSpXXnzh3t3bvXcm7dunWKjIxUqVKlbGqLSikAAIA9JMDEo1jbtEFISIhOnTpl+frs2bM6cOCAvLy8lD59ejVs2FD79u3TihUr9OjRI8s4US8vLzk5OSlv3ryqUaOG2rVrp2nTpunBgwfq0qWLmjRpYtPMe4mkFAAAIMnas2ePKleubPm6R48ekqQWLVpoyJAhWrZsmSSpSJEiVq9bv369KlWqJEmaO3euunTpoipVqsjBwUHvv/++Jk2aZHMsJKUAAABJVKVKlWQ2m595/b+uRfPy8tK8efNeOhaSUgAAAHswcKJTYpR4IwcAAMBrg0opAACAPSSCiU6vEiqlAAAAMByVUgAAADswmUwyUSmNMyqlAAAAMBxJKQAAAAxH9z0AAIAd0H1vGyqlAAAAMByVUgAAAHswPT4Sus1EikopAAAADEdSCgAAAMPRfQ8AAGAHTHSyDZVSAAAAGI5KKQAAgB1QKbUNlVIAAAAYjkopAACAHVAptQ2VUgAAABiOpBQAAACGo/seAADADui+tw2VUgAAABiOSikAAIA9mJTwe9En3kIplVIAAAAYj6QUAAAAhqP7HgAAwA6Y6GQbKqUAAAAwHJVSAAAAOzCZZEClNGGbi09USgEAAGA4KqUAAAB2YJIBY0oTcamUSikAAAAMR1IKAAAAw9F9DwAAYAcsCWUbKqUAAAAwHJVSAAAAezAp4ecdJd5CKZVSAAAAGI+kFAAAAIaj+x4AAMAeDJjoZGaiEwAAAPDiqJQCAADYgRFLQiX8DlLxh0opAAAADEdSCgAAAMPRfQ8AAGAHdN/bhkopAAAADEelFAAAwB7Y0ckmVEoBAABgOCqlAAAAdsCYUttQKQUAAIDhSEoBAABgOLrvAQAA7IDue9tQKQUAAIDhqJQCAADYAZVS21ApBQAAgOFISgEAAGA4uu8BAADsgO5721ApBQAAgOGolAIAANiDSQm/F33iLZRSKQUAAIDxqJQCAADYAWNKbUOlFAAAAIYjKQUAAIDh6L4HAACwA7rvbUOlFAAAAIajUgoAAGAHVEptQ6UUAAAAhiMpBQAAgOHovgcAALAHdnSyCZVSAAAAGI5KKQAAgB0w0ck2VEoBAABgOCqlAAAAdkCl1DZUSgEAAGA4klIAAAAYju57AAAAOzDJgO77RLwmFJVSAAAAGI5KKQAAgB0w0ck2VEoBAABgOJJSAAAAGI7uewAAAHswKeH3ok+8vfdUSgEAAGA8KqUAAAB2wEQn21ApBQAAgOGolAIAANgBlVLbUCkFAACA4UhKAQAAYDi67wEAAOzAZIo6ErrNxIpKKQAAAAxHpRQAAMAOoiqlCT3RKUGbi1dUSgEAAGA4klIAAIAkatOmTapTp44yZMggk8mkJUuWWF03m80aNGiQ0qdPL1dXV1WtWlUnT560uicwMFDNmjWTu7u7PD091aZNG4WEhNgcC0kpAACAPZj+neyUUIds7L6/d++eChcurO+++y7W62PGjNGkSZM0bdo07dy5UylTplT16tUVFhZmuadZs2Y6evSo1qxZoxUrVmjTpk1q3769zd8uxpQCAAAkUTVr1lTNmjVjvWY2mzVhwgQNGDBA9erVkyT9/PPP8vb21pIlS9SkSRMdO3ZMq1at0u7du1WiRAlJ0uTJk1WrVi198803ypAhQ5xjoVIKAABgB9E7OiX0EV/Onj2rgIAAVa1a1XLOw8NDpUqV0vbt2yVJ27dvl6enpyUhlaSqVavKwcFBO3futKk9KqUAAACvmeDgYKuvnZ2d5ezsbNMzAgICJEne3t5W5729vS3XAgIClC5dOqvryZMnl5eXl+WeuKJSimcqmtdXPVu9o/nftNWpVcN1f/+3ur//2/98zbsVC2r6sI+1+7f+urhutIJ3TdT5taO0ePInqlm+QJzb7tuuhqW9JrVKvlD82XzTKmjXBI3sVj/GNQcHkz5pUlFb5/bWzW1jFbDpa62Z2U313i4c67OSJXPQFx1qadGkjvpn+RBd3/KNbu8Yr8NLB2lCv8bKnD61TbF90aGW5f3911G2WHar11UokVNb5/bWnZ3j9c/yIWrfqPwz2+jZ6h0F75qofNnTx3q9TqVCur//W73/TlGbYgee5fixY2r5cTNl9U0vj5TOyp0ji7p91kU3b9584WeO/HKYUjg56Mjhw7FeDwkJ0YjhQ1WyaCGl9Uwl7zQeKl6kgLp92tmmiRZzZv+kj5s1UZGCeZUhnZfcUzgpa+YMavpBQ23bujXW19y6dUstP26mdF7u8k7jodYtPlZgYGCs9547e1ap3Vw18It+sV6/f/++svqmV/06teIcM159CT2e9MnF+n19feXh4WE5Ro0aZew3Iw6olOKZ+rWroTqVY0/SnqVZ7TdV7+3C+ud0gHYfOaeQ0HD5pfdSjXL5VaNcfo2Z+ZcGf7v8P5+R0y+d+rSprsjISDk4vPjvTcM/rauIB480bvbfVucdHEz6bVx7vVuxoO7eC9O2/Wfk4GDSW4Wzav7Ydvpy2h8a8f0fVq9xcUquAR1r6e69MB05eVn7j12Qo2NyFc6dSR0aV1CTmiVVq+Nk7fvnQpxiO+R/SXOW7Yj1WoZ0nqryVh7dux+uA8cuWs77ZUijpd92UsSDh/pryz8qmtdXE/t/oNvBofr9r71Wz8iYzlN92tbQtF836p/TV2NtZ/mGQzrof0lDu9TV0vUH9fBhZJxiB2KzYf06vV+/jkJDQ5U7Tx6VKl1G/xw9ou+nfqcVy5dqw+btypQpk03PvHbtmsaP/Vrvvd9QBQoWjHH93Nmzqlm9is6dPaus2bKpWo2aiggP14kT/vp+2hT17NNPqVKlilNb06Z8q0OHDqpAgYIqU7acnF1cdNLfX0sWLdTSxYs0cfIUtevQ0eo1LT/+UH+vWa1y5SvIbDbrl3n/082bN7Rs5aoYz+/1eTelSZtWffsPiLV9V1dXdf+8t/r06qEN69epUuW34xQ38CwXL16Uu7u75Wtbq6SS5OPjIynqs5g+/b8FjmvXrqlIkSKWe65fv271uocPHyowMNDy+rgiKcUz7Tx0VodPXtHeo+e19+h5HV85TC7Ojv/5mq9m/KUuX85XYNA9q/MlC/hp5bRP1bPVO/pt1V4dPXXlmc/4bmBT3bl7X7sPn7U5KY5WJE8mNXinmL6bt143b1tXSz5tVlnvViyoc5dvqlbHb3X2UlQVJ1cWb/35/aca0LGW/t5+TDsPnbW8Jiziod5uOU67jpzTo0f/Jm8ODiYN6VxHvVpX06QvmqhcszFxim/5hkNavuFQrNe+/KyeqryVR8vWHdS9+xGW892aV5GLs6Oqt5uoXYfPKbV7Cu1fNEB92laPkZSO7vGe7t4L0/Bpfzz9eCtjZ63Rz6NbqdV7ZTT99y1xih14WmhoqFp+/KFCQ0PVf8AgDRw8VFLUJIn+fXtrwrhv9En7Nlr+x182PXfM6JEKCQlRr94xq4vh4eGqV6emLl64oMnfTVPb9h2srh89ckReXl5xbmv8pO+UN18+ubm5WZ1fsXyZmjRqoN49u+u99xsqbdq0kqQ9u3fr7zWr1a59R036bqokqVOHdpr14wzt3bNHxZ8YX7f6r1VasXyZ5sz7VSlTpnxmDO06dNSoEcM08It+2rzNtrF4wNPc3d2tktIXkTVrVvn4+Gjt2rWWJDQ4OFg7d+7UJ598IkkqXbq07ty5o71796p48eKSpHXr1ikyMlKlSpWyqT267/FMY3/6W8OnrtQfm47o2q27cXrNQf9LMRJSSdp95LwWrN4nBwcHVSyZ85mvb/VeGZUvnlP9xi3Snbv3Xzj2do+7teeu2BXzWsOoa0O+XWFJSCXpxLlr+vJxEtejRVWr1zx6FKntB89YJaSSFBlp1tApK3Q/LELF82WWeyqXF445WuMaUR/qeSt3W50vnDuj/M8GaNfhc5Kk28GhWr7+kPJk9ZFj8mSW+yqUyKmG1YtrwKSlunsvTP9l+YZDCg65r7YNy7103Ei6li5epGvXrilX7tz6YuBgy3mTyaRhX46UX5Ys+nvNah06eDDOzwwNDdXcObOVP38BFSkac4jJt5Mn6oS/vz7r1iNGQipJ+QsUUIoUKeLc3pulSsVISCWpdp26qlCxksLCwrRj+zbL+UMHD0iSmn3cwnKuecvWVtckKSIiQp93/0yVKr+tho0a/2cMrq6uqv/e+9qze5cO7N8f59jx6nJwMBly2CIkJEQHDhzQgQMHJEVNbjpw4IAuXLggk8mkbt266csvv9SyZct0+PBhNW/eXBkyZFD9+vUlSXnz5lWNGjXUrl077dq1S1u3blWXLl3UpEkTm2beSySlSEAPHj6SJEU8eBTrde80bhrRrb7W7Tyu+X/ueeF2Uro6qVH14jp5/rr2P9H9LUnuqVyUPfMbkqRNe0/GeO3GPSckSVVL55WTY9w6Esxmsx5FmhUZGfnM9xZXFUrklG96L129EaR1O49bXfN0TxEjUb9zN1TJkjnIw81VUtTY13F9Gmnb/tOaF0tC/rSw8AdavuGQCuXKpJIF/F4qdiRd+/ZFVerLlasQY8iNo6OjSpcuK0lasXxpnJ+5aMHvCgoKUuMmTWO9PmvmdEnSJ50/fZGQbeLoGNVD5OTkZDl3+85tSVLq1P+OJ4/+c/Q1SZo4fqzOnT2rcRMmx6mtD5p+KEn6ccYPLxc0EEd79uxR0aJFVfTxL389evRQ0aJFNWjQIElS79699emnn6p9+/YqWbKkQkJCtGrVKrm4/FuEmTt3rvLkyaMqVaqoVq1aKleunH74wfa/w3TfI0Hkz5FBDasVU8SDh1q743is94zt3Uiuzo76bOSvL9VW+eI55ZbSRb+t2hvjWkrXf8fU3A4OjXE98E5UlTeFq5Ny+qX7z2EG0T5v+Y5SpXDW+p3+Cgt/8BKRS03fjZrU9ftfexUZaba6dvHqbRXOk0kODibLtVx+3gq9H2EZotC5aSXlzuKtsnEcRiBJm/acVLPapVSjfAHtPnL+peJH0hR6L+pz4/lEgvYkrzRpJEmHDsW9UvrHHyskSeUrVIpx7eLFizp96pQyZsokX19fbdu6VStXLFNwUJD8smbVe++9r+w5ctj4LmK3ft1abVi/TqlTp9abpd6ynPf1zSxJOnnyhHLlzi1JOnHC3+raxYsX9dWoEerU5TPlzZcvTu29VbqMHB0d9eefK+MlfhjryYlHCdmmLSpVqiSz2fzM6yaTScOGDdOwYcOeeY+Xl5fmzZtnW8OxICmFXdSqUED1qxSRY/Jk8vVJrbcKZ9ODh4/UafgvVl3m0WqWL6D3qxXTsKkrdPrCjZdqO3rG+t6jMROswKB7evjwkZInT6bM6b104tw1q+tZMqax/Dlzeq9Yk9IvP6undGnc5J7SRQVyZlT2zG/o2Jmr+mTYy30gnZ2Sq36VIpIUa5Xzr61HVa1sPvVvX1MT56xTpZK5VLN8Aa3YGDU21TuNm/q3r6kZC7bo0InLcW53z+NEtHzx+PkhjqQn7RtRvQ8XLsT+S835c1Hjsy+ej/svPdu2bFby5Mlj7bo/fuwfSVL69BnU7dPO+n7aFKvrQwcN0PCRo9Wt++dxbi/azz/N0uZNGxUWHqYzp09r39498vDw0Oz//SJPT0/LfRUqVpKrq6tGDh+qAgULSWazRg4fqhQpUqhCxUqSpL69P5ebu7sGDBoS5/ZdXFxUsGAh7du3V+fOnlWWrFltfg9AYkX3PeyiYK6M+rjuW2pSq6TKFsuh8IiH6vHV77EmWyldnTSxX2OdOHdNY2f9HcvTbFMgZ0ZJ0onz12JcC494qL2PZ8h/XDfmAOwW9Upb/uyWMvaZivWrFNHHdd9SvSpFlD3zGzp04pI+7jNL56/ceqm4a1csKE+3FDp66ooO+l+KcX3mwq06fOKyvuhQS9e3fKPfxrdXyP1wDZoctZrBiG71FfHwoYZOWWF5jYOD6bnDEPwfJ+aFctk2MxqIVq58BUnSqj9Wxlj+6fLly1r79xpJ0t2QuI1Nv379uq5du6ZMvr5ydXWNcf327aju8QP792n6D9M0YNAQnTx7UWcvXtWXo76SJPXr3VN//mF7tXH7tq3635zZWvDbr9q3d4+8vLw0bfqPeqdadav7fHx81Lf/AO3bt1d5cmRRnpxZdeDAfvUfOFje3t7asH6dFi34XSNHjbEaqxoaGrOH5mm5cueRJB18YmwqkBSQlMIuvprxl1yLdpFnqW4q3nCEfl62Q1MGfajfx7e3mpQjScM+rSvf9F76bOSvinjw8KXbfsMr6gfAneDYJ0p9M2u1JKnrR1XU7eMq8k7jpvRveKh3m+pq27CcHjweF/p093m0AvWGyrVoF2Wq3Ed1On2nBw8jtW1ebzWrY9ssw6c1efdNSdIvK2MfCxoe8VCVW45VzzELNGPBFn057Q+92XikTl24rtKFs6lprZIaOGmZ7ty9Ly+PlJo7prVu7xivoF0TtHH25yqYK2Osz330KFLBIffl4eYa4/8NEBdV36mmokWLKSQkRPVq19TuXbsUEhKiHdu3q37tmnr4MOpzHdcl3m48Xl4mtWfswwEiI6MmHD58+FBt23XQFwMHK1OmTPLx8dHnPXvr067dJUXN3rfV1B9m6P4Ds27cvqutO/aocpWqatr4fXXuGHMf7959+2vpij/VsVMXfdL5U634c7U+79lbDx8+VI9un6psufJq2uwjSdK3kybKL6O30niklF9Gb0359tljTFM/XjXg5o2X6zWC8RL7jk4Jje572FV4xEP9c/qquo/+TZGRkerUtJI6Na2oiXPWSZJK5PdTh8YVNHfFTm3cfSJe2vR4PAP+WTPPV2w4rC8mLNHQLnU0qsd7GtXjPcu1GQu2qEieTCpRIEusY06fdOvOPf29/Zh2HT6rPb/116R+H2jjLn9dunbH5pi9PFKqWpm8evQoUvP/ePYkr3v3I/TdLxuszjk4mDSubyPtPXpBs5dEbfv2/dCPVKlkLvUdt1jXbwVraJe6WjypowrWH6b7YTHHvd69Fyb3VK7ydHPVjdtxX3AckKJ+8P7y+yI1qPeu9u3dowpl//0FzdvbWwMGDdGQQQPk+Ywk82lBQUGSpFSxzIaXZLX26MctWsW43rxFK40f+7V279qpsLAwqwkZcZUqVSoVK15c/5v3q8LDwvTjzOmqWq263mvwvtV91arXULXqNazORa8MsH3XPknSksWL1Ovzbmr64Udq0LCRFi9coM+7f6bMfn6qXadujLajl/G5E3TH5riBxIykFAlm3opd6tS0kmpXKmRJSquXy69kyRyUP0cG/TW9q9X9ubJEbWvWp011tXqvjNZs+0ffzFrz3HaCQqKSUbeUz/5BNG7231q6/qDeq1pUfum9FBxyX39uOaote0/p1KrhkqRjz1h0/mnBIWFauemIOn5QQW+/lUc/L419Ufz/0rBaMTk5JteGXf66fP2OTa9t17C8CubMqArNv5Ek5cicTrUrFtTwqSs1df5GSdL1wBCtntFVH9QsoZ8Wb4/xDPdUUV2kL7MMF5I2Pz8/7dxzQEuXLNaO7dsUdv++8ubLryYfNtPSxYskSfny5Y/Tszw8PCRJIXdj7+7PnPnflSL8smSJGcvjc48ePVJgYKDNy9I8rcmHH2nF8mVasWxpjKT0aQEBARo5fKjad+ykgoUKSZImjPtGWbNl04xZs+Xg4KBa79bWtm1bNO6bMbEmpdFJuaeH50vFDeMlholOr5Ikl5QOGTJES5YssazHhYRz8/HM9rSeMXdYKZLH95mvy5PNR3my+cR5zOaNwKgfZKk9/nuNwtMXbuibH1dbnfP1Sa2M3ql16sJ1XbkRFKf2JOnWnajq4hup47Z7zNOiZ90/vTbp86TxTKlBnd7VT0u2W3aTyp01Kpnf+8+/k0r2HD0nScqbLeaWo8mTO8gtpYuC7t63LNsFvIjkyZPr/YaN9H7DRlbno9f3LP94AtDzvPF4H+3A27Fv2Zk7Tx65uLgoLCxMd27f1huPJ1pFe3Krz7ju6PRfohfMv3nz+d3p/fv0kqurqwYN+Xem8gn/46pcpapl+IKDg4OKFS+h9WtjH0N/5/GY2bRPvS/gdZfkxpT27NlTa9euNTqMJCl6dveZJ2bfj/j+D7kW7RLrEb0NZ6svZsu1aBe1H/y/OLVz+PHM81x+3jbH+EmTipKkHxfGvtf1s5QvHrUhwJlYVhZ4niwZ0+itwtkUej9CS9YesOm1wz6tK7NZGjR5WYxrKVz+XVMxeims2MbJ5s4StQ3coRMxJ1cBLysgIECLFy1QmjRpVP+9BnF6Tbp06eTj46NLFy/GOjHI2dlZVR9PPNq0cUOM65s3RfUQZM2W7aV3tLF+Xvb/vG/rli36Zd7/NHzEaKuZ+pJ0/6n3EXrv3jPH2PofPyZJKly4yIsFjFcGY0ptk+SS0lSpUilNmjTPvxE2S5s6lVq9V0auLjG3In27VB6N6FZfkp6553t82br/lCSpeP7MsV5P4eJkqSY+qc37ZfVps8ryPxug737ZaHWtRrn8eqtwzKVZXF0cNaRzHVUokVNXbwRp9dZ/rK4P+7SuDiwaoI4fVHhmvNFV0hUbDz13B6YnFc+XWS3rl9bQKcutdtGK3uv+gxr/bnPYpGYJq2tPKvF40fzNe0/FuW3gaUePHFFYmPXf30uXLqlRg3q6e/euRo8ZG+tM+mcpU668Hj169MydjXp83luSNGrkcJ088e949HNnz2rYkIGSpLbtrfeq371rlwoXyKOa1apYnT9+7JgW/P6bIiIirM6bzWb99ut8jftmjEwmkz56Yvempz169Eg9unbRm6Xe0sctWlpdy5svvzZt3KDLl6N+Yb58+bI2b9qovLEMZwgLC9ORI4eVydeX5aCQ5LwS3fcLFizQ0KFDderUKaVIkUJFixbV0qVL1blzZ925c0dvvvmmJk6cqPDwcPXo0UP9+/dXv379NHPmTKVIkULDhw9Xq1b/Dna/dOmSevXqpb/++kvh4eHKmzevvvvuO5UqVYruexvUKJdf/dr9O4DfyTFqZvbG2f+u/Tdq+iqt2nJUUlSyN2XQh/q61/vaf+yiLl+7E7UIfeZ0ypMtqho36X/rbK4G2mrL3lO6ey9MFUrEvp1p2tSpdGDRQB09dUWnL9zQg4ePVDSvr7L5vqFzl2+qXpepMVYBKJ7fTwM61tLla7d10P+ygkPuyzuNuwrlzqQ0nil1526oPu7zo9Ve9ZLkk9ZdubP6KE0sQxaiNakZ3XX//B2YnjShX2MdOH5JMxZYV3XPXrqpRWv2qcE7xbTlf710PfCuqpXJp3OXb+q3VTEnUVV4XOVdtfmITe0DT5ow7hstW7pYRYoWk0/69Lpx/bq2bd2i8PBw9ftioD5q/uyELjY1a76rRQt+1+ZNG1SmbNkY10uXKaP+AwZp5JfD9FbJoipdpqySJUum7du26u7du6peo6a6duth9Zr790N1wt8/RvJ8/fo1ffzhB/Lw8FDRYsXl7e2joKA7OnbsH50/d04ODg766utxKlGy5DPj/WHaVB05clibt+2KUanq2buvGtSrrbKliuutMmW1Y9tW3bt3T7369IvxnO3bturBgweqWfNdW75dwGvB8KT06tWratq0qcaMGaP33ntPd+/e1ebNmy27C6xbt06ZMmXSpk2btHXrVrVp00bbtm1ThQoVtHPnTv3666/q0KGD3nnnHWXKlEkhISGqWLGiMmbMqGXLlsnHx0f79u2zLCHyPOHh4QoPD7d8HRwcbJf3nRikTZ1KbxaK+Zv6k+fSPjGG8sbtu+o/frHKl8ipfNnTq1jezHJwMCngZpB+W7VHMxZs1eZYtvaMb/fuR+i3VXvV5v2yKp4vs2Vd0mi3g0P1w++bVa5YDlV6M5eSJXPQucu39OW0PzTh579jJJaStHTdAbmldFbZotlVPH9mebmn1P3wCJ2+eFMzF27R1PkbFXDT9r8rJfL7KVcWb127Fay/t8e+01VsWr5XWsXyZdbbrcbHuhNHx6HzFHwvTHUrF1a+7Om1fpe/enz1u8IjrJNtF2dH1alcSIdOXGI3J7yUOvXq69q1AB0+dFDbt21V6tSp9U71Gvr0s26WxeRt8X6jxurZo6t+nT9Pffp9Ees9AwcPVcFChfXtpAnatXOHHj58qFy5cqvZxy30SecuSpYsbkuc5c2XX4OGDNOmjRt08uQJbd+2VQ4ODsqYKZNatGytDp90VtFixZ75+ps3b2r40EFq3aadihUvHuN6zVrvatoPM/XN16P1x4rlyuznp+EjRseYtS9Jv/4StQlHqzbt4hQ7Xm1GdKcn5u57k/m/9pZKAPv27VPx4sV17tw5+flZ773dsmVLbdiwQWfOnLGMvcmTJ4/SpUunTZs2SYrqMvHw8NCMGTPUpEkT/fDDD+rZs6fOnTsnr8drvT3peZXSIUOGaOjQoTHOOxdsJ1Myp1hegVdRoVwZtfPXfpo6f6N6fPW70eG8shrXKK7Zo1rps5HzNf33LUaHY4jbu781OgQ8Q6/Pu+vbSRO0dceeWJO91839+/eVLXMG5ciZS5u37TQ6nEQvODhY3mk8FBQUFC9ji21t28PDQ/n7LFUy55QJ2vaj8Hs6+lU9Q973yzJ8TGnhwoVVpUoVFSxYUI0aNdL06dMtu3VIUv78+a0Gg3t7e6tgwYKWr5MlS6Y0adLo+uPFlg8cOKCiRYvGmpDGRb9+/RQUFGQ5Ll68+ILvDEY6dOKyFq7ep+b13nrhGfFJQY+W7+j0hRuxLhMFGK1Xn35KlSqVvh4zyuhQEsT076fpzp07Gj4iabzfpCB6SaiEPhIrw5PSZMmSac2aNfrzzz+VL18+TZ48Wblz59bZs1F7JTs6Wk+aMZlMsZ6L7p63ZSB9bJydneXu7m51IHEaOHmZHJMnU4+W7xgdyiupTqVCKpw7kwZ/u4yloPBKSpcunbp/3ktLFy/SkcOHjQ7Hru7fv6/xY8eoeo2aqlT5baPDAQxh+JhSKSqpLFu2rMqWLatBgwbJz89PixcvfqFnFSpUSDNmzFBgYOALV0vxejh76aY83uxmdBivrOUbDsm1aBejwwD+U/8Bg9R/wCCjw7A7V1dXnb0Ytw07gNeV4ZXSnTt3auTIkdqzZ48uXLigRYsW6caNG8qbN+8LPa9p06by8fFR/fr1tXXrVp05c0YLFy7U9u10TwIAgIRjkgHrlCrx9t8bnpS6u7tr06ZNqlWrlnLlyqUBAwZo7Nixqlmz5gs9z8nJSatXr1a6dOlUq1YtFSxYUKNHj47zLEwAAAAkPMNn37/qomfQMfseeD0x+x54Pb0Ks+8L9VumZC4JPPs+7J4OjarL7HsAAADgRZCUAgAAwHCvxOx7AACA1w07OtmGSikAAAAMR6UUAADADozYYSkRF0qplAIAAMB4VEoBAADsgDGltqFSCgAAAMORlAIAAMBwdN8DAADYAROdbEOlFAAAAIajUgoAAGAHTHSyDZVSAAAAGI6kFAAAAIaj+x4AAMAeDJjopMTbe0+lFAAAAMajUgoAAGAHTHSyDZVSAAAAGI5KKQAAgB2weL5tqJQCAADAcCSlAAAAMBzd9wAAAHbARCfbUCkFAACA4aiUAgAA2AETnWxDpRQAAACGIykFAACA4ei+BwAAsAMmOtmGSikAAAAMR6UUAADADqiU2oZKKQAAAAxHpRQAAMAOWBLKNlRKAQAAYDiSUgAAABiO7nsAAAA7YKKTbaiUAgAAwHBUSgEAAOyAiU62oVIKAAAAw5GUAgAAwHB03wMAANgBE51sQ6UUAAAAhqNSCgAAYAcmGTDRKWGbi1dUSgEAAGA4KqUAAAB24GAyySGBS6UJ3V58olIKAAAAw5GUAgAAwHB03wMAANgBOzrZhkopAAAADEelFAAAwA5YPN82VEoBAABgOJJSAAAAGI7uewAAADtwMEUdCd1mYkWlFAAAAIajUgoAAGAPJgMmHlEpBQAAAF4clVIAAAA7YPF821ApBQAAgOFISgEAAGA4uu8BAADswPT4v4RuM7GiUgoAAADDUSkFAACwAxbPtw2VUgAAABiOpBQAAACGo/seAADADkwmU4Lv6JTgO0jFIyqlAAAAMByVUgAAADtgRyfbUCkFAACA4aiUAgAA2IGDySSHBC5dJnR78YlKKQAAAAxHUgoAAADD0X0PAABgB0x0sg2VUgAAABiOpBQAAMAOohfPT+jDFo8ePdLAgQOVNWtWubq6Knv27Bo+fLjMZrPlHrPZrEGDBil9+vRydXVV1apVdfLkyfj+dpGUAgAAJFVfffWVpk6dqm+//VbHjh3TV199pTFjxmjy5MmWe8aMGaNJkyZp2rRp2rlzp1KmTKnq1asrLCwsXmNhTCkAAEAStW3bNtWrV0/vvvuuJClLliz65ZdftGvXLklRVdIJEyZowIABqlevniTp559/lre3t5YsWaImTZrEWyxUSgEAAOwgeqJTQh+SFBwcbHWEh4fHGmOZMmW0du1anThxQpJ08OBBbdmyRTVr1pQknT17VgEBAapatarlNR4eHipVqpS2b98er98vKqUAAACvGV9fX6uvBw8erCFDhsS4r2/fvgoODlaePHmULFkyPXr0SCNGjFCzZs0kSQEBAZIkb29vq9d5e3tbrsUXklIAAAA7MHJHp4sXL8rd3d1y3tnZOdb7f/vtN82dO1fz5s1T/vz5deDAAXXr1k0ZMmRQixYtEiTmaCSlAAAArxl3d3erpPRZevXqpb59+1rGhhYsWFDnz5/XqFGj1KJFC/n4+EiSrl27pvTp01ted+3aNRUpUiReY2ZMKQAAQBIVGhoqBwfrdDBZsmSKjIyUJGXNmlU+Pj5au3at5XpwcLB27typ0qVLx2ssVEoBAADswPT4SOg2bVGnTh2NGDFCmTNnVv78+bV//36NGzdOrVu3jnqeyaRu3brpyy+/VM6cOZU1a1YNHDhQGTJkUP369eM1dpJSAACAJGry5MkaOHCgOnXqpOvXrytDhgzq0KGDBg0aZLmnd+/eunfvntq3b687d+6oXLlyWrVqlVxcXOI1FpP5ySX7EUNwcLA8PDzkXLCdTMmcjA4HQDy7vftbo0MAYAfBwcHyTuOhoKCgOI2tjO+2PTw89P60zXJ0TZWgbT+4H6KFHcsb8r5fFmNKAQAAYDi67wEAAOzAwRR1JHSbiRWVUgAAABguTpXSZcuWxfmBdevWfeFgAAAAkDTFKSmN65R/k8mkR48evUw8AAAArwWTySRTAu/olNDtxac4JaXRC6gCAAAA9vBSE53CwsLifY0qAACA10UiLlwmOJsnOj169EjDhw9XxowZlSpVKp05c0aSNHDgQM2cOTPeAwQAAMDrz+akdMSIEfrpp580ZswYOTn9u5h8gQIFNGPGjHgNDgAAAEmDzUnpzz//rB9++EHNmjVTsmTJLOcLFy6s48ePx2twAAAAiVX0RKeEPhIrm5PSy5cvK0eOHDHOR0ZG6sGDB/ESFAAAAJIWm5PSfPnyafPmzTHOL1iwQEWLFo2XoAAAABK76B2dEvpIrGyefT9o0CC1aNFCly9fVmRkpBYtWiR/f3/9/PPPWrFihT1iBAAAwGvO5kppvXr1tHz5cv39999KmTKlBg0apGPHjmn58uV655137BEjAABAosOYUtu80Dql5cuX15o1a+I7FgAAACRRL7x4/p49e3Ts2DFJUeNMixcvHm9BAQAAIGmxOSm9dOmSmjZtqq1bt8rT01OSdOfOHZUpU0bz589XpkyZ4jtGAACARMf0+EjoNhMrm8eUtm3bVg8ePNCxY8cUGBiowMBAHTt2TJGRkWrbtq09YgQAAMBrzuZK6caNG7Vt2zblzp3bci537tyaPHmyypcvH6/BAQAAJFYOJpMcEnjiUUK3F59srpT6+vrGukj+o0ePlCFDhngJCgAAAEmLzUnp119/rU8//VR79uyxnNuzZ4+6du2qb775Jl6DAwAAQNIQp+771KlTW617de/ePZUqVUrJk0e9/OHDh0qePLlat26t+vXr2yVQAACAxMRkijoSus3EKk5J6YQJE+wcBgAAAJKyOCWlLVq0sHccAAAArxUjdlhKcjs6RQsLC1NERITVOXd395cKCAAAAEmPzROd7t27py5duihdunRKmTKlUqdObXUAAADg3zGlCX0kVjYnpb1799a6des0depUOTs7a8aMGRo6dKgyZMign3/+2R4xAgAA4DVnc/f98uXL9fPPP6tSpUpq1aqVypcvrxw5csjPz09z585Vs2bN7BEnAAAAXmM2V0oDAwOVLVs2SVHjRwMDAyVJ5cqV06ZNm+I3OgAAgEQqekenhD4SK5uT0mzZsuns2bOSpDx58ui3336TFFVB9fT0jNfgAAAAkDTYnJS2atVKBw8elCT17dtX3333nVxcXNS9e3f16tUr3gMEAABIjJjoZBubx5R2797d8ueqVavq+PHj2rt3r3LkyKFChQrFa3AAAABIGl5qnVJJ8vPzk5+fX3zEAgAAgCQqTknppEmT4vzAzz777IWDAQAAeF2wo5Nt4pSUjh8/Pk4PM5lMr21SuvG3IUrlxm5VwOtm3fHrRocAwA5CQ+4aHQJsFKekNHq2PQAAAOLGQS8wozwe2kysEnPsAAAAeE289EQnAAAAxMSYUttQKQUAAIDhSEoBAABgOLrvAQAA7MBkkhwSuDc9Effev1ildPPmzfroo49UunRpXb58WZI0Z84cbdmyJV6DAwAAQNJgc1K6cOFCVa9eXa6urtq/f7/Cw8MlSUFBQRo5cmS8BwgAAJAYOZiMORIrm5PSL7/8UtOmTdP06dPl6OhoOV+2bFnt27cvXoMDAABA0mBzUurv768KFSrEOO/h4aE7d+7ER0wAAABIYmxOSn18fHTq1KkY57ds2aJs2bLFS1AAAACJXfQ6pQl9JFY2J6Xt2rVT165dtXPnTplMJl25ckVz585Vz5499cknn9gjRgAAALzmbF4Sqm/fvoqMjFSVKlUUGhqqChUqyNnZWT179tSnn35qjxgBAAASHSMmHiXmiU42J6Umk0lffPGFevXqpVOnTikkJET58uVTqlSp7BEfAAAAkoAXXjzfyclJ+fLli89YAAAAXhsmU8IvZp+Ih5TanpRWrlz5PwfRrlu37qUCAgAAQNJjc1JapEgRq68fPHigAwcO6MiRI2rRokV8xQUAAIAkxOakdPz48bGeHzJkiEJCQl46IAAAgNeBg8kkhwTuT0/o9uKTzUtCPctHH32kH3/8Mb4eBwAAgCTkhSc6PW379u1ycXGJr8cBAAAkag6Kx+qfDW0mVjYnpQ0aNLD62mw26+rVq9qzZ48GDhwYb4EBAAAg6bA5KfXw8LD62sHBQblz59awYcNUrVq1eAsMAAAASYdNSemjR4/UqlUrFSxYUKlTp7ZXTAAAAIke65TaxqahB8mSJVO1atV0584dO4UDAACApMjm7vsCBQrozJkzypo1qz3iAQAAeC04yIAloZR4S6U2T9L68ssv1bNnT61YsUJXr15VcHCw1QEAAADYKs6V0mHDhunzzz9XrVq1JEl169a12m7UbDbLZDLp0aNH8R8lAABAIsOYUtvEOSkdOnSoOnbsqPXr19szHgAAACRBcU5KzWazJKlixYp2CwYAAABJk00TnUyJuSYMAACQgBxMUUdCt5lY2ZSU5sqV67mJaWBg4EsFBAAAgKTHpqR06NChMXZ0AgAAQEwmkxJ8SajE3KltU1LapEkTpUuXzl6xAAAAIImK8zqljCcFAACAvdg8+x4AAADPxzqltolzUhoZGWnPOAAAAJCE2TSmFAAAAHHDklC2ifOYUgAAAMBeSEoBAABgOLrvAQAA7MD0+L+EbjOxolIKAAAAw1EpBQAAsAMmOtmGSikAAAAMR6UUAADADqiU2oZKKQAAAAxHUgoAAADD0X0PAABgByaTSaYE3ow+oduLT1RKAQAAYDgqpQAAAHbARCfbUCkFAACA4UhKAQAAYDi67wEAAOzAZIo6ErrNxIpKKQAAQBJ2+fJlffTRR0qTJo1cXV1VsGBB7dmzx3LdbDZr0KBBSp8+vVxdXVW1alWdPHky3uMgKQUAALADB5PJkMMWt2/fVtmyZeXo6Kg///xT//zzj8aOHavUqVNb7hkzZowmTZqkadOmaefOnUqZMqWqV6+usLCweP1+0X0PAACQRH311Vfy9fXVrFmzLOeyZs1q+bPZbNaECRM0YMAA1atXT5L0888/y9vbW0uWLFGTJk3iLRYqpQAAAHYQvSRUQh+2WLZsmUqUKKFGjRopXbp0Klq0qKZPn265fvbsWQUEBKhq1aqWcx4eHipVqpS2b98eX98qSSSlAAAAr53g4GCrIzw8PNb7zpw5o6lTpypnzpz666+/9Mknn+izzz7T7NmzJUkBAQGSJG9vb6vXeXt7W67FF5JSAACA14yvr688PDwsx6hRo2K9LzIyUsWKFdPIkSNVtGhRtW/fXu3atdO0adMSOGLGlAIAANiHAUtC6XF7Fy9elLu7u+W0s7NzrLenT59e+fLlszqXN29eLVy4UJLk4+MjSbp27ZrSp09vuefatWsqUqRIPAZOpRQAAOC14+7ubnU8KyktW7as/P39rc6dOHFCfn5+kqImPfn4+Gjt2rWW68HBwdq5c6dKly4drzFTKQUAALADB5nkoIQtldraXvfu3VWmTBmNHDlSjRs31q5du/TDDz/ohx9+kCSZTCZ169ZNX375pXLmzKmsWbNq4MCBypAhg+rXrx+vsZOUAgAAJFElS5bU4sWL1a9fPw0bNkxZs2bVhAkT1KxZM8s9vXv31r1799S+fXvduXNH5cqV06pVq+Ti4hKvsZCUAgAAJGG1a9dW7dq1n3ndZDJp2LBhGjZsmF3jICkFAACwA5MBE50SfGJVPGKiEwAAAAxHpRQAAMAOXmSHpfhoM7GiUgoAAADDUSkFAACwAweTSQ4JPMgzoduLT1RKAQAAYDiSUgAAABiO7nsAAAA7YEko21ApBQAAgOGolAIAANiBgwyY6KTEWyqlUgoAAADDkZQCAADAcHTfAwAA2AETnWxDpRQAAACGo1IKAABgBw5K+OpfYq42JubYAQAA8JqgUgoAAGAHJpNJpgQe5JnQ7cUnKqUAAAAwHEkpAAAADEf3PQAAgB2YHh8J3WZiRaUUAAAAhqNSCgAAYAcOJpMcEnjiUUK3F5+olAIAAMBwJKUAAAAwHN33AAAAdpJ4O9MTHpVSAAAAGI5KKQAAgB2YTFFHQreZWFEpBQAAgOGolAIAANiByWRK8L3oE7q9+ESlFAAAAIYjKQUAAIDh6L4HAACwAwclfPUvMVcbE3PsAAAAeE1QKQUAALADJjrZhkopAAAADEdSCgAAAMPRfQ8AAGAHpsdHQreZWFEpBQAAgOGolAIAANgBE51sQ6UUAAAAhqNSCgAAYAcsnm+bxBw7AAAAXhMkpQAAADAc3fcAAAB2wEQn21ApBQAAgOGolMJms3+YrH27tuvk8X8UeOuGwsPDlPYNb5V4q5xadeyqXHnzx3jN1SuXtHHNnzp8YI8O7d+jc6dPymw268ff/tCbZcq/cCxLF8zTF9066LvZv6tilRqW8+tXr9SaP5bq2OGDunE9QCF3g+Xu4an8hYrpgxZtValqzVif9+jRI82fPV1Lf5+rs6dOKFny5Mqdr4A+atNJ79SqZ1NsLRvW1J4dW/7zHpPJpMMXg63OzZv1vWb/MFnXr11Vzjz51XPAiGd+jzo0e0/nz57S0nW75eziEuP66MF99Pv/ftSKTfuUPqOvTfEDkhR8J1Ad65VTUOAtpffNohl/7Ixxz7sFvZ/7nEJvltWomYtsanvtst807otPNfi7/+nNCu/EuP7wwQOtmP+jNv6xSBfPnpI5MlJe6XyUv+ib+qhLX6X1Th/jNedPHdfcKd/o8J5tCgu9p/S+WVStwYeq26ydHBziXqc5639Uqxb8Tyf/OaAbVy8r+M5tOTk7K3O2XKpYq4FqNW6h5I6OMV63fN5MLf55qm5dv6YsOfOqTc/BKlSybKxtDOzYRJfPnda0pZvl5Bzz8/3DVwP05+9z9P3yrUqXPlOcY0fCYfF825CUwmbTJ3+j+6GhypW3gHLmySdJOn3imJYv/EV/LlugCdPnxkj6/v5jqb4a0jde4wgPC9PkMcNVoHBxq4RUkpYt+EV//7lMOXLlVcGiJZQylZuuXDyvzetXa/P61Wrb5XN16zvE6jWPHj3SZ22aaOPfq5QiZSoVfbO0IiMjdXDPTnVv/5E+6d5PnT/vH+f4ylWqqoy+mWO99s+hAzrp/4+Kv1nG6vwfS37XyIE9lT6jr8pXfkc7t25Sx4/f0/INe5XR18/q3r//XKatG//WpJm/xJqQSlKbTt31+/9+1KQxwzVq4g9xjh2INuPrIQq+Hfif91Sp+8Ezr+3e/LeCb99S/mJv2dRuRHiY5kwerVwFisSakN4Nuq0B7T/QqX8OyusNbxV5q4Ik6eqFs1qzZL7eee/DGEnpsQO79UW7RgoPu69cBYvKO4OvjuzdoeljBunYgT3q+80Pce76PLJ3h1bM/1HpMvjKN1sueXilUVDgLR07sFvHD+3Vtr9XavgPv8rR0cnymg1/LNK0Uf31RvpMKlHubR3ctUWDOjbV98u2yDuj9b8V29b+oX1b12vAxJ9iTUglqWHrT/Xn73M0Z/JofT7y2zjFDbzKSEphs0k/zlf+gkVjJELzZ0/Xl1/00OBeXbR2t7+SJ//3r1emzFn0cdvOKlC4mAoULqYRA3tq28a1LxXHr3NmKODKJfUd+lWMa+0/66XBX02UZ+o0VucP7duttk3rauZ341SrXiOrqu6cGd9p49+rlNHXT9N/WabMWbJJks6c8lfbD+po6vhRKlupiooULxWn+Np2+fyZ15rWrixJqv1+E6vz308ao7TpvLVw9Ta5e3hq365tat6gun6aNklfjBhruS/s/n19Pay/yleuprer135mO294+6huow+1YO4ste3cQ9lz5YlT7IAkHdixSWuX/aoaDT/WqgVznnlfjxGTYj0fEhykTauWSJIq125oU9srf/1JNwIuq33fL2NcM5vNGtmjjU79c1AfftJTTdp3V7In/r25evGcUqRys3rNwwcP9HXfTgoPu6+2vYbqveYdJUn3Q+9pQPvG2rJ6mf5eWkXv1Lf+TD5LifJVNKP8TqX3zWJ1/vbN6/qiXSMd3rNNq36fozoftrFc+/WHCUqdNp2+XbBOqdw9dHTfTvVuUVeLfpqqT74YZbkvPOy+Znw9SCXKVVHpt2Pv1ZEkrze8VaVuY61aMEeN2nyqzNlzxyl24FXFmFLYrFjJ0rFW5pq0aCdfv2y6deO6Tp84bnWtcrV31WfIaL37XmP5ZcshUzx0MPz68wx5eKZWxVi64vMWKBwjIZWkQsVKqkadBjKbzdq1bdNTz5spSfqs9yBLQipJ2XLkVqce/SRJP06Z8NJxnz9zSocP7JGzs4uq137Pcj4iPFxnT51Q5Wrvyt3DU5JU7M0yypIth47/c8jqGTO+G6fr167GmpA/rU6DD2Q2m/XrnJkvHTuSjvCw+/p2WC9lzp5bDVp2eqFnbFm9TA8iwpWnUHFl9Mv2/Bc84Y/fZsvNI3WsVdItfy3ToV1bVa5aXTXr1MsqIZWk9L5Z5PHU53/72j907fIFZc2d35KQSpJripT6pH9UQrh49tQ4x5feN0uMhFSSUqdNp4atP5UkHdz17/CdBxHhunT2pN6qXEOp3D0kSfmLlVLGLNl1xv+I1TN+nzlZt65fizUhf1rl2g1lNpv1x2+z4xw7Eo7JZMyRWJGUIl4ld4z64eDoFHMsVXzavX2Lzp89rXdq1ZNjLOO2/kv0OC9Hp3+71e4GB+ni+TOSpJKlY47ffLNMVNfgto1rFREe/qJhS5KWL/pVklTpnZpye/zDSZLu3g1WZGSkJSGN5u7hqeCgO5avL104p1lTJ6hlh8/kly3Hc9srWrK00mf01YpFvyo8LOylYkfSMW/qNwq4dF6dB46x6vWwxfoVCyVJles0sul1h3dv05XzZ1Sm6ruxjstctfB/kmRVhXye3Zv/liSVeydmz0KOfIXkk8lP508d17XLF2yKNTaWfwefiP3e4893qic+85KUyt1DIcFBlq8DLp3XwlnfqUHLT+KUyOcr+qbeSJ9J61csVEQ4n28kbiSliDfLFvyic6dPyi9rdvllfX6y9DI2/v2npNgTyP9y4thRrVq2SMkdHVW6fGXL+fuhoZY/P50USpJHai9JUljYfZ07c+oFIv7XysW/SZJqN7Aeh+eVJq2cnV10/onnP3z4UJcunFP6DP9OUho9uLdSp0mr9p/1ilN7JpNJJd4qp+Cg2zqwN+YkFeBpZ/2PavHP01S1fhMVKG7bWNBo169e0tF9O5Q8uaMq1LBtkuCuTWskSYVKlolx7eGDB/pn/66oSYgFi+qs/1HNmTxak4f21LypY3XG/2isz4w+nz1voVivR58/e+Ifm2J92t2gO5aKa8knqrweXmnl5Oyiy49/+ZWkRw8fKuDSeb3hk9Fy7vuvBsgjdRp90K5bnNozmUwqWKK0QoLv6NiB3S8VO+Kfg0yGHIkVY0rxwn6cOkGnTxzT/dBQnTnlr1P+x5TOO73GfDdLyZIls2vb+3ZtkyQVKFzsP+/bsOYPrfljqR4+eKirVy7qwJ6dSu7oqKFjJlt10Xt4playZMn06NEjXbl8QdlyWI/NunzxvOXPVy5fiHWFgbg4sHenLp4/I8/UXipXuZrVNZPJpHKV39HGtau0fvVKlXirnGZNm6jAWzdVoUp1SdLmdau1Yc2fGjdtjlxdU8S53YJFimv5wl+0e/sWlSpb8YViR9IQGRmpSUN6KKWbh1r3GPTCz9mwcqHMZrOKl3tb7p5eNr326L4dkqScBYrGuBZw6bwiwsPkmeYNLf75e82ZPEqRkZGW6/Omfq26zdqpfZ/hVq+7cfWyJMU6I//J89evXLIp1svnz+jXHybIbI7UnVs3dOzAbt0PvadajVuo0rvvW+4zmUwqXu5t7dq4RjvWr1LBEmW0cNZ3Cgq8pZIVqkqS9mxeq10bVqvf2BlyseHznatAUa1b/rsO79muwqVefDUTwGgkpXhh2zau1Y4tGyxfZ8iUWSMnfK/8hWL+IIlvJ44dlYODgzJnzf6f9/n/c0RLf59n+drFxVV9h36lOu83tbrP2cVFBQoX08F9u7X0t7nq3n+Y1fXF8/+d5BEaEvLCcS9fOF+SVLNuw1iHHXzWZ5B2bdukT1v/O9kiT/5CatSslR5ERGj04N56q3xlVatd33I9IjxcyZIn/89fBLLmyCVJ8n9qbCrwtOXzZujEkQPqNnyizcnkk6K77t+2seteks6dOCYHBwdlyJw1xrWQ4DuSombfz544Qu9+0ErvteiolG7u2rF+laaN6q+l//tBGTJnVe2mrS2vCwu9J0lyfkayF50E3g+17fN959YNrV32q9W5us3a6uMufWMsMdX8s346tGuLhn/WwnIuW54CqtHoYz14EKHvvxqgIm9VULlqdSzXH0SEyyHZf3++Mz3umTpz/Mgz7wESA7rv8cJmzF+uI5fuatvRi5q9cJUyZ82ulg1r6vtJX9u13dB7IQoLuy83d4/nLt/SoWtvHbl0V3tP3dDiv3eq/gcfaUifz/Rp6w/0ICLC6t42nXtIilqHdda0ibp5/ZquB1zV95O+1m//m2kZV2eyYS3DJz148EB/LY9ap7HO+7HP8M2eM48Wrt6mjt36quGHLdVv2Neas2SNHJ2cNOv7ibp86YL6DRsjSTp25KA+rFNZxbKnVfEcb+jzjs0VdOd2rM/18EwtSQq8dfOFYkfScP3qJc2ZPFoFS5SJ8yz02Jz655AunPZXSjcPlapU7fkveML90HsKD7uvlG6xf74jzWZJUV3fJcpVUacBo5XeN4vcPb1U7b0P1brHYEnSbzNiXxEgvuUvVkorD1/TsgNXNPPPXWrbc6j+XvqrujapFmN8auZsufTtgnVq2vFzVX//I3XoO0Jf/7xcjo5OWvTTFF2/fFEd+o2QJJ0+dlg9mtVU/eKZ1aCEn0Z93k53nxhb/iQ3j6jPd9DtW3Z9r7AdE51sQ1KKl+bu4anipcpq6s8Lla9QUX379XAdPrDXbu3dDY5abD7lU0u+/BdnFxflzJNPA0aM04etOmrj36s0d9Y0q3verl5bPfoPk9ls1tgvB6hSsRx6u0QuTR4zTA2aNFee/IUlxT7mNC62rF+tO7cD5Zc1uwoVK/nM+zJkyqwuPb/QkDGT1ax1R7m6ptDVK5c0fdI3+qj1J8qeM49CQ++pU4uGuh0YqK+n/KTeg0Zp07rVGtSzc6zPTPX4e3X3iQkVwNOmjuirBw8eqPPAMS/1nPUrFkiSylWrI0cnZ5tee+9u1OfbNWWqWK8/OWylaiyJc9V6UWO1b12/qisXzlrOu6RIKUkKvx8a4zWSFPb4vGuK2Nt9nmTJksknk5/ea9FR3YZP1JXzZzRtVMx1jdNl8NVHnXvrsyFjVbdZW7m4ptCNgMv6dfoE1f2onTJny6Ww0Hsa0rmZgm8Hqs/X36ttr6Has/lvTRzcPda2o5e/iv7eAYlVkuu+r1SpkooUKaIJEyYYHcprx9HRUTXqNNA/h/Zr45o/VbBIcbu04+buLkm6F3L3hV5f5/0mmjdrmtavXqmWHT6zuta6U3dVqVFHq/9YoisXLyiVm7sqVKmhkqXLqUqJqHGmOXLlfaF2VzyedV+7ge0VqK+H9pObu4c+6R61AcHKRb/qxrUAzfr9T5UsXU6SdDvwlqaOH6XzZ07FmJV/9/EPK7enZv4CT9q1cY1Sunnou+G9rc5HRETN6r51PUB9W0UtY9b76+/llTZdjGc8evTIsjbp2zauTSpJKd2iPt/378XejZ7uiUl/3rHsUubimkKeXml1J/Cm7gTetAwBeCN9RoUE39HNa1eVNXfMMeE3r119/PyX3xmpTJVack2RUnu3rteDBxFWC+jHZvqYwUrl5qGmHaPWNl6/cqECb1zT6B8Xq+DjyV7BdwI1b+o3unz+TIxZ+dHJaPT3Dq8O0+P/ErrNxCrJJaWLFi2yeQkhxF1qr6i1AQMD7ddNnCJlKrm4uOpucJAiIyNt2hpQeiLGZ3Rl+2XLoXZdelqdu3r5oq4FXFHmLNnlnT6DzTGH3A3WhjVRKwY8Pev+eXZs2aDVK5foq8kzLdXhs6dPSJIKFPl3olf0LwFnTvnHSEqjl5TySpPW5tiRtNy7G6TDe7bFei0iPMxy7cEzlh86uHOzAm9cU7oMvsr/AjP3XVOklLOLq+7djf3zndLNXd4ZM+va5QtWSylFi4yMVEh0tfWJqmq23Pl11v+oTh87ZJlY9KTTx6LGW2fNlc/mmJ9mMpmUyiO1bly9pJCgO0odS/Ie7cCOTdq6Zrl6jZ6iFI+rw5fORq3AkbNAEct9uR5P+rp45kSMpDR6nO3Ta7MCiU2S67738vKSm1vcu31hm+i93n39Yk5QiE+58xVQZGSkLpw7bfNrXyTGuT9GdfU3bNbS5vYkafXKJQoPD1PRkm/Z1O6DBw80cmBPlShVVu++1zjG9bAnuiLvP/5zbGNez5z0lyTlzhf7cjiAJK08fC3W48dVUUsNpffNYjn39LaY0aK77iu/+36ct+x8WtZc+RQZGamrT3S/P+mtylGrURzevTXGteOH9urhgwg5u7haJgBJUsnyUYnoljUrYrzm9LHDCrh0Xn458jzzfdni6sVzuhlwWSlSucn9PxLFhw8eaNqoL1SgeGmrmfrRwsPuW/4c/VmP7Zfwi2dOSoqaNIVXC2NKbWNoUlqpUiV16dJFXbp0kYeHh9KmTauBAwfK/Hgge5YsWfTll1+qefPmSpUqlfz8/LRs2TLduHFD9erVU6pUqVSoUCHt2bPH6rlbt25VpUqVlCJFCqVOnVrVq1fX7du3LW1269Ytod/qa2Pf7u3asn6N1RIsUlTyNPfHaVq+cL5cXFxVo27Mf2DjU7HHe8YfObAvxrXAWze0YO4sS5L2pG2b1mnciIGSpPcaf2x1LTT0nk6fPB7jNb/970fNmfGdsmbPqY9afxLjepsPaqtOxWI6vH9PjGvRorvun571/zz/mzlF58+cUv8vx1qdz/54CMGKRVFrnprNZv2x5PeoazljbiUaPcY3uqsfsIew+6HavvYPSS826z5adIX1xJH9sV6v91F7JXd00vJfftTxg/9+7oJu39L0rwZIkqrWa2I1nrV0lVryzpjZsgarJebQe5oyImpYzHstYn6++7d9Xx3qlJX/Yet/a5bNnaHAm9dj3H/p7Cl93fcTmc1mvV2n0X/Oml86d7ounz+tT/qPtDqf+fGSdBtWRq1gYDabtfHPxZIk32y5Yjwn+vtUsETpZ7YFJAaGd9/Pnj1bbdq00a5du7Rnzx61b99emTNnVrt27SRJ48eP18iRIzVw4ECNHz9eH3/8scqUKaPWrVvr66+/Vp8+fdS8eXMdPXpUJpNJBw4cUJUqVdS6dWtNnDhRyZMn1/r16/Xo0SOD3+nr4cLZ0xrQ4xOl9kqjfAWLyjO1l27fvqWTx4/qxrUAOTu76Mvx05T+qXFZN64FqGvbfxOys6ejfrP/8ovulkk4FarUUMdufeIUR4UqNTRr2kTt3r45Rnf4/dBQDenzmb4a0lf5ChWRt09G3b9/T+fOnNLZU1Hd3s3bddY771ov6H371k3Vq1xSOXLnVeYs2eXo6Kijhw/o0vmzyujrp6lzFsnJOeakjYvnz+rKpQu6f/9+jGuSFHDlsvbs2CJHJyerbUWf58a1AE2b8JWatuwQY13Ud+s31tTxo/X1sH7atnGtbgfe0pGDe1WzXsMYlViz2aw9O7bI3cNTRYqXinP7gK12rPtT90PvKVeBIlZVSluVLF9VC2d9p8N7tqlyLONSvTNmVueBX2nS4B7q07K+8hQuoRRubjp+YI+C7wQqe95CatVjoNVrkjs6qufoKRrQrpFmfD1Ym/9aqnTpM+novp0KvHFNZd+pY5kk9aSrF8/r+pWLVlVLSVr88zRNHzNQWXPnV3rfrDKbzbpx9aJO/XNIkZGRKlC8tFp2G/DM9xh445p+mTZWdZq2VpanhgxUqtVAv0wdqxlfD9a+rRsUfOeWThw5oAo168fY2tRsNuvInu1K6eahvEWePYESSAwMT0p9fX01fvx4mUwm5c6dW4cPH9b48eMtSWmtWrXUoUMHSdKgQYM0depUlSxZUo0aRf0W3qdPH5UuXVrXrl2Tj4+PxowZoxIlSmjKlCmWNvLnj/tC5+Hh4Qp/YhvJ4GBmMz6pxFvl1O7TntqzY4tOHD+i24G35OjopIy+mfVOrfr6qHXHWNcOjYgI16FYKonR3crSv2tpxkXJ0uWUJVsOrfljmQaMGGe1ZahX2jfU44vh2r19s06fOK6jB/cr0hypN9L5qGa9hmrUrLXeLBNzgWkPz9Rq/HEb7d25VTu3blTko0fKmNlPn3Tvp1YdP7OM97LVH0t+U2RkpCq/Xd2yNFNcfPPlALm4uqrz5zFn8Lq4uur7uYs1enAf7d6+WU7OzmrQpLn6DBkd4959u7Yp4Molfdiqo5xdXF7oPQBxYdlW9AUmOD2pYMkyypglu7auWalPvhgd60Shau99KJ9Mfvp95mT5H9qniPAw+WTyU50P26hBi08ss+2flK9ISY3/ZZXmTvlah3dv01n/f5Te108NWnZSvY/a2zTcoPmnfbVn81qd/Oeg9m1br4iwMKXy8FSR0hVVseZ7ertOo/8c7z5z7FA5u7iqWafeMa45u7hq2Pfz9cPoATq8Z5uSOzqpWoMP1a738Bj3Ht23UzcCLqvOh23k5Mzn+1VjMmCHpcQ80clkju4rN0ClSpWULVs2/fjjj5ZzS5cuVcOGDRUWFqbs2bOrc+fO6tUrajtFs9ksBwcH/fbbb5ak9OzZs8qWLZsOHjyoQoUKKV++fGrUqJGGDh36zDb/a/b9kCFDYn3tjmOXlYqZja+UOTOm6KshfTT++//FqHriX0P7fKYF837S4r93KkfuF1s54HV2/nbsSwTBWEv/94N++Gqg+o+bqbKx7FePKJOH9tRfC/+n7xZtkF+OmEN3krLQkLtqVDqHgoKC5O6esD+/g4OD5eHhoQU7Ttu0fGF8uBdyVw3fym7I+35Zr/xEpydnykf/Fhvbuegxjq6uri/VXr9+/RQUFGQ5Ll68+FLPg/00/qi10mf01Ywp44wO5ZV141qAli34RbUbNCEhRaJSs1FzvZE+k36fOdnoUF5ZgTeuad3y31W5dkMS0lcUE51sY3hSunPnTquvd+zYoZw5c77w3umFChXS2rVrXzgeZ2dnubu7Wx14NTm7uKhLrwE6enCfNvz9p9HhvJJmThkvSfqs98Dn3Am8WpycXfRxlz46efSAdm1cbXQ4r6QFP0Yl7B9/2tfgSID4YXhSeuHCBfXo0UP+/v765ZdfNHnyZHXt2vWFn9evXz/t3r1bnTp10qFDh3T8+HFNnTpVN2+yveLrqF7DD3Xk0l1VqlrT6FBeSX2HfqW9p28ofSyLjAOvuip1G2vl4Wt6s6JtW5UmFe37fKnFe84rXfqXX/AfeBUYPtGpefPmun//vt58800lS5ZMXbt2Vfv27V/4ebly5dLq1avVv39/vfnmm3J1dVWpUqXUtKltS/EAAAC8DCO60xNz973hSamjo6MmTJigqVOnxrh27ty5GOeenpeVJUuWGOcqVqyorVtjLqosSRs2bHjhWAEAAGAfhielAAAAryPT4/8Sus3EyvAxpQAAAIChlVK60gEAwOvKwRR1JHSbiRWVUgAAABiOpBQAAACGY6ITAACAHTDRyTZUSgEAAGA4KqUAAAB2wOL5tqFSCgAAAMORlAIAAMBwdN8DAADYgUkJP/EoEffeUykFAACA8aiUAgAA2AE7OtmGSikAAAAMR6UUAADADlg83zZUSgEAAGA4klIAAAAYju57AAAAO2BHJ9tQKQUAAIDhqJQCAADYgUkJv5h9Ii6UUikFAACA8UhKAQAAoNGjR8tkMqlbt26Wc2FhYercubPSpEmjVKlS6f3339e1a9fs0j5JKQAAgB04yCQHUwIfL9iBv3v3bn3//fcqVKiQ1fnu3btr+fLl+v3337Vx40ZduXJFDRo0iI9vTwwkpQAAAElYSEiImjVrpunTpyt16tSW80FBQZo5c6bGjRunt99+W8WLF9esWbO0bds27dixI97jICkFAACwA5NBhyQFBwdbHeHh4c+Ms3Pnznr33XdVtWpVq/N79+7VgwcPrM7nyZNHmTNn1vbt21/wu/JsJKUAAACvGV9fX3l4eFiOUaNGxXrf/PnztW/fvlivBwQEyMnJSZ6enlbnvb29FRAQEO8xsyQUAACAPRi4JtTFixfl7u5uOe3s7Bzj1osXL6pr165as2aNXFxcEirCZ6JSCgAA8Jpxd3e3OmJLSvfu3avr16+rWLFiSp48uZInT66NGzdq0qRJSp48uby9vRUREaE7d+5Yve7atWvy8fGJ95iplAIAACRBVapU0eHDh63OtWrVSnny5FGfPn3k6+srR0dHrV27Vu+//74kyd/fXxcuXFDp0qXjPR6SUgAAADswPf4voduMKzc3NxUoUMDqXMqUKZUmTRrL+TZt2qhHjx7y8vKSu7u7Pv30U5UuXVpvvfVWvMYtkZQCAADgGcaPHy8HBwe9//77Cg8PV/Xq1TVlyhS7tEVSCgAAYA8myWTQRKcXtWHDBquvXVxc9N133+m77757uQfHAROdAAAAYDiSUgAAABiO7nsAAAA7MHCZ0kSJSikAAAAMR6UUAADAHiiV2oRKKQAAAAxHpRQAAMAOXvXF8181VEoBAABgOJJSAAAAGI7uewAAADswGbCjU4LvIBWPqJQCAADAcFRKAQAA7IAVoWxDpRQAAACGIykFAACA4ei+BwAAsAf6721CpRQAAACGo1IKAABgB+zoZBsqpQAAADAclVIAAAA7YPF821ApBQAAgOFISgEAAGA4uu8BAADsgBWhbEOlFAAAAIajUgoAAGAPlEptQqUUAAAAhiMpBQAAgOHovgcAALADdnSyDZVSAAAAGI5KKQAAgB2wo5NtqJQCAADAcCSlAAAAMBzd9wAAAHbAMqW2oVIKAAAAw1EpBQAAsAdKpTahUgoAAADDUSkFAACwAxbPtw2VUgAAABiOpBQAAACGo/seAADADtjRyTZUSgEAAGA4KqUAAAB2wIpQtqFSCgAAAMORlAIAAMBwdN8DAADYA/33NqFSCgAAAMNRKQUAALADdnSyDZVSAAAAGI5KKQAAgB2weL5tqJQCAADAcCSlAAAAMBzd9wAAAHbAilC2oVIKAAAAw1EpBQAAsAdKpTahUgoAAADDkZQCAADAcHTfAwAA2AE7OtmGSikAAAAMR6UUAADAHgzY0SkRF0qplAIAAMB4VEoBAADsgBWhbEOlFAAAAIYjKQUAAIDh6L4HAACwB/rvbUKlFAAAAIajUgoAAGAHLJ5vGyqlAAAAMBxJKQAAAAxH9z0AAIAdmAzY0SnBd5CKR1RKAQAAYDgqpQAAAHbAilC2oVIKAAAAw1EpBQAAsAdKpTahUgoAAADDkZQCAADAcHTfAwAA2AE7OtmGSikAAAAMR6UUAADADkwyYPH8hG0uXlEpBQAAgOFISgEAAGA4uu8BAADsgGVKbUOlFAAAAIajUgoAAGAHJpMBE50ScamUSikAAAAMR6UUAADALhhVagsqpQAAADAcldLnMJvNkqR7IXcNjgSAPYSG3Dc6BAB2EHov6ud29M9xvPpISp/j7t2ov9RVSuYxOBIAAGCru3fvysPDw5C2mehkG5LS58iQIYMuXrwoNzc3mRLz/2nESXBwsHx9fXXx4kW5u7sbHQ6AeMTnO2kxm826e/euMmTIYHQor7RRo0Zp0aJFOn78uFxdXVWmTBl99dVXyp07t+WesLAwff7555o/f77Cw8NVvXp1TZkyRd7e3vEaC0npczg4OChTpkxGh4EE5u7uzg8t4DXF5zvpMKpCGi0xTHPauHGjOnfurJIlS+rhw4fq37+/qlWrpn/++UcpU6aUJHXv3l0rV67U77//Lg8PD3Xp0kUNGjTQ1q1b4zV2klIAAIAkatWqVVZf//TTT0qXLp327t2rChUqKCgoSDNnztS8efP09ttvS5JmzZqlvHnzaseOHXrrrbfiLRZm3wMAAECSFBQUJEny8vKSJO3du1cPHjxQ1apVLffkyZNHmTNn1vbt2+O1bSqlwBOcnZ01ePBgOTs7Gx0KgHjG5xsJzciJTsHBwVbnnZ2dn/t3PzIyUt26dVPZsmVVoEABSVJAQICcnJzk6elpda+3t7cCAgLiLW6JSilgxdnZWUOGDOGHFvAa4vONpMTX11ceHh6WY9SoUc99TefOnXXkyBHNnz8/ASKMiUopAACAHZge/5fQbUqKscrE834Z69Kli1asWKFNmzZZTfD28fFRRESE7ty5Y1UtvXbtmnx8fOI1diqlAAAAr5noVSaij2clpWazWV26dNHixYu1bt06Zc2a1ep68eLF5ejoqLVr11rO+fv768KFCypdunS8xkylFAAAwB4SwZpQnTt31rx587R06VK5ublZxol6eHjI1dVVHh4eatOmjXr06CEvLy+5u7vr008/VenSpeN15r1EpRSIF0OGDFGRIkWMDgOAHVSqVEndunUzOgzALqZOnaqgoCBVqlRJ6dOntxy//vqr5Z7x48erdu3aev/991WhQgX5+Pho0aJF8R6LycymsMBLCwkJUXh4uNKkSWN0KADiWWBgoBwdHeXm5mZ0KEgkgoOD5eHhoRMXb8otgTdquBscrFy+aRUUFJToNomg+x6IB6lSpVKqVKmMDgOAHUSv1wjYKhH03r9S6L7Ha2vBggUqWLCgXF1dlSZNGlWtWlX37t1Ty5YtVb9+fY0cOVLe3t7y9PTUsGHD9PDhQ/Xq1UteXl7KlCmTZs2aZfW8S5cuqWnTpvLy8lLKlClVokQJ7dy5UxLd90BCqVSpkrp06aIuXbrIw8NDadOm1cCBAxXd6ZclSxZ9+eWXat68uVKlSiU/Pz8tW7ZMN27cUL169ZQqVSoVKlRIe/bssXru1q1bValSJaVIkUKpU6dW9erVdfv2bUubdN8D9kdSitfS1atX1bRpU7Vu3VrHjh3Thg0b1KBBA8sPrnXr1unKlSvatGmTxo0bp8GDB6t27dpKnTq1du7cqY4dO6pDhw66dOmSpKju+YoVK+ry5ctatmyZDh48qN69eysyMtLItwkkSbNnz1by5Mm1a9cuTZw4UePGjdOMGTMs18ePH6+yZctq//79evfdd/Xxxx+refPm+uijj7Rv3z5lz55dzZs3t/x7cODAAVWpUkX58uXT9u3btWXLFtWpU0ePHj0y6i3iNRG9eH5CH4kV3fd4LV29elUPHz5UgwYN5OfnJ0kqWLCg5bqXl5cmTZokBwcH5c6dW2PGjFFoaKj69+8vSerXr59Gjx6tLVu2qEmTJpo3b55u3Lih3bt3W7rycuTIkfBvDIB8fX01fvx4mUwm5c6dW4cPH9b48ePVrl07SVKtWrXUoUMHSdKgQYM0depUlSxZUo0aNZIk9enTR6VLl7asszhmzBiVKFFCU6ZMsbSRP3/+hH9jQBJHpRSvpcKFC6tKlSoqWLCgGjVqpOnTp1u64qSoHzgODv/+9ff29rZKWpMlS6Y0adLo+vXrkqIqKUWLFmVsGfAKeOutt2R6ohxUunRpnTx50lLZLFSokOWat7e3JOtfSqPPPfn5rlKlit3jBvDfSErxWkqWLJnWrFmjP//8U/ny5dPkyZOVO3dunT17VpLk6Ohodb/JZIr1XHT3vKura8IEDuClPflZjk5eYzvH5xv2ZjLov8SKpBSvLZPJpLJly2ro0KHav3+/nJyctHjx4hd6VqFChXTgwAEFBgbGc5QAbBU9wTDajh07lDNnTiVLluyFnleoUCGr3WoAGIOkFK+lnTt3auTIkdqzZ48uXLigRYsW6caNG8qbN+8LPa9p06by8fFR/fr1tXXrVp05c0YLFy7U9u3b4zlyAM9z4cIF9ejRQ/7+/vrll180efJkde3a9YWf169fP+3evVudOnXSoUOHdPz4cU2dOlU3b96Mx6iRJJkMOhIpklK8ltzd3bVp0ybVqlVLuXLl0oABAzR27FjVrFnzhZ7n5OSk1atXK126dKpVq5YKFiyo0aNHv3BlBsCLa968ue7fv68333xTnTt3VteuXdW+ffsXfl6uXLm0evVqHTx4UG+++aZKly6tpUuXKnly5gIDCYkdnQAAiUalSpVUpEgRTZgwwehQgGeK3tHp9OVbhuzolD1jGnZ0AgAAQBR2dLIN3fcAAAAwHJVSAECisWHDBqNDAOLMiB2WEvOOTlRKAQAAYDgqpQAAAHZhxGL2ibdUSqUUAAAAhiMpBQAAgOFISgG80lq2bKn69etbvq5UqZK6deuW4HFs2LBBJpNJd+7ceeY9JpNJS5YsifMzhwwZoiJFirxUXOfOnZPJZNKBAwde6jkA4l/0RKeEPhIrklIANmvZsqVMJpNMJpOcnJyUI0cODRs2TA8fPrR724sWLdLw4cPjdG9cEkkAwKuBiU4AXkiNGjU0a9YshYeH648//lDnzp3l6Oiofv36xbg3IiJCTk5O8dKul5dXvDwHAPBqoVIK4IU4OzvLx8dHfn5++uSTT1S1alUtW7ZM0r9d7iNGjFCGDBmUO3duSdLFixfVuHFjeXp6ysvLS/Xq1dO5c+csz3z06JF69OghT09PpUmTRr1799bTOyE/3X0fHh6uPn36yNfXV87OzsqRI4dmzpypc+fOqXLlypKk1KlTy2QyqWXLlpKkyMhIjRo1SlmzZpWrq6sKFy6sBQsWWLXzxx9/KFeuXHJ1dVXlypWt4oyrPn36KFeuXEqRIoWyZcumgQMH6sGDBzHu+/777+Xr66sUKVKocePGCgoKsro+Y8YM5c2bVy4uLsqTJ4+mTJlicywA8KojKQUQL1xdXRUREWH5eu3atfL399eaNWu0YsUKPXjwQNWrV5ebm5s2b96srVu3KlWqVKpRo4bldWPHjtVPP/2kH3/8UVu2bFFgYKAWL178n+02b95cv/zyiyZNmqRjx47p+++/V6pUqeTr66uFCxdKkvz9/XX16lVNnDhRkjRq1Cj9/PPPmjZtmo4eParu3bvro48+0saNGyVFJc8NGjRQnTp1dODAAbVt21Z9+/a1+Xvi5uamn376Sf/8848mTpyo6dOna/z48Vb3nDp1Sr/99puWL1+uVatWaf/+/erUqZPl+ty5czVo0CCNGDFCx44d08iRIzVw4EDNnj3b5ngA4JVmBgAbtWjRwlyvXj2z2Ww2R0ZGmtesWWN2dnY29+zZ03Ld29vbHB4ebnnNnDlzzLlz5zZHRkZazoWHh5tdXV3Nf/31l9lsNpvTp09vHjNmjOX6gwcPzJkyZbK0ZTabzRUrVjR37drVbDabzf7+/mZJ5jVr1sQa5/r1682SzLdv37acCwsLM6dIkcK8bds2q3vbtGljbtq0qdlsNpv79etnzpcvn9X1Pn36xHjW0ySZFy9e/MzrX3/9tbl48eKWrwcPHmxOliyZ+dKlS5Zzf/75p9nBwcF89epVs9lsNmfPnt08b948q+cMHz7cXLp0abPZbDafPXvWLMm8f//+Z7YLIGEFBQWZJZnPBwSab4c+TNDjfECgWZI5KCjI6G+DzRhTCuCFrFixQqlSpdKDBw8UGRmpDz/8UEOGDLFcL1iwoNU40oMHD+rUqVNyc3Ozek5YWJhOnz6toKAgXb16VaVKlbJcS548uUqUKBGjCz/agQMHlCxZMlWsWDHOcZ86dUqhoaF65513rM5HRESoaNGikqRjx45ZxSFJpUuXjnMb0X799VdNmjRJp0+fVkhIiB4+fCh3d3erezJnzqyMGTNatRMZGSl/f3+5ubnp9OnTatOmjdq1a2e55+HDh/Lw8LA5HgB4lZGUAnghlStX1tSpU+Xk5KQMGTIoeXLrf05Spkxp9XVISIiKFy+uuXPnxnjWG2+88UIxuLq62vyakJAQSdLKlSutkkEpapxsfNm+fbuaNWumoUOHqnr16vLw8ND8+fM1duxYm2OdPn16jCQ5WbJk8RYrAPswGbCjU8LvIBV/SEoBvJCUKVMqR44ccb6/WLFi+vXXX5UuXboY1cJo6dOn186dO1WhQgVJURXBvXv3qlixYrHeX7BgQUVGRmrjxo2qWrVqjOvRldpHjx5ZzuXLl0/Ozs66cOHCMyusefPmtUzairZjx47nv8knbNu2TX5+fvriiy8s586fPx/jvgsXLujKlSvKkCGDpR0HBwflzp1b3t7eypAhg86cOaNmzZrZ1D4AJDZMdAKQIJo1a6a0adOqXr162rx5s86ePasNGzbos88+06VLlyRJXbt21ejRo7VkyRIdP35cnTp1+s81RrNkyaIWLVqodevWWrJkieWZv/32myTJz89PJpNJK1as0I0bNxQSEiI3Nzf17NlT3bt31+zZs3X69Gnt27dPkydPtkwe6tixo06ePKlevXrJ399f8+bN008//WTT+82ZM6cuXLig+fPn6/Tp05o0aVKsk7ZcXFzUokULHTx4UJs3b9Znn32mxo0by8fHR5I0dOhQjRo1SpMmTdKJEyd0+PBhzZo1S+PGjbMpHgAJj8XzbUNSCiBBpEiRQps2bVLmzJnVoEED5c2bV23atFFYWJilcvr555/r448/VosWLVS6dGm5ubnpvffe+8/nTp06VQ0bNlSnTp2UJ08etWvXTvfu3ZMkZcyYUUOHDlXfvn3l7e2tLl26SJKGDx+ugQMHatSoUcqbN69q1KihlStXKmvWrJKixnkuXLhQS5YsUeHChTVt2jSNHDnSpvdbt25dde/eXV26dFGRIkW0bds2DRw4MMZ9OXLkUIMGDVSrVi1Vq1ZNhQoVslryqW3btpoxY4ZmzZqlggULqmLFivrpp58ssQLA68JkftYMAgAAANgsODhYHh4eunjt9jOHK9mzbV/v1AoKCkrwtl8WY0oBAADswPT4SOg2Eyu67wEAAGA4KqUAAAD2QKnUJlRKAQAAYDiSUgAAABiO7nsAAAA7YEcn21ApBQAAgOGolAIAANiBETsssaMTAAAA8BKolAIAANgBK0LZhkopAAAADEdSCgAAAMPRfQ8AAGAP9N/bhEopAAAADEelFAAAwA5YPN82VEoBAABgOJJSAAAAGI7uewAAADtgRyfbkJQCAADYQXBwcJJoM76QlAIAAMQjJycn+fj4KGdWX0Pa9/HxkZOTkyFtvwyT2Ww2Gx0EAADA6yQsLEwRERGGtO3k5CQXFxdD2n4ZJKUAAAAwHLPvAQAAYDiSUgAAABiOpBQAAACGIykFAACA4UhKAQAAYDiSUgAAABiOpBQAAACG+z9DcGfJ1sLu9QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(test_data).flatten()\n",
    "\n",
    "# --- Print evaluation metrics ---\n",
    "y_true = []\n",
    "test_samples = []\n",
    "for sample, label in test_data.as_numpy_iterator():\n",
    "    test_samples.append(sample)\n",
    "    y_true.append(label)\n",
    "y_true = np.concatenate(y_true)\n",
    "\n",
    "\n",
    "test_samples = np.concatenate(test_samples, axis=0)\n",
    "y_true_int = y_true.astype(int)\n",
    "y_pred_int = y_pred.round().astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_true_int, y_pred_int)\n",
    "sensitivity = recall_score(y_true_int, y_pred_int, pos_label=1)\n",
    "specificity = recall_score(y_true_int, y_pred_int, pos_label=0)\n",
    "bacc = balanced_accuracy_score(y_true_int, y_pred_int)\n",
    "f1 = f1_score(y_true_int, y_pred_int, average='weighted')\n",
    "mcc = matthews_corrcoef(y_true_int, y_pred_int)\n",
    "\n",
    "auc_score = result.get('auc')\n",
    "\n",
    "print(\"\\n--- Evaluation Metrics on Test Set ---\")\n",
    "print(f\"Accuracy:    {accuracy:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f} \")\n",
    "print(f\"Balanced Accuracy (BACC): {bacc:.4f}\")\n",
    "print(f\"F1 Score (Weighted):      {f1:.4f}\") \n",
    "print(f\"Matthews Corr Coef (MCC): {mcc:.4f}\")\n",
    "print(f\"Area Under the Curve (AUC): {auc_score:.4f}\\n\")\n",
    "\n",
    "# --- Plot confusion matrix ---\n",
    "class0, class1 = DATASET.split(\"_\")\n",
    "target_names = [class0, class1]\n",
    "\n",
    "make_confusion_matrix(y_true=y_true,\n",
    "                      y_pred=y_pred.round(),\n",
    "                      classes=target_names,\n",
    "                      figsize=(8, 8),\n",
    "                      text_size=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d55452",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47d0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: /home/diogommiranda/tese/outputs/masked/fixed_lr/CROSS_VALIDATION/saved_models/LR=1.1e-05_L2=2e-04\n"
     ]
    }
   ],
   "source": [
    "save_option = False # Set to True to save the model, confusion matrix, and evaluation metrics\n",
    "\n",
    "if save_option:\n",
    "    \n",
    "    # Configure the right path\n",
    "    if USE_MASK:\n",
    "        dir1 = \"masked/\"\n",
    "    else:\n",
    "        dir1 = \"full_brain/\"\n",
    "    if cosine_scheduler:\n",
    "        dir2 = \"cosine_decay/\"\n",
    "    else:\n",
    "        dir2 = \"fixed_lr/\"\n",
    "        \n",
    "    save_model_dir = \"/home/diogommiranda/tese/outputs/\" + dir1 + dir2 + \"CROSS_VALIDATION/saved_models/\" + f\"LR={BEST_LR:.1e}_L2={BEST_REG:.0e}\"\n",
    "    print(f\"Saving model to: {save_model_dir}\")\n",
    "    os.makedirs(save_model_dir, exist_ok=True)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(os.path.join(save_model_dir, \"model.keras\"))\n",
    "\n",
    "    # Save the confusion matrix plot\n",
    "    make_confusion_matrix(y_true=y_true,\n",
    "                        y_pred=y_pred.round(),\n",
    "                        classes=target_names,\n",
    "                        figsize=(8, 8),\n",
    "                        text_size=15,\n",
    "                        save_dir=save_model_dir)\n",
    "\n",
    "    # Save the test loss and accuracy and the evaluation metrics\n",
    "    result_file_path = os.path.join(save_model_dir, \"resultados.txt\")\n",
    "    with open(result_file_path, \"w\") as f:\n",
    "        f.write(f\"[{result['loss']}, {result['accuracy']}]\\n\\n\")\n",
    "        f.write(\"--- Evaluation Metrics on Test Set ---\\n\")\n",
    "        f.write(f\"Accuracy:    {accuracy:.4f}\\n\")\n",
    "        f.write(f\"Sensitivity: {sensitivity:.4f}\\n\")\n",
    "        f.write(f\"Specificity: {specificity:.4f}\\n\")\n",
    "        f.write(f\"Balanced Accuracy (BACC): {bacc:.4f}\\n\")\n",
    "        f.write(f\"F1 Score (Weighted):      {f1:.4f}\\n\")\n",
    "        f.write(f\"Matthews Corr Coef (MCC): {mcc:.4f}\\n\")\n",
    "        f.write(f\"Area Under the Curve (AUC): {auc_score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saved_model = tf.keras.models.load_model(\"/home/diogommiranda/tese/outputs/full_brain/fixed_lr/CROSS_VALIDATION/saved_models/LR=1.1e-5 L2=2e-4/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 118ms/step - accuracy: 0.8917 - auc: 0.3368 - loss: 1.7163\n",
      "[1.964396357536316, 0.8461538553237915]\n"
     ]
    }
   ],
   "source": [
    "#result = saved_model.evaluate(test_data, return_dict=True)\n",
    "#print(f\"[{result['loss']}, {result['accuracy']}]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
